{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch基礎\n",
    "Pytorchを使う上で一番ネックになるのはPytorchの文法、classの仕様などを詳しく知らないことです。\n",
    "<br>\n",
    "それを解説するipynbファイルを制作しました。<br>\n",
    "基本コマンド編は適宜既知の内容を読み飛ばして使用ください<br>\n",
    "目次\n",
    "- 基本コマンド\n",
    "- Dataloader定義\n",
    "- モデル定義\n",
    "- Pytorchの勾配について, 最適化の方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本コマンド編"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#警告の非表示\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの作り方<br>\n",
    "Pythonデフォルトにもあるリストからtorch.tensorで作る方法とnumpyのndarrayを使ってtorch.tensorかfrom_numpyから作る方法の二通りがある<br>\n",
    "引数にdtypeを加えることで型を変更することができる。<br>\n",
    "基本的にPytorchで使う方はfloat32型である。tensor.float()とすることでfloat32型の変換を行うこともできる。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonのリストから制作 tensor([1, 2, 3])\n",
      "Pythonのnumpyからtorch.tensorで制作 tensor([1, 2, 3])\n",
      "Pythonのnumpyからtorch.from_numpyで制作 tensor([1, 2, 3])\n",
      "dtypeを引数にすることで型をfloatへ tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = [1,2,3]\n",
    "b = np.array([1,2,3])\n",
    "print(\"Pythonのリストから制作\",torch.tensor(a))\n",
    "print(\"Pythonのnumpyからtorch.tensorで制作\",torch.tensor(b))\n",
    "print(\"Pythonのnumpyからtorch.from_numpyで制作\",torch.from_numpy(b))\n",
    "print(\"dtypeを引数にすることで型をfloatへ\", torch.tensor(a, dtype = torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全成分が0と1のTensorの制作<br>\n",
    "torch.zeros, torch.onesはtorch.zeros(d1,d2,...dn)のようにn次元目の要素数を指定して制作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.zerosで制作(3,3)Tensor\n",
      " torch.Size([3, 3]) \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.onesで制作(3,3)Tensor\n",
      " torch.Size([3, 3]) \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,3)\n",
    "b = torch.ones(3,3)\n",
    "print(\"torch.zerosで制作(3,3)Tensor\\n\", a.shape, \"\\n\", a)\n",
    "print(\"torch.onesで制作(3,3)Tensor\\n\", b.shape, \"\\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乱数Tensorの作成<br>\n",
    "0から1までの一様分布ならば<br>\n",
    "torch.randはtorch.rand(d1,d2,...dn)のようにn次元目の要素数を指定して制作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.randで制作(3,3)Tensor\n",
      " torch.Size([3, 3]) \n",
      " tensor([[0.7507, 0.1789, 0.9409],\n",
      "        [0.4464, 0.4339, 0.2068],\n",
      "        [0.7291, 0.8215, 0.5488]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "print(\"torch.randで制作(3,3)Tensor\\n\", a.shape, \"\\n\", a)\n",
    "#他にも, torch.randnで正規分布の乱数の生成, torch.bernoulliでベルヌーイ分布の乱数の生成, torch.multinominalで多項分布の乱数の生成が行われる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値を指定して行列を作るのはtorch.full関数を用いる<br>\n",
    "torch.fullはtorch.full(size = (tuple or list), fill_value = (int, float))のように指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.fullで制作\n",
      " tensor([[100, 100, 100],\n",
      "        [100, 100, 100],\n",
      "        [100, 100, 100]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.full(size = (3,3), fill_value = 100)\n",
    "print(\"torch.fullで制作\\n\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単位行列はtorch.eyeで制作する引数には次元数を指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.eyeで制作, 3d対角行列\n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.eye(3)\n",
    "print(\"torch.eyeで制作, 3d対角行列\\n\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等差数列のTensorを作成<br>\n",
    "torch.arrange(start = Number, end = Number, step = Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始: 0, 終了: 100, step: 2\n",
      " tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
      "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70,\n",
      "        72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98])\n"
     ]
    }
   ],
   "source": [
    "print(\"開始: 0, 終了: 100, step: 2\\n\",torch.arange(start = 0, end = 100, step = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorのデータ型と形状を操作する<br>\n",
    "データ型を変更するのは制作したTensorにtoメソッドを使用します。<br>\n",
    "形状指定は転置にはtransposeメソッド, 形状変更はreshapeかviewメソッド, <br>サイズが1の次元を追加するのはunsqueezeメソッドサイズが1の次元を削除はsqueezeメソッドを使う<br>\n",
    "指定された順に次元を入れ替えるにはtorch.permuteメソッドを用いる<br>\n",
    "各関数, メソッドの引数は<br>\n",
    "tensor.transpose(転置する次元1つ目,転置する次元2つ目)<br>\n",
    "tensor.reshape(d1,d2,d3,...dn)<br>\n",
    "tensor.unsqueeze(追加するサイズ1の次元)<br>\n",
    "tensor.squeeze(削除するサイズ1の次元)<br>\n",
    "tensor.permute(d1, d2, ..., dn)<br>\n",
    "のように用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor\n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "転置\n",
      " tensor([[[1],\n",
      "         [4]],\n",
      "\n",
      "        [[2],\n",
      "         [5]],\n",
      "\n",
      "        [[3],\n",
      "         [6]]]) torch.Size([3, 2, 1])\n",
      "形状変更 reshape\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]]) torch.Size([6, 1])\n",
      "形状変更 view\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]]) torch.Size([6, 1])\n",
      "サイズが1の次元を追加\n",
      " tensor([[[[1]],\n",
      "\n",
      "         [[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]],\n",
      "\n",
      "         [[6]]]]) torch.Size([2, 3, 1, 1])\n",
      "サイズが1の次元を削除\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n",
      "次元の入れ替え\n",
      " tensor([[[1, 4],\n",
      "         [2, 5],\n",
      "         [3, 6]]]) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1],[2],[3]],[[4],[5],[6]]])\n",
    "print(\"元のTensor\\n\", a, a.shape)\n",
    "print(\"転置\\n\", a.transpose(0,1),a.transpose(0,1).shape)\n",
    "print(\"形状変更 reshape\\n\", a.reshape(-1,1),a.reshape(-1,1).shape) \n",
    "#numpyを使い慣れている人ならわかるように、引数に-1を指定すると, 0以上で指定した次元のサイズをいい感じに整えてくれます、\n",
    "print(\"形状変更 view\\n\", a.reshape(-1,1),a.view(-1,1).shape)\n",
    "# a.viewでエラーが出ることがある場合は.contiguous()を呼んでからview()する(https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930)\n",
    "print(\"サイズが1の次元を追加\\n\", a.unsqueeze(2), a.unsqueeze(2).shape)\n",
    "print(\"サイズが1の次元を削除\\n\", a.squeeze(2), a.squeeze(2).shape)\n",
    "print(\"次元の入れ替え\\n\", a.permute(2,1,0), a.permute(2,1,0).shape) \n",
    "#指定するのは次元, 今回は元の行列の3次元目(2)を1次元目(0),2次元目(1)を2次元目(1), 1次元目(0)を3次元目(2)にしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squeezeとunsqueezeはよく使うため詳しく解説しておく。<br>\n",
    "tensor.squeeze(num): num次元目のサイズが1ならばその次元を消す。サイズが1でなければ消さない<br>\n",
    "tensor.unsqueeze(num): num次元目に次元を増やしてサイズを1とする。<br>\n",
    "増やし方は、<br>\n",
    "$(d_0, d_1, d_{num}, d_{num+1}, d_n) -> (d_0, d_1, d_{num},1, d_{num+1}, d_n)$<br>\n",
    "と言った感じである。$num \\gt n$のときはエラーとなる。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.squeeze(0): \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.squeeze(1): \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.squeeze(2): \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1],[2],[3]],[[4],[5],[6]]])\n",
    "print(\"元のTensor: \\n\", a, a.shape)\n",
    "print(\"tensor.squeeze(0): \\n\", a.squeeze(0), a.squeeze(0).shape)\n",
    "print(\"tensor.squeeze(1): \\n\", a.squeeze(1), a.squeeze(1).shape)\n",
    "print(\"tensor.squeeze(2): \\n\", a.squeeze(2), a.squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.unsqueeze(0):\n",
      " tensor([[[[1],\n",
      "          [2],\n",
      "          [3]],\n",
      "\n",
      "         [[4],\n",
      "          [5],\n",
      "          [6]]]]) torch.Size([1, 2, 3, 1])\n",
      "tensor.unsqueeze(1):\n",
      " tensor([[[[1],\n",
      "          [2],\n",
      "          [3]]],\n",
      "\n",
      "\n",
      "        [[[4],\n",
      "          [5],\n",
      "          [6]]]]) torch.Size([2, 1, 3, 1])\n",
      "tensor.unsqueeze(2):\n",
      " tensor([[[[1]],\n",
      "\n",
      "         [[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]],\n",
      "\n",
      "         [[6]]]]) torch.Size([2, 3, 1, 1])\n",
      "tensor.unsqueeze(3):\n",
      " tensor([[[[1]],\n",
      "\n",
      "         [[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]],\n",
      "\n",
      "         [[6]]]]) torch.Size([2, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"元のTensor: \\n\", a, a.shape)\n",
    "print(\"tensor.unsqueeze(0):\\n\", a.unsqueeze(0), a.unsqueeze(0).shape)\n",
    "print(\"tensor.unsqueeze(1):\\n\", a.unsqueeze(1), a.unsqueeze(1).shape)\n",
    "print(\"tensor.unsqueeze(2):\\n\", a.unsqueeze(2), a.unsqueeze(2).shape)\n",
    "print(\"tensor.unsqueeze(3):\\n\", a.unsqueeze(3), a.unsqueeze(3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorでの算術演算<br>\n",
    "基本的にはnumpyと同じなので使い慣れている人には大丈夫なはずです。<br>\n",
    "Broadcastなどの仕様を知らない場合は理解しておきましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明に使うTensorの定義\n",
    "a = torch.tensor([[1.,2.,3.],[4.,5.,6.]]) #size (2,3)のTensor\n",
    "b = torch.tensor([[1.,2.],[3.,4.],[5.,6.]]) #size (3,2)のTensor\n",
    "c = 10. #スカラー\n",
    "d = torch.tensor([1.,2.,3.]) #size (3)のTensor\n",
    "e = torch.tensor([[7.,8.,9.],[1.,2.,3.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列の要素積(アダマール積)<br>\n",
    "行列の要素ごとの計算はtorch.multiply関数か、<br>Pythonの演算記号*を用いるものの2通りがあります。<br>どちらも同じ計算結果となります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.multiplyの計算結果\n",
      " tensor([[ 7., 16., 27.],\n",
      "        [ 4., 10., 18.]])\n",
      "*での計算結果\n",
      " tensor([[ 7., 16., 27.],\n",
      "        [ 4., 10., 18.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.multiplyの計算結果\\n\", torch.multiply(a,e))\n",
    "print(\"*での計算結果\\n\", a*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列積<br>\n",
    "線形代数でよく使われる行列の積です。<br>\n",
    "torch.matmulもしくは@記号で計算ができます。<br>\n",
    "torch.dotでの計算も可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.multiplyの計算結果\n",
      " tensor([[22., 28.],\n",
      "        [49., 64.]])\n",
      "@での計算結果\n",
      " tensor([[22., 28.],\n",
      "        [49., 64.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.multiplyの計算結果\\n\", torch.matmul(a,b))\n",
    "print(\"@での計算結果\\n\", a@b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三階以上のTensorの掛け算には<br>\n",
    "torch.bmm(Tensor1, Tensor2)(batch matrix matrix product)や、torch.einsumを用いる方が良いです。<br>\n",
    "torch.bmmは3階のテンソルで、それぞれが(b, n, m)と(b, m, p)のsizeを有する場合に(b, n, p)のテンソルを出力します。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### einsum, bmm共にattentionの実装において\n",
    "##### pythonに組み込まれているfor文を使わずに効率よくバッチごとの計算を行うために必要な関数です。\n",
    "##### 今はわからなくてもattention_from_scratch.ipynbでのattentionの実装では必ずマスターしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算対象のTensor:  torch.Size([2, 3, 4]) torch.Size([2, 4, 5])\n",
      "torch.bmm: \n",
      " tensor([[[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]],\n",
      "\n",
      "        [[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]]]) torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, 4)\n",
    "b = torch.ones(2, 4, 5)\n",
    "print(\"計算対象のTensor: \", a.shape, b.shape)\n",
    "print(\"torch.bmm: \\n\", torch.bmm(a,b), torch.bmm(a,b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.einsumはアインシュタインの縮約記法による計算です。<br>\n",
    "einsumは、最初の引数に、計算を行う前と後のサイズを添字とした文字列で与え、第二、第三の引数にTensorを与えて計算します。<br>\n",
    "詳しくは公式ドキュメント(https://pytorch.org/docs/stable/torch.html#torch.einsum)を参照してください。<br>\n",
    "上のtorch.bmmでの計算は下のように実装できます<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算対象のTensor:  torch.Size([2, 3, 4]) torch.Size([2, 4, 5])\n",
      "torch.einsum(\"bnm, bmp->bnp\", Tensor1, Tensor2): \n",
      " tensor([[[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]],\n",
      "\n",
      "        [[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]]]) torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, 4)\n",
    "b = torch.ones(2, 4, 5)\n",
    "print(\"計算対象のTensor: \", a.shape, b.shape)\n",
    "print('torch.einsum(\"bnm, bmp->bnp\", Tensor1, Tensor2): \\n', torch.einsum(\"bnm, bmp->bnp\",a,b), torch.einsum(\"bnm, bmp->bnp\",a,b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの足し算引き算\n",
    "Tensorの足し算引き算が可能になる条件は何通りかあります。\n",
    "- サイズが完全に揃っている場合\n",
    "- ブロードキャストが使える状態の場合\n",
    "- 計算対象の一方がスカラーの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "サイズが完全に揃っている場合\n",
      " torch.Size([2, 3]) torch.Size([2, 3]) \n",
      " tensor([[ 8., 10., 12.],\n",
      "        [ 5.,  7.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "#サイズが完全に揃っている場合\n",
    "#説明に使うTensorの定義\n",
    "a = torch.tensor([[1.,2.,3.],[4.,5.,6.]]) #size (2,3)のTensor\n",
    "e = torch.tensor([[7.,8.,9.],[1.,2.,3.]])\n",
    "print(\"サイズが完全に揃っている場合\\n\", a.shape, e.shape, \"\\n\" ,a + e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブロードキャストが使える時の場合<br>\n",
    "ブロードキャストに関してはNumpyの記事を参照して欲しいです。<br>少し細かい話にはなりますが、\n",
    "計算対象のテンソルのサイズが合っていなくても、<br>一部のサイズが合っていれば計算ができるといった感じです。例えば<br>\n",
    "Tensor1: size (3,3), Tensor2: size (1,3)という2つのテンソルでTensor1 + Tensor2を計算する時に<br>\n",
    "Tensor2のサイズはTensor1に合わせて(3,3)というサイズにまで拡張されて計算されます。<br>\n",
    "このときはTensor2 = [1,2,3]ならば、Tensor2は[1,2,3]という要素が3つになった(3,3)というサイズになって計算が行われます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1: torch.Size([2, 3])\n",
      "Tensor2: torch.Size([3])\n",
      "Tensor1 + Tensor2 =\n",
      " tensor([[2., 4., 6.],\n",
      "        [5., 7., 9.]])\n",
      "Tensor1 * Tensor2 =\n",
      " tensor([[ 1.,  4.,  9.],\n",
      "        [ 4., 10., 18.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor1:\",  a.shape)\n",
    "print(\"Tensor2:\",  d.shape)\n",
    "print(\"Tensor1 + Tensor2 =\\n\", a + d)\n",
    "#実は、ブロードキャストは他の演算でも有効\n",
    "print(\"Tensor1 * Tensor2 =\\n\", a * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スカラー演算<br>\n",
    "スカラーでの演算は全ての要素が足し引き、掛け算割り算されます。<br>\n",
    "スカラー演算はブロードキャストの一種と見なすこともできます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Scalar 10.0\n",
      "Scaler + Tensor1 = \n",
      " tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor1:\\n\",  a)\n",
    "print(\"Scalar\",  c)\n",
    "print(\"Scaler + Tensor1 = \\n\", a + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ブロードキャスト機能をうまく活用すると効率的にコードを書くことができます。<br>他人のコードはブロードキャスト機能を用いたものが多いため、注意を払って読みましょう。<br>また、この他にもnumpyにあったsum, mean, var, std, max, minなども実装されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_p$ノルムを求めることができます。$L_p$ノルムとは以下の式で定義される量です。<br>\n",
    "ベクトルではなく2階以上のテンソルの場合は2階以上のテンソルの場合の$L_p$ノルムを計算します。<br>\n",
    "$$\n",
    "    ||x||_p = \\left(x^p_1 + x^p_2 + \\ldots + x^p_N\\right)^{1/p}\n",
    "$$\n",
    "$L_p$ノルムを求める関数にはtorch.linalg.norm関数とtorch.norm関数があります。<br>\n",
    "それぞれ仕様に違いがあるので注意<br>\n",
    "\n",
    "torch.linalg.norm関数: ordという引数で計算するノルムの種類を指定<br>\n",
    "torch.norm関数: pという引数で計算するノルムの種類を指定<br>\n",
    "- 引数にpとdimがあるpは$L_p$ノルムのpの値を決める。dimは計算する次元を決定する。<br>\n",
    "- 計算する次元を決定する引数名はnumpyではaxisだったが、PyTorchではdimであることに注意する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算対象行列\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "行列L_2ノルム(torch.norm) tensor(9.5394)\n",
      "行列L_2ノルム(torch.norm), dim = 1 tensor([3.7417, 8.7750])\n"
     ]
    }
   ],
   "source": [
    "print(\"計算対象行列\\n\", a)\n",
    "print(\"行列L_2ノルム(torch.norm)\", a.norm(p = 2))\n",
    "print(\"行列L_2ノルム(torch.norm), dim = 1\", a.norm(p = 2,dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの分割、連結<br>\n",
    "Tensorの分割はtorch.chunk, torch.splitなどの関数が用意されており、<br>\n",
    "Tensorの結合はtorch.stack, torch.catなどの関数が用意されている。<br>\n",
    "torch.chunkはchunks引数とdim引数を持ち、chunksで分割する数を指定し、dimで分割する次元を指定する。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "torch.chunk(Tensor, chunks = 2):  (tensor([[0, 1, 2, 3, 4]]), tensor([[5, 6, 7, 8, 9]]))\n",
      "torch.chunk(Tensor, chunks = 2, dim = 1): \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [5, 6, 7]])\n",
      "tensor([[3, 4],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10).reshape(2, 5)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"torch.chunk(Tensor, chunks = 2): \", a.chunk(2))\n",
    "print(\"torch.chunk(Tensor, chunks = 2, dim = 1): \\n\")\n",
    "for t in a.chunk(chunks = 2, dim = 1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.splitはsplit_size_or_sections引数とdim引数を持ち<br>\n",
    "dimはtorch.chunkと同様の働きをする。<br>\n",
    "split_size_or_sectionsにint型を渡すと、渡した数を要素に持つようにデータを分割する<br>\n",
    "split_size_or_sectionsにlist型を渡すとlistの要素に従ってデータを分割する。例えば[1,3,1]とすると、<br>\n",
    "要素数が[1,3,1]となるように分割する<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "torch.split(Tensor, split_size_or_sections=2,dim = 1): \n",
      "\n",
      "tensor([[0, 1],\n",
      "        [5, 6]])\n",
      "tensor([[2, 3],\n",
      "        [7, 8]])\n",
      "tensor([[4],\n",
      "        [9]])\n",
      "torch.split(Tensor, split_size_or_sections=[1,3,1],dim = 1): \n",
      "\n",
      "tensor([[0],\n",
      "        [5]])\n",
      "tensor([[1, 2, 3],\n",
      "        [6, 7, 8]])\n",
      "tensor([[4],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10).reshape(2, 5)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"torch.split(Tensor, split_size_or_sections=2,dim = 1): \\n\")\n",
    "for t in torch.split(a,split_size_or_sections=2,dim = 1):\n",
    "    print(t)\n",
    "print(\"torch.split(Tensor, split_size_or_sections=[1,3,1],dim = 1): \\n\")\n",
    "for t in torch.split(a,split_size_or_sections=[1,3,1],dim = 1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの連結に使う関数にはtorch.catとtorch.stackがあります。<br>\n",
    "torch.catは結合する2つのTensorの既存の次元数に従ってTensorを結合する関数であり,<br>\n",
    "torch.stackは結合する2つのTensorに次元を追加してTensorを結合する関数である。<br>\n",
    "torch.catはtorch.cat([結合するTensorのリスト], dim = (結合する次元を指定))という感じで使い、<br>\n",
    "torch.stackはtorch.stack([結合するTensorのリスト], dim = (増やして結合する次元を指定))という感じで使う。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結合するTensorのサイズ torch.Size([2, 3]) torch.Size([2, 4])\n",
      "結合するTensor\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      " tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "torch.cat([Tensor1, Tensor2], dim = 1): \n",
      " tensor([[0, 1, 2, 0, 1, 2, 3],\n",
      "        [3, 4, 5, 4, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(8).reshape(2, 4)\n",
    "print(\"結合するTensorのサイズ\", a.shape, b.shape)\n",
    "print(\"結合するTensor\\n\", a,\"\\n\", b)\n",
    "print(\"torch.cat([Tensor1, Tensor2], dim = 1): \\n\", torch.cat([a,b], dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結合するTensorのサイズ torch.Size([2, 3]) torch.Size([2, 3])\n",
      "結合するTensor\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.stack([Tensor1, Tensor2], dim = 2): \n",
      " tensor([[[0, 0],\n",
      "         [1, 1],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[3, 3],\n",
      "         [4, 4],\n",
      "         [5, 5]]]) torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(6).reshape(2, 3)\n",
    "print(\"結合するTensorのサイズ\", a.shape, b.shape)\n",
    "print(\"結合するTensor\\n\", a,\"\\n\", b)\n",
    "print(\"torch.stack([Tensor1, Tensor2], dim = 2): \\n\", torch.stack([a,b], dim = 2),torch.stack([a,b], dim = 2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einopsというライブラリを用いるとアインシュタインの縮約記法を用いて配列を次元毎に操作することが簡単となります。<br>\n",
    "einsumとeinopsを使用してコードを簡潔に書いてしまうのがどうやら流行っているようなので覚えて損はないはずです。[einsum-attention](https://theaisummer.com/einsum-attention/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einopsはPytorchとの互換性があるため、普通に用いても勾配の計算方法を示してくれます。<br>Pytorchの勾配に関してはPytorchの勾配について, 最適化の方法で解説します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einops.rearangeはTensorの分割を行います。()で囲んだところは一つの次元とみなします。例えば下の実行例では<br>\n",
    "(i j (h k))という3つの次元のうち、3つめをh×kとみなし、h = 5, k = 3として分割をしています。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor:\n",
      " tensor([[[-0.8601, -0.3673,  0.4550,  0.8364, -0.3174,  0.4932,  0.6502,\n",
      "          -0.5228, -0.0527, -0.3271,  0.7233, -0.8816,  0.8678, -0.4960,\n",
      "           0.8767],\n",
      "         [ 0.1919,  0.1208,  0.3644,  0.1817, -0.5470,  0.2140, -0.0250,\n",
      "          -0.0844, -0.3594, -0.3971,  0.0031, -0.4746,  0.2952, -0.4868,\n",
      "          -0.1388],\n",
      "         [ 0.4334,  0.8886,  0.5452,  0.2740,  0.4277, -0.9238, -0.7216,\n",
      "          -0.0358, -0.4496, -0.6455,  0.3277, -0.6316,  0.8278,  0.4761,\n",
      "          -0.4828]],\n",
      "\n",
      "        [[-0.2377,  0.6290, -0.0030,  0.7001, -0.4949,  0.9654,  0.5006,\n",
      "          -0.4041, -0.8974, -0.4493,  0.6399,  0.3943,  0.7072, -0.4100,\n",
      "           0.2010],\n",
      "         [ 0.7614,  0.3581,  0.0768, -0.6685, -0.6705,  0.5732,  0.8943,\n",
      "           0.8172,  0.5097,  0.0203, -0.8037,  0.2167,  0.7539, -0.8204,\n",
      "          -0.7820],\n",
      "         [-0.1401,  0.2751,  0.6245,  0.9356,  0.3720,  0.1617,  0.8210,\n",
      "          -0.6095,  0.8241,  0.7745, -0.8811, -0.3423,  0.2312, -0.9478,\n",
      "          -0.5882]]], grad_fn=<ToCopyBackward0>) torch.Size([2, 3, 15])\n",
      "rearrange(i j (h k)->h i j k):\n",
      " tensor([[[[-0.8601, -0.3673,  0.4550],\n",
      "          [ 0.1919,  0.1208,  0.3644],\n",
      "          [ 0.4334,  0.8886,  0.5452]],\n",
      "\n",
      "         [[-0.2377,  0.6290, -0.0030],\n",
      "          [ 0.7614,  0.3581,  0.0768],\n",
      "          [-0.1401,  0.2751,  0.6245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8364, -0.3174,  0.4932],\n",
      "          [ 0.1817, -0.5470,  0.2140],\n",
      "          [ 0.2740,  0.4277, -0.9238]],\n",
      "\n",
      "         [[ 0.7001, -0.4949,  0.9654],\n",
      "          [-0.6685, -0.6705,  0.5732],\n",
      "          [ 0.9356,  0.3720,  0.1617]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6502, -0.5228, -0.0527],\n",
      "          [-0.0250, -0.0844, -0.3594],\n",
      "          [-0.7216, -0.0358, -0.4496]],\n",
      "\n",
      "         [[ 0.5006, -0.4041, -0.8974],\n",
      "          [ 0.8943,  0.8172,  0.5097],\n",
      "          [ 0.8210, -0.6095,  0.8241]]],\n",
      "\n",
      "\n",
      "        [[[-0.3271,  0.7233, -0.8816],\n",
      "          [-0.3971,  0.0031, -0.4746],\n",
      "          [-0.6455,  0.3277, -0.6316]],\n",
      "\n",
      "         [[-0.4493,  0.6399,  0.3943],\n",
      "          [ 0.0203, -0.8037,  0.2167],\n",
      "          [ 0.7745, -0.8811, -0.3423]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8678, -0.4960,  0.8767],\n",
      "          [ 0.2952, -0.4868, -0.1388],\n",
      "          [ 0.8278,  0.4761, -0.4828]],\n",
      "\n",
      "         [[ 0.7072, -0.4100,  0.2010],\n",
      "          [ 0.7539, -0.8204, -0.7820],\n",
      "          [ 0.2312, -0.9478, -0.5882]]]], grad_fn=<ReshapeAliasBackward0>) torch.Size([5, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce\n",
    "x = torch.tensor(np.random.uniform(low = -1, high = 1, size = (2,3,15)), requires_grad=True).float()\n",
    "print(\"元のTensor:\\n\",x,x.shape)\n",
    "print(\"rearrange(i j (h k)->h i j k):\\n\",rearrange(x,\"i j (h k) -> h i j k\",h=5,k=3),rearrange(x,\"i j (h k) -> h i j k\",h=5,k=3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einops.reduceは次元を減らします。第一引数に次元を減らす対象となるテンソル, 第二引数に減らす前の次元と減らした後の次元を指定、第三引数に次元の減らし方を指定します。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor:\n",
      " tensor([[[-0.8601, -0.3673,  0.4550,  0.8364, -0.3174,  0.4932,  0.6502,\n",
      "          -0.5228, -0.0527, -0.3271,  0.7233, -0.8816,  0.8678, -0.4960,\n",
      "           0.8767],\n",
      "         [ 0.1919,  0.1208,  0.3644,  0.1817, -0.5470,  0.2140, -0.0250,\n",
      "          -0.0844, -0.3594, -0.3971,  0.0031, -0.4746,  0.2952, -0.4868,\n",
      "          -0.1388],\n",
      "         [ 0.4334,  0.8886,  0.5452,  0.2740,  0.4277, -0.9238, -0.7216,\n",
      "          -0.0358, -0.4496, -0.6455,  0.3277, -0.6316,  0.8278,  0.4761,\n",
      "          -0.4828]],\n",
      "\n",
      "        [[-0.2377,  0.6290, -0.0030,  0.7001, -0.4949,  0.9654,  0.5006,\n",
      "          -0.4041, -0.8974, -0.4493,  0.6399,  0.3943,  0.7072, -0.4100,\n",
      "           0.2010],\n",
      "         [ 0.7614,  0.3581,  0.0768, -0.6685, -0.6705,  0.5732,  0.8943,\n",
      "           0.8172,  0.5097,  0.0203, -0.8037,  0.2167,  0.7539, -0.8204,\n",
      "          -0.7820],\n",
      "         [-0.1401,  0.2751,  0.6245,  0.9356,  0.3720,  0.1617,  0.8210,\n",
      "          -0.6095,  0.8241,  0.7745, -0.8811, -0.3423,  0.2312, -0.9478,\n",
      "          -0.5882]]], grad_fn=<ToCopyBackward0>) torch.Size([2, 3, 15])\n",
      "reduce(i j k->i j) method max:\n",
      " tensor([[0.8767, 0.3644, 0.8886],\n",
      "        [0.9654, 0.8943, 0.9356]], grad_fn=<ReshapeAliasBackward0>) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"元のTensor:\\n\",x,x.shape)\n",
    "print(\"reduce(i j k->i j) method max:\\n\",reduce(x, \"i j k->i j\",\"max\"),reduce(x, \"i j k->i j\",\"max\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件演算子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.where条件を満たす要素に処理を行う関数です。\n",
    "torch.where(条件式, Trueの場合, Falseの場合)のように書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([0.0433, 0.7358, 0.5388, 0.8124, 0.9210, 0.3257, 0.5095, 0.3620, 0.3561,\n",
      "        0.3368])\n",
      "Tensor1 > 0.5なら1, Tensor1 <= 0.5なら0としてtorch.where関数を適用させたもの: \n",
      " tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10)\n",
    "a = 1/(1+torch.exp(a))\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"Tensor1 > 0.5なら1, Tensor1 <= 0.5なら0としてtorch.where関数を適用させたもの: \\n\", torch.where(a > 0.5, torch.ones_like(a), torch.zeros_like(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.clamp<br>\n",
    "torch.clampは値を一定の範囲でクリッピングします。logやゼロ割に対処するために使用します。<br>\n",
    "torch.clamp(処理前のTensor, min, max)のように指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([ 0.6773,  0.8354, -0.6208,  0.2292, -1.6646, -0.1285, -0.5516, -0.6917,\n",
      "         1.0182, -0.2993])\n",
      "torch.clampを適用しない場合: \n",
      " tensor([-0.3896, -0.1799,     nan, -1.4731,     nan,     nan,     nan,     nan,\n",
      "         0.0180,     nan])\n",
      "torch.clampを適用する場合: \n",
      " tensor([-3.8959e-01, -1.7987e-01, -7.3683e+01, -1.4731e+00, -7.3683e+01,\n",
      "        -7.3683e+01, -7.3683e+01, -7.3683e+01,  1.8005e-02, -7.3683e+01])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10)\n",
    "a_clamp = torch.clamp(a, 1e-32, 1e+32) #値が\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"torch.clampを適用しない場合: \\n\", torch.log(a))\n",
    "print(\"torch.clampを適用する場合: \\n\", torch.log(a_clamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.ge, torch.gt, torch.le, torch.lt, torch.eq<br>\n",
    "torch.geはgreater than or equal toを意味し,torch.ge(tensor, num)となった場合、tensor>=numとなった要素をTrueとして返します。<br>\n",
    "torch.gt, torch.le, torch.lt, torch.eqも関数の呼び出し方は一緒です。<br>\n",
    "gtはgreater than, leはless than or equal, ltはless than, eqはequalを意味します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Tensor >= 4 tensor([False, False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "Tensor > 4 tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "Tensor <= 4 tensor([ True,  True,  True,  True,  True, False, False, False, False, False])\n",
      "Tensor < 4 tensor([ True,  True,  True,  True, False, False, False, False, False, False])\n",
      "Tensor == 4 tensor([False, False, False, False,  True, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"Tensor >= 4\", torch.ge(a, 4))\n",
    "print(\"Tensor > 4\", torch.gt(a, 4))\n",
    "print(\"Tensor <= 4\", torch.le(a, 4))\n",
    "print(\"Tensor < 4\", torch.lt(a, 4))\n",
    "print(\"Tensor == 4\", torch.eq(a, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyと同じく、算術演算子を使うこともできます。実用上はこちらの方が使う場面が多いかもしれません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Tensor >= 4 tensor([False, False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "Tensor > 4 tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "Tensor <= 4 tensor([ True,  True,  True,  True,  True, False, False, False, False, False])\n",
      "Tensor < 4 tensor([ True,  True,  True,  True, False, False, False, False, False, False])\n",
      "Tensor == 4 tensor([False, False, False, False,  True, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"Tensor >= 4\", a>=4)\n",
    "print(\"Tensor > 4\", a>4)\n",
    "print(\"Tensor <= 4\", a<=4)\n",
    "print(\"Tensor < 4\", a<4)\n",
    "print(\"Tensor == 4\", a==4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他にPytorchで知っておくメソッドは, <br>リストやnumpyのndarrayに変換するtolist, numpyメソッド, 値の取得を行うitemメソッド, 計算するデバイスの指定などがあります。<br>\n",
    "紹介する時になったら紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader定義編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有名なデータセットは前もってPytorch上で扱いやすいように提供されています。<br>しかし実際には自分でデータを集めて制作した自作データセットを使いたいという場面もあります。<br>\n",
    "そこでこの章では自作Dataloaderセットの定義の方法を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データがTensorオブジェクト, Pythonリスト, またはNumpy配列として既に存在している場合には<br>torch.utils.data.DataLoaderクラスを用いればデータセットローダーを簡単に制作することができる。<br>\n",
    "DataLoaderクラスの定義の際にBatch_sizeを指定すると, 指定したサイズのバッチが反復の際に出力される。<br>\n",
    "また、シャッフルが必要なときはshuffle = Trueと引数を変更することでデータがシャッフルされた状態で取り出される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "t = torch.ones(size = (10,3), dtype = torch.float32)\n",
    "data_loader = DataLoader(t, batch_size = 2)\n",
    "for t_item in data_loader:\n",
    "    print(t_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に2つのテンソルを1つのデータセットに結合する。<br>\n",
    "この時に自作データセットの定義が必要となる。<br>\n",
    "Pythonのクラスに関しての説明は詳しくは行わないので, Pythonの基本的な参考書で補填して欲しい。<br>\n",
    "Datasetクラスの継承を行ったあと, init, getitem, lenメソッドの挙動の定義を行うことで簡単にDatasetクラスを制作することができる。<br>\n",
    "getitemメソッドが見慣れないと思うので少し簡単な解説を行う。<br>\n",
    "getitemメソッドはPythonの特殊メソッドであり鉤括弧[]でオブジェクトにアクセスした時の挙動を定義するものである。<br>\n",
    "例えばリストL = [0,1,2,3,4,5]の4番目の要素にアクセスする時、L[3] = 3となるのはこのgetitemメソッドによるものである。<br>\n",
    "今回はfor文を回した時に, データとラベルを出力できるように制作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: \n",
      " tensor([[0.5950, 0.0602, 0.6915, 0.2800, 0.7117],\n",
      "        [0.2111, 0.6598, 0.9283, 0.1824, 0.1428],\n",
      "        [0.0711, 0.4590, 0.4088, 0.1092, 0.4826],\n",
      "        [0.9806, 0.6467, 0.8081, 0.7305, 0.1708]]) \n",
      "label: \n",
      " tensor([0., 1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "#簡単なデータを制作する\n",
    "data = torch.rand(size = (4,5), dtype = torch.float32)\n",
    "y = torch.arange(4, dtype = torch.float32)\n",
    "print(\"Data: \\n\", data, \"\\nlabel: \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5950, 0.0602, 0.6915, 0.2800, 0.7117]) tensor(0.)\n",
      "tensor([0.2111, 0.6598, 0.9283, 0.1824, 0.1428]) tensor(1.)\n",
      "tensor([0.0711, 0.4590, 0.4088, 0.1092, 0.4826]) tensor(2.)\n",
      "tensor([0.9806, 0.6467, 0.8081, 0.7305, 0.1708]) tensor(3.)\n",
      "Length:  4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class normal_dataset(Dataset):\n",
    "    def __init__(self, data, y):\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.y[idx]\n",
    "d_set = normal_dataset(data, y)\n",
    "for batch_x, batch_y in d_set:\n",
    "    print(batch_x, batch_y)\n",
    "print(\"Length: \", len(d_set))\n",
    "#実際にDataLoaderと同じように使えることがわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットがテンソル形式のラベルデータセットならば, 単純にtorch.utils.data.TensorDatasetを用いることでも実装ができる。<br>\n",
    "TensorDatasetで制作したオブジェクトをDataLoaderに渡すことでbatch_sizeを指定してデータを取り出すこともできる。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5950, 0.0602, 0.6915, 0.2800, 0.7117],\n",
      "        [0.2111, 0.6598, 0.9283, 0.1824, 0.1428]]) tensor([0., 1.])\n",
      "tensor([[0.0711, 0.4590, 0.4088, 0.1092, 0.4826],\n",
      "        [0.9806, 0.6467, 0.8081, 0.7305, 0.1708]]) tensor([2., 3.])\n",
      "Length:  2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "d_set = TensorDataset(data, y)\n",
    "d_set = DataLoader(d_set, batch_size = 2)\n",
    "for batch_x, batch_y in d_set:\n",
    "    print(batch_x, batch_y)\n",
    "print(\"Length: \", len(d_set))\n",
    "#実際にDataLoaderと同じように使えることがわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データのサブセット作成<br>\n",
    "torch.utils.data.Subset(data, idx)でデータセットのサブセットの制作が行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5950, 0.0602, 0.6915, 0.2800, 0.7117]]) tensor([0.])\n",
      "Length:  1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "d_set = TensorDataset(data, y)\n",
    "d_set_sub = Subset(d_set, torch.arange(1))\n",
    "d_set_sub = DataLoader(d_set_sub)\n",
    "for batch_x, batch_y in d_set_sub:\n",
    "    print(batch_x, batch_y)\n",
    "print(\"Length: \", len(d_set_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの説明はDataloaderの一部にすぎませんが, <br>Datasetクラスを定義し, init, len, getitemメソッドの挙動を定義することを覚えておけば, 応用が効くようになると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル定義編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この章では主にモデルを構築する方法を学びます。<br>Pytorchの高レベルAPIを用いれば簡単なモデルの構築は3秒で終わりますが, <br>\n",
    "今回は全結合層, 2次元畳み込み層の低レベルAPIを用いた実装を通してより深くPytorchを学んだ上でモデルの定義を行おうと思います。<br>\n",
    "<br>\n",
    "低レベルAPIで高レベルAPIにある機能を実装することは、Pytorch内部の仕様の理解を助け、よりカスタムされた機能を追加することに役立つため、<br>\n",
    "必ず自分でドキュメントを読み、一度は手を動かして行ってください。<br>\n",
    "写経でも全く問題はありません、しかし組んでいる最中でコードに疑問を持ったところは必ず理解して次に進みましょう。<br>\n",
    "モデル定義編で扱わなかったレイヤーの低レベルAPI実装はAppendixに記しておきます。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU\n",
    "ReLUは<br>$$\\text{ReLU}(x) = \\text{max}(0, x)$$<br>で定義される関数であり、$x=0$付近で非線形の特性を示す関数です。活性化関数としておそらく最も頻繁に使われています。<br>\n",
    "Pytorchの練習としてtorch.where関数で組んでみましょう。\n",
    "また、今後は関数を組む際に事故を防ぐためにPythonの型を明示的にコードを書いていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor:  tensor([ 0.3777,  0.6822,  0.2602,  1.4187,  1.6311, -1.6210, -0.1317,  1.3137])\n",
      "ReLU(Tensor):  tensor([0.3777, 0.6822, 0.2602, 1.4187, 1.6311, 0.0000, 0.0000, 1.3137])\n"
     ]
    }
   ],
   "source": [
    "def relu(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.where(x > 0, x, torch.zeros_like(x))\n",
    "a = torch.randn(8)\n",
    "print(\"元のTensor: \", a)\n",
    "print(\"ReLU(Tensor): \", relu(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層のスクラッチ実装<br>\n",
    "全結合層\n",
    "$$\n",
    "Z = XW^{T}+b\n",
    "$$\n",
    "の実装を行います。ここで、$W \\in{M_{out\\_dim×in\\_dim}}, X \\in{M_{num\\_data×in\\_dim}}$であることに注意してください。<br>\n",
    "初めはこの定義に対して疑問を思うかもしれませんが、一度誤差逆伝播法の証明をすればわかるようになるかと思います。<br>\n",
    "<br>実際に使う時はtorch.nn.Linearクラスを用いれば問題はありませんが, 今回はPytorchの理解のためにスクラッチ実装を行います。\n",
    "手順<br>\n",
    "- nn.Moduleの継承\n",
    "- init引数をin_dim, out_dimとする。\n",
    "- nn.Parameterでパラメーター行列, バイアスベクトルを制作\n",
    "- クラス内でforward関数の挙動を定義, $Z = XW^{T}+b$を出力するようにする。これにはtorch.matmulとtorch.nn.functional.linearを使う方法の2通りがある\n",
    "\n",
    "torch.nn.functional.linearはtorch.nn.functional.linear(A,B,b)として実行すると$AB^{T}+b$を出力する関数である。torch.matmulとの違いに気をつけよう。<br>\n",
    "torch.matmulを使った方が直感的にはわかりやすい。\n",
    "<br>\n",
    "<br>\n",
    "次に, nn.Parameterを使う理由としては、公式ドキュメントによると, nn.Parameterで定義されたパラメーターは<br>nn.Moduleのparameters()イテレーターとして追加されるからである。\n",
    "<br>\n",
    "<br>\n",
    "nn.Moduleを継承したクラスでforwardを定義すると、丸括弧で囲んだときの挙動を指定する。例えば、Linear(x)などである。<br>\n",
    "Pythonではこれは__call__メソッドの定義にあたるものだが、__call__メソッドとして forward が機能するようにモジュール側で実装されています。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "rng = np.random.RandomState(1)\n",
    "class linear(nn.Module):\n",
    "    def __init__(self, in_dim: int or float, out_dim: int or float) -> None:\n",
    "        super().__init__()\n",
    "        #He uniformで初期化\n",
    "        weight = torch.tensor(rng.uniform(low=-np.sqrt(6/in_dim),high=np.sqrt(6/in_dim),size=(out_dim, in_dim)).astype('float32'))\n",
    "        #Biasは全て0で初期化\n",
    "        bias = torch.tensor(np.zeros([out_dim]).astype('float32'))\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #以下の関数はreturn torch.matmul(x, self.weight.T) + self.biasを実行していることと同じである。\n",
    "        return F.linear(x, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に使ってみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size = (3,3))\n",
    "L = linear(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に,forwardが機能していることと, Linearのパラメーターがparametersメソッドを使った時にイテレーターになっているかを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward: \n",
      " tensor([[ 1.1952,  1.2553,  0.9727],\n",
      "        [-0.6939, -2.7353, -1.2733],\n",
      "        [-1.4224, -1.1505, -0.2474]], grad_fn=<AddmmBackward0>)\n",
      "Linear parameters: \n",
      "Parameter containing:\n",
      "tensor([[-0.2347,  0.6232, -1.4139],\n",
      "        [-0.5591, -0.9991, -1.1530],\n",
      "        [-0.8874, -0.4368, -0.2920]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"forward: \\n\", L(x))\n",
    "print(\"Linear parameters: \")\n",
    "for p in L.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 高レベルAPI: torch.nn.Linearの注意点\n",
    "torch.nn.Linearでは上の実装よりさらに頭の良い実装を行っている。<br>\n",
    "nn.Linearはnn.Linear(in_dim, out_dim)という初期化を行うが、これは入力テンソル: $(*, H_{in})$->出力テンソル: $(*,H_{out})$という変換を意味する。<br>\n",
    "つまり、入力テンソルが二次元であるか否かに関わらず機能する。<br>\n",
    "この特性は、Attentionの実装の際に系列データを読み込み、(batch_size, sequence_length, num_features)というデータを扱うときでも<br>\n",
    "入力テンソル: $(\\text{batch\\_size}, \\text{sequence\\_length}, \\text{num\\_features})$->出力テンソル: $(\\text{batch\\_size}, \\text{sequence\\_length}, H_{out})$<br>\n",
    "となることを意味する。<br>\n",
    "このため、特別な事情がない限り(例えば, カスタム化した行列の初期化を行いたいなど)は行列演算はtorch.nn.Linearを用いた方が良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に2次元畳み込み層の実装を示します。<br>\n",
    "畳み込みをするモチベーションに関しては市販の技術書やウェブサイトを参考にしてほしい<br>\n",
    "<br>\n",
    "公式ドキュメントにのっとり、__init__にはin_channels, out_channels, kernel_size, stride, padding,dilation,groupを引数として実装します。<br>\n",
    "バッチサイズを$N$, 入力チャンネルを$C_{in}$, 出力チャンネルを$C_{out}$, 入力2次元画像の高さを幅を$H, W$とすると<br>\n",
    "conv2dは$(N, C_{in}, H, W) \\to (N, C_{out}, H_{out}, W_{out})$とする層である。<br>\n",
    "$H_{out}, W_{out}$の大きさはpaddingなどで決まる。<br>\n",
    "式は以下の通りである。<br>\n",
    "$$\n",
    "H_{out} = \\lfloor \\dfrac{H_{in}+2\\rm{padding}[0]-\\rm{dilation}[0](\\rm{kernel\\_size}[0]-1)-1}{\\rm{stride}[0]}+1 \\rfloor\n",
    "$$\n",
    "$$\n",
    "W_{out} = \\lfloor \\dfrac{W_{in}+2\\rm{padding}[1]-\\rm{dilation}[1](\\rm{kernel\\_size}[1]-1)-1}{\\rm{stride}[1]}+1 \\rfloor\n",
    "$$\n",
    "モデルを構築するときは畳み込み層を通した後の形に注意しながら実装する必要がある。<br>\n",
    "二次元畳み込みは全結合層のようにtorch.matmulなどの単純な関数による実装はできないため、torch.nn.functional.conv2d関数を用いる<br>\n",
    "もし本当にゼロからの実装に興味がある人は, 効率よく二次元畳み込み演算を計算する方法として<br>Winograd's Minimal Filteringアルゴリズムなどが知られているため、調べてもらいたい。<br>\n",
    "単純に二次元畳み込みの定義式\n",
    "$$\n",
    "Y[i,j] = \\sum\\limits_{k_1=-\\infty}^{+\\infty}\\sum\\limits_{k_2=-\\infty}^{+\\infty}X[i-k_1, j-k_2]W[k_1,k_2]\n",
    "$$\n",
    "を実装するだけでは非常に効率が悪いため効率が良いアルゴリズムを用いてPytorchでは実装を行っている。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "rng = np.random.RandomState(1)\n",
    "class conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = (1,1), padding = (0,0), dilation = (1,1), group = 1):\n",
    "        super().__init__()\n",
    "        filter_shape = (out_channels, in_channels // group, kernel_size[0], kernel_size[1])\n",
    "        k = in_channels * kernel_size[0] * kernel_size[1]\n",
    "        weight = torch.tensor(rng.uniform(low=-np.sqrt(k),high=np.sqrt(k),size=filter_shape).astype('float32'))\n",
    "        bias = torch.tensor(rng.uniform(low = -np.sqrt(k), high = np.sqrt(k), size = [out_channels]).astype('float32'))\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "        self.stride = stride  \n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.group = group\n",
    "    def forward(self, x):\n",
    "        return F.conv2d(x, weight = self.weight, bias = self.bias, stride = self.stride, padding = self.padding, dilation = self.dilation, groups = self.group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(rng.uniform(size = (3,3,3,3)).astype(\"float32\"))\n",
    "conv = conv2d(3,32,(3,3),padding=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv(x), conv(x)のサイズ: \n",
      " tensor([[[[-4.2212e+00,  1.2553e+01,  1.8412e+00],\n",
      "          [ 1.9680e+00,  9.3378e+00,  1.0218e+01],\n",
      "          [ 3.4083e+00,  9.3369e+00,  3.0335e+00]],\n",
      "\n",
      "         [[-4.0024e+00, -1.6263e+00, -1.5996e+01],\n",
      "          [-1.9691e+00, -6.2055e+00,  1.4242e+00],\n",
      "          [-5.3402e-01, -6.7465e+00, -1.1870e+00]],\n",
      "\n",
      "         [[-5.1369e+00,  5.8946e+00, -4.3092e+00],\n",
      "          [-7.9002e+00, -7.5852e+00, -9.3150e+00],\n",
      "          [-3.0901e+00, -1.0952e+01, -9.2359e+00]],\n",
      "\n",
      "         [[-5.2849e+00, -1.3041e+01, -1.1580e+01],\n",
      "          [-9.4775e+00, -6.8972e+00, -1.2919e+01],\n",
      "          [-5.3173e+00, -6.5992e+00, -7.8031e+00]],\n",
      "\n",
      "         [[ 1.4641e+00, -1.6522e+00,  2.8938e+00],\n",
      "          [ 3.0718e+00,  3.8519e+00,  8.9192e+00],\n",
      "          [ 1.4945e+01,  1.8072e+01,  7.8460e+00]],\n",
      "\n",
      "         [[ 2.3566e+00,  2.1134e+00,  1.6296e+00],\n",
      "          [ 9.4615e+00,  9.0693e+00,  1.0424e+00],\n",
      "          [ 7.3955e+00, -1.5721e+00,  4.7677e+00]],\n",
      "\n",
      "         [[ 3.8665e+00,  3.6910e+00, -3.2254e+00],\n",
      "          [ 8.2848e+00,  1.1335e+01,  5.6206e+00],\n",
      "          [ 9.4431e+00,  1.5931e+01,  6.6220e+00]],\n",
      "\n",
      "         [[-5.8059e+00, -6.8000e+00, -5.6801e+00],\n",
      "          [-4.7471e+00, -4.5583e-01,  2.5118e+00],\n",
      "          [ 1.2426e+00,  4.9865e+00,  3.6071e+00]],\n",
      "\n",
      "         [[-4.8402e+00, -3.1580e+00, -8.0357e-01],\n",
      "          [-6.8964e+00, -1.0076e+01, -1.0149e+01],\n",
      "          [ 7.5310e+00, -2.1680e+00, -1.3987e+00]],\n",
      "\n",
      "         [[ 1.8814e+00,  6.4850e+00, -2.4349e+00],\n",
      "          [ 4.6980e-01, -4.2739e-01,  5.9480e+00],\n",
      "          [ 4.8854e-01,  5.5092e+00,  2.4561e+00]],\n",
      "\n",
      "         [[ 6.4304e+00, -1.7882e+00,  8.7652e+00],\n",
      "          [ 2.6893e+00, -1.4163e+00, -3.9525e+00],\n",
      "          [-2.6933e+00, -1.2160e+01, -8.2072e+00]],\n",
      "\n",
      "         [[ 8.5322e+00,  2.1324e+00,  2.0537e+00],\n",
      "          [ 7.3839e+00,  1.7225e+00, -4.5678e+00],\n",
      "          [ 1.0294e+01,  9.3125e-01,  6.0450e+00]],\n",
      "\n",
      "         [[-6.4079e+00, -4.1864e+00, -3.4164e+00],\n",
      "          [-5.5811e+00, -8.6498e+00,  1.5957e-01],\n",
      "          [ 1.5107e+00, -1.1364e+01, -4.3111e+00]],\n",
      "\n",
      "         [[-5.9112e+00,  1.0174e+01,  9.3950e+00],\n",
      "          [-1.1121e+00,  8.4347e+00,  6.9819e+00],\n",
      "          [ 3.9289e+00,  1.0275e+01,  3.8587e+00]],\n",
      "\n",
      "         [[ 4.3815e+00, -3.3545e+00,  3.8626e+00],\n",
      "          [ 3.4558e+00,  3.1050e-01, -3.9126e+00],\n",
      "          [ 2.6509e+00,  7.9246e-01, -6.6392e+00]],\n",
      "\n",
      "         [[-2.5555e+00, -5.5719e+00,  9.0077e-01],\n",
      "          [-3.5690e+00, -3.6162e+00,  8.9537e+00],\n",
      "          [ 5.2036e+00,  1.1415e+01,  5.0173e+00]],\n",
      "\n",
      "         [[-1.1978e+00, -6.0554e+00, -2.5344e+00],\n",
      "          [ 5.5720e-01,  1.0559e+01,  8.4872e+00],\n",
      "          [ 9.0260e+00,  3.6497e+00,  7.4694e+00]],\n",
      "\n",
      "         [[-2.0615e+00, -2.9419e+00,  5.6444e+00],\n",
      "          [ 6.9038e-02, -1.1934e+00,  2.4905e+00],\n",
      "          [-8.6935e+00, -2.9418e+00, -2.3955e+00]],\n",
      "\n",
      "         [[ 1.3307e+01,  4.6928e+00,  1.2866e+01],\n",
      "          [ 4.1512e+00,  1.4819e+01,  1.2864e+01],\n",
      "          [ 1.2055e+01,  5.8130e+00,  5.4783e+00]],\n",
      "\n",
      "         [[-9.4914e+00, -1.4016e+01, -3.5725e+00],\n",
      "          [-2.1224e+01, -7.6232e+00, -7.3130e+00],\n",
      "          [-1.3175e+01, -1.2351e+01, -4.5656e+00]],\n",
      "\n",
      "         [[-1.0647e+01, -1.6798e+01, -7.1448e-01],\n",
      "          [-1.3792e+01, -3.7417e+00, -9.1354e+00],\n",
      "          [-3.5064e+00, -5.6484e+00, -1.0031e+01]],\n",
      "\n",
      "         [[ 2.6667e+00, -4.4700e-01,  2.9994e+00],\n",
      "          [ 2.7490e+00, -2.6855e+00, -3.0351e+00],\n",
      "          [-2.4086e+00,  1.4948e+00, -9.0130e+00]],\n",
      "\n",
      "         [[ 3.6116e+00,  2.8318e+00, -3.2734e+00],\n",
      "          [ 2.0908e+00, -4.7741e+00,  1.9412e+00],\n",
      "          [ 6.8920e-01,  1.9249e+00, -4.2260e+00]],\n",
      "\n",
      "         [[-6.4911e-01,  1.4366e+01,  3.5775e+00],\n",
      "          [ 2.8121e+00,  5.1930e+00,  1.5458e+01],\n",
      "          [ 1.0417e+01,  1.1579e+01,  1.1893e+01]],\n",
      "\n",
      "         [[ 8.2714e+00,  1.1812e+01, -6.3672e+00],\n",
      "          [ 6.6282e+00,  1.3404e+01, -1.8837e+00],\n",
      "          [ 3.0128e+00, -5.5767e+00, -1.5928e+00]],\n",
      "\n",
      "         [[ 5.3380e+00, -2.9487e-01,  4.6412e+00],\n",
      "          [ 3.8932e+00, -4.3542e+00, -2.8166e+00],\n",
      "          [-2.7744e+00,  9.8807e-01, -8.7967e+00]],\n",
      "\n",
      "         [[ 6.7980e+00,  1.0394e+01,  1.2109e+01],\n",
      "          [ 1.0949e+01,  1.3516e+01,  1.8680e+01],\n",
      "          [ 4.7029e+00,  1.1905e+01,  4.8649e+00]],\n",
      "\n",
      "         [[-7.2184e+00, -6.6266e+00, -4.3200e+00],\n",
      "          [-4.8187e+00, -7.5617e+00, -3.1376e+00],\n",
      "          [-8.6600e+00,  1.5430e-01,  3.3446e+00]],\n",
      "\n",
      "         [[ 3.9177e+00,  1.7335e+00,  4.8065e+00],\n",
      "          [ 3.5283e+00,  3.6849e+00,  4.2832e+00],\n",
      "          [ 1.1976e+01,  5.2033e+00,  5.7067e+00]],\n",
      "\n",
      "         [[-9.8239e+00, -1.3295e+01, -3.3296e+00],\n",
      "          [-9.6862e+00, -1.1987e+01, -4.9146e+00],\n",
      "          [-1.1561e+01,  2.0281e+00, -9.5186e+00]],\n",
      "\n",
      "         [[ 3.5834e+00,  4.7398e+00,  1.4064e+01],\n",
      "          [ 3.4230e+00,  3.2606e+00,  8.3300e+00],\n",
      "          [ 2.0626e+00,  3.7634e+00, -6.9722e-01]],\n",
      "\n",
      "         [[ 1.1332e+00, -1.7280e+01, -7.7852e+00],\n",
      "          [-1.2591e+01, -3.3959e+00, -9.6998e+00],\n",
      "          [-1.2414e+01, -1.4146e+01, -3.5798e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.6290e+00,  6.3791e+00,  1.8310e+01],\n",
      "          [-2.9181e+00,  7.8631e+00,  1.2331e+01],\n",
      "          [ 4.0288e+00,  7.9162e+00,  6.1245e+00]],\n",
      "\n",
      "         [[-7.4999e-01, -1.3590e+00, -4.1292e+00],\n",
      "          [-1.0735e+01, -3.6308e+00, -3.4051e+00],\n",
      "          [-4.6021e+00, -4.0944e+00,  3.8529e+00]],\n",
      "\n",
      "         [[-2.7841e-01, -2.5033e+00, -7.1352e+00],\n",
      "          [-1.5301e+01, -1.5327e+01, -8.9060e+00],\n",
      "          [-9.8518e+00, -9.9865e+00, -4.4466e+00]],\n",
      "\n",
      "         [[-5.2352e+00, -1.6359e+01, -1.9155e+01],\n",
      "          [-4.3034e+00, -1.0251e+01, -3.4973e+00],\n",
      "          [-8.7216e+00, -9.3384e+00, -1.2694e+00]],\n",
      "\n",
      "         [[ 1.2675e+00,  4.0405e+00, -1.9288e+00],\n",
      "          [ 1.2483e+01,  1.0918e+01,  6.6721e+00],\n",
      "          [ 1.6136e+01,  1.1558e+01,  7.8340e+00]],\n",
      "\n",
      "         [[ 4.5169e+00,  4.3676e+00,  2.7941e+00],\n",
      "          [ 3.8343e+00,  1.0692e+01,  7.2530e+00],\n",
      "          [ 2.8866e+00,  1.0801e+01,  5.0331e+00]],\n",
      "\n",
      "         [[ 8.7198e+00,  1.0358e+01,  1.1474e+00],\n",
      "          [ 1.3553e+01,  1.6971e+01,  7.8502e+00],\n",
      "          [ 9.4789e+00,  1.1788e+01,  5.7109e+00]],\n",
      "\n",
      "         [[-6.6392e+00,  1.0325e+00,  5.3916e+00],\n",
      "          [-2.0417e+00,  2.5129e+00,  1.4224e+00],\n",
      "          [ 5.3363e+00,  9.6504e+00,  2.3759e+00]],\n",
      "\n",
      "         [[-3.7746e+00, -6.9748e+00, -1.0981e+01],\n",
      "          [-5.7494e+00, -5.7516e+00,  1.9877e+00],\n",
      "          [ 4.8878e+00, -1.0483e+00, -1.5323e+00]],\n",
      "\n",
      "         [[ 8.3991e+00,  7.3758e+00,  6.9483e-01],\n",
      "          [-5.0370e-01,  1.0043e+01, -1.5661e-01],\n",
      "          [-1.7905e+00, -1.5898e+00, -1.3787e+00]],\n",
      "\n",
      "         [[ 2.1383e+00,  1.2943e+01,  7.0721e-01],\n",
      "          [ 6.0177e+00, -2.0380e+00, -3.3859e+00],\n",
      "          [-5.7345e-01, -9.1295e+00, -9.5165e+00]],\n",
      "\n",
      "         [[ 1.2327e+01,  5.7455e+00, -2.6516e+00],\n",
      "          [ 5.7381e+00, -7.8672e+00, -3.8227e+00],\n",
      "          [ 2.1029e+00,  1.5264e+00, -3.1760e+00]],\n",
      "\n",
      "         [[-5.4040e+00, -9.4334e+00, -9.6561e+00],\n",
      "          [-3.3732e+00, -8.3494e+00, -7.0541e+00],\n",
      "          [-2.9421e-01, -6.9657e+00, -4.7243e+00]],\n",
      "\n",
      "         [[-6.6083e-01,  4.1577e+00,  1.0439e+01],\n",
      "          [-1.7464e+00,  6.5143e+00,  7.5378e+00],\n",
      "          [ 7.0832e-02,  3.4198e+00, -9.2248e-01]],\n",
      "\n",
      "         [[ 1.0044e+00,  4.6049e+00,  1.1955e+00],\n",
      "          [ 4.5212e+00, -1.7203e-01, -3.2786e+00],\n",
      "          [ 6.5324e+00, -2.1900e-03, -9.1479e+00]],\n",
      "\n",
      "         [[-7.8223e+00, -5.3046e-03, -8.2315e-01],\n",
      "          [ 1.9117e+00,  6.6971e+00,  1.9747e+00],\n",
      "          [ 1.1842e+01,  1.0832e+01,  9.0077e+00]],\n",
      "\n",
      "         [[ 2.0060e+00,  4.0044e+00,  3.6087e+00],\n",
      "          [ 7.1372e+00,  6.5923e+00, -9.6082e-01],\n",
      "          [ 4.7834e+00,  8.0507e+00,  7.4611e+00]],\n",
      "\n",
      "         [[-1.3594e+00,  4.9089e+00, -2.6031e-01],\n",
      "          [-6.3054e+00, -9.4204e+00,  2.3876e+00],\n",
      "          [-8.1818e+00, -5.6090e+00,  1.9469e+00]],\n",
      "\n",
      "         [[ 6.4556e+00,  1.5133e+01,  8.1501e+00],\n",
      "          [ 1.1768e+01,  8.8059e+00,  1.3763e+01],\n",
      "          [ 9.6549e+00,  4.6258e+00,  6.0580e+00]],\n",
      "\n",
      "         [[-9.8106e+00, -7.0389e+00,  2.5540e+00],\n",
      "          [-1.2352e+01, -1.6962e+01, -6.1246e+00],\n",
      "          [-1.5137e+01, -1.4014e+01, -1.4324e+01]],\n",
      "\n",
      "         [[-1.0515e+01, -3.5720e+00, -5.4189e+00],\n",
      "          [-2.3842e+00, -1.1493e+01, -9.2629e+00],\n",
      "          [-1.9724e+00, -5.7938e-01, -6.8444e+00]],\n",
      "\n",
      "         [[ 1.5699e+00, -5.4154e-01, -4.3305e+00],\n",
      "          [ 9.8684e-01, -8.5585e+00,  5.6663e-01],\n",
      "          [-3.3054e+00, -7.5892e+00, -6.2689e+00]],\n",
      "\n",
      "         [[ 8.4743e+00,  8.7301e+00,  1.5311e+00],\n",
      "          [ 5.2001e+00, -3.9543e+00, -6.1627e+00],\n",
      "          [ 6.9629e+00,  4.5263e-01,  4.4819e+00]],\n",
      "\n",
      "         [[ 1.8458e+00,  4.7003e+00,  1.5452e+01],\n",
      "          [ 3.1319e+00,  1.3936e+01,  9.1319e+00],\n",
      "          [ 8.9022e+00,  7.3387e+00,  5.8197e+00]],\n",
      "\n",
      "         [[ 1.2771e+01,  1.4898e+00, -4.1418e+00],\n",
      "          [ 1.3131e+01,  2.2502e+00, -5.4882e+00],\n",
      "          [ 1.0136e+00, -2.8761e+00, -1.5011e+00]],\n",
      "\n",
      "         [[ 1.2431e+00,  1.6483e+00, -3.9307e+00],\n",
      "          [ 1.6282e+00, -4.4497e-01, -2.0258e+00],\n",
      "          [ 4.1253e+00, -3.6479e+00, -8.2212e-01]],\n",
      "\n",
      "         [[ 8.7654e+00,  1.1373e+01,  1.2680e+01],\n",
      "          [ 9.8735e+00,  8.2289e+00,  9.3030e+00],\n",
      "          [ 4.7899e+00,  3.3438e+00,  1.3274e+01]],\n",
      "\n",
      "         [[-1.2854e+01, -1.2594e+01, -2.8448e+00],\n",
      "          [-6.5775e+00,  1.9210e-01,  1.1152e+00],\n",
      "          [-4.3130e+00,  2.8903e+00,  7.1117e-01]],\n",
      "\n",
      "         [[ 5.4331e+00,  6.4694e-01,  2.2074e-01],\n",
      "          [ 8.2765e+00,  8.5867e+00,  1.1131e+01],\n",
      "          [ 3.7019e+00, -3.1859e-01, -2.4731e+00]],\n",
      "\n",
      "         [[-1.3178e+01, -9.9554e+00, -1.1767e+01],\n",
      "          [-1.0278e+01, -9.5932e+00, -1.2342e+01],\n",
      "          [-5.0609e+00, -9.5404e+00, -1.8665e+00]],\n",
      "\n",
      "         [[ 6.7730e-01,  1.0042e+01,  9.6175e+00],\n",
      "          [-1.9441e+00,  4.5315e+00,  1.9249e+00],\n",
      "          [ 2.8057e-01,  1.3284e+00,  4.5271e+00]],\n",
      "\n",
      "         [[-4.8964e+00, -1.9346e+00, -1.0283e+01],\n",
      "          [-3.0094e+00, -1.3003e+01, -1.4780e+01],\n",
      "          [-1.3760e+01, -1.3550e+01, -8.5229e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6047e+00, -7.3884e-01,  1.3551e+01],\n",
      "          [ 3.6223e+00,  5.3254e+00,  1.4668e+01],\n",
      "          [ 4.0871e+00,  7.1577e+00,  1.2292e+01]],\n",
      "\n",
      "         [[ 8.6263e+00, -5.3601e+00, -3.9610e+00],\n",
      "          [ 1.4187e+00, -2.4955e+00, -9.8172e+00],\n",
      "          [-8.8111e+00, -7.5229e-01,  4.1888e+00]],\n",
      "\n",
      "         [[ 2.5077e+00, -7.9161e+00, -3.7695e+00],\n",
      "          [ 9.2876e-01, -1.1008e+01, -1.1948e+01],\n",
      "          [-4.9378e+00, -6.6643e+00, -8.5078e+00]],\n",
      "\n",
      "         [[-8.0954e+00, -1.2947e+01, -1.7904e+01],\n",
      "          [-4.6707e-01, -1.5804e+01, -1.3748e+01],\n",
      "          [-1.7783e+00, -6.3552e+00, -8.1114e+00]],\n",
      "\n",
      "         [[-2.1184e+00, -1.8313e+00, -2.4582e+00],\n",
      "          [ 4.4134e+00,  9.3000e+00,  2.1008e+00],\n",
      "          [ 1.3264e+01,  1.6818e+01,  1.4438e+01]],\n",
      "\n",
      "         [[ 3.0839e+00,  1.1935e+00,  2.3193e+00],\n",
      "          [ 4.8929e+00,  7.0598e+00,  7.0652e+00],\n",
      "          [ 2.3729e+00,  1.5318e+01,  2.0044e+00]],\n",
      "\n",
      "         [[ 5.9446e+00,  3.2566e+00,  1.5805e+00],\n",
      "          [ 1.3635e+01,  7.7481e+00,  6.7409e+00],\n",
      "          [ 1.1206e+01,  1.6691e+01,  1.2002e+01]],\n",
      "\n",
      "         [[-4.4276e+00, -4.8204e+00, -3.5936e+00],\n",
      "          [-6.3297e+00, -4.3057e-01, -8.7262e-01],\n",
      "          [-8.0288e-01,  9.6970e+00,  7.4679e+00]],\n",
      "\n",
      "         [[-9.1240e+00, -9.5453e+00, -6.6369e+00],\n",
      "          [-8.8295e+00, -7.1727e+00, -1.6203e+00],\n",
      "          [ 1.0565e+00,  2.4760e+00, -1.1719e+00]],\n",
      "\n",
      "         [[ 3.7123e+00,  2.9068e+00,  4.0652e+00],\n",
      "          [ 3.5694e+00,  5.0169e+00,  5.7890e+00],\n",
      "          [-2.3937e+00, -8.8178e-02,  4.9725e+00]],\n",
      "\n",
      "         [[ 2.6424e-01,  1.2250e+01,  8.1262e-01],\n",
      "          [-2.1852e+00,  1.0388e+01, -5.2863e-02],\n",
      "          [-7.3361e+00, -8.5632e+00, -1.2737e+01]],\n",
      "\n",
      "         [[ 1.1987e+01,  5.1389e+00, -3.3562e-01],\n",
      "          [ 8.1262e+00,  4.4373e+00, -3.8335e+00],\n",
      "          [ 3.3151e+00,  6.5910e+00,  1.7931e+00]],\n",
      "\n",
      "         [[-5.0276e+00, -1.0104e+01, -3.6271e+00],\n",
      "          [-1.3205e+01, -2.8657e+00, -1.0646e+01],\n",
      "          [-3.2976e+00, -5.3939e+00, -8.4897e+00]],\n",
      "\n",
      "         [[-2.6032e+00, -2.2180e+00,  9.2605e+00],\n",
      "          [-1.4976e+00,  6.4846e+00,  1.4091e+01],\n",
      "          [ 8.7707e+00,  7.0327e+00,  5.9579e+00]],\n",
      "\n",
      "         [[-1.3064e+00,  6.9880e+00,  3.4155e-01],\n",
      "          [-5.8306e-01,  3.2536e+00, -4.0354e-02],\n",
      "          [ 6.3339e+00,  8.9876e-01, -6.3275e+00]],\n",
      "\n",
      "         [[-6.5485e+00, -5.3973e+00, -3.3772e+00],\n",
      "          [-5.9393e+00, -9.0221e-01, -4.2650e+00],\n",
      "          [ 8.5019e+00,  1.0532e+01,  9.9411e+00]],\n",
      "\n",
      "         [[ 1.9782e+00,  3.2371e+00,  4.1912e+00],\n",
      "          [ 5.2203e+00, -2.5384e+00, -3.0426e-02],\n",
      "          [ 6.0901e+00,  1.2295e+01,  4.4337e+00]],\n",
      "\n",
      "         [[-5.5379e-01,  3.5056e+00,  2.9124e+00],\n",
      "          [-7.3302e+00, -6.1298e+00,  3.6303e+00],\n",
      "          [-1.1477e+01, -1.0580e+01,  4.4198e+00]],\n",
      "\n",
      "         [[ 5.0140e+00,  1.2207e+01,  1.1656e+01],\n",
      "          [ 8.0010e+00,  1.1849e+01,  1.7671e+01],\n",
      "          [ 3.7417e+00,  8.9745e+00,  9.6801e+00]],\n",
      "\n",
      "         [[-1.4136e+01, -8.6866e+00, -1.2813e+00],\n",
      "          [-1.9277e+01, -2.2596e+01, -1.4766e+00],\n",
      "          [-1.9439e+01, -1.5232e+01, -1.2537e+01]],\n",
      "\n",
      "         [[-1.1376e+01, -8.7493e+00, -8.7837e+00],\n",
      "          [-9.9992e+00, -1.5397e+01, -8.4326e+00],\n",
      "          [ 9.7542e-01, -3.2239e+00, -9.5764e+00]],\n",
      "\n",
      "         [[ 4.7668e+00,  1.8818e-01, -1.8402e+00],\n",
      "          [ 5.4049e+00, -5.5863e+00,  5.5788e-01],\n",
      "          [ 1.7888e+00, -9.4179e+00,  8.4233e-02]],\n",
      "\n",
      "         [[ 4.3913e+00,  7.5108e+00, -1.4728e+00],\n",
      "          [ 1.2413e+00,  1.0709e+00, -8.1921e+00],\n",
      "          [ 8.4713e-01, -2.4171e+00,  5.2994e+00]],\n",
      "\n",
      "         [[ 3.7249e+00,  2.4051e-02,  1.2007e+01],\n",
      "          [-7.6802e-01,  1.5362e+01,  8.8144e+00],\n",
      "          [ 7.5416e+00,  1.2706e+01,  1.0454e+01]],\n",
      "\n",
      "         [[ 1.0289e+01,  9.4594e+00,  3.5331e+00],\n",
      "          [ 1.4638e+01,  1.2071e+01, -6.8785e+00],\n",
      "          [ 3.8484e+00, -2.6836e-01, -9.7891e+00]],\n",
      "\n",
      "         [[-5.3179e+00,  3.9929e+00, -3.9179e+00],\n",
      "          [ 2.8482e+00, -9.0824e-01,  4.1371e-01],\n",
      "          [ 1.4239e+00, -5.6828e+00, -1.7142e+00]],\n",
      "\n",
      "         [[ 3.7275e+00,  1.4129e+01,  1.1769e+01],\n",
      "          [ 9.5122e+00,  1.2548e+01,  1.1275e+01],\n",
      "          [ 7.5099e+00,  3.9628e+00,  1.4818e+01]],\n",
      "\n",
      "         [[-8.9187e+00, -1.1220e+01, -4.6761e+00],\n",
      "          [-1.0532e+01, -7.3066e+00,  3.5394e-01],\n",
      "          [-5.2563e+00, -3.3762e+00,  1.6459e+00]],\n",
      "\n",
      "         [[ 3.4666e+00,  1.9505e+00,  3.1032e+00],\n",
      "          [ 4.0992e+00,  7.5455e+00,  7.3310e+00],\n",
      "          [ 7.7600e+00,  6.5864e+00,  1.2399e+00]],\n",
      "\n",
      "         [[-1.6519e+01, -7.2758e+00, -1.1837e+01],\n",
      "          [-1.0312e+01, -1.1195e+01, -7.9870e+00],\n",
      "          [-3.1562e+00, -1.3690e+01, -1.4919e+00]],\n",
      "\n",
      "         [[ 9.0969e-01,  1.4270e+01,  2.4964e+00],\n",
      "          [ 2.6022e+00,  5.8724e+00,  1.1947e+01],\n",
      "          [ 1.5210e+00,  4.3964e+00,  5.6000e+00]],\n",
      "\n",
      "         [[-5.7555e+00, -2.9475e+00, -5.3105e+00],\n",
      "          [-2.9881e+00, -1.6868e+01, -1.0241e+01],\n",
      "          [-1.5727e+01, -1.4173e+01, -1.3952e+01]]]],\n",
      "       grad_fn=<ConvolutionBackward0>) torch.Size([3, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"conv(x), conv(x)のサイズ: \\n\", conv(x), conv(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorchの勾配について, 最適化の方法編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PytorchのTensorには.data, .grad, .grad_fnという属性があります。<br>\n",
    "dataはテンソルそのものです。<br>gradは損失関数により計算される最適化のためにパラメーターを動かす方向を表します。backwardメソッドにより加算されます。<br>\n",
    "grad_fnはどのTensorを使ってどう作られたかを表すものです。自動微分の計算グラフ構築などに用いられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor.data:  tensor([1., 2., 3.])\n",
      "Tensor.grad:  None\n",
      "Tensor.grad_fn:  None\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1.,2.,3.]).to(torch.float32)\n",
    "a.requires_grad = True #勾配をTrueに\n",
    "print(\"Tensor.data: \", a.data)\n",
    "print(\"Tensor.grad: \",a.grad)\n",
    "print(\"Tensor.grad_fn: \",a.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まだ計算がなされていないので、Tensorのgradには勾配が計算されていない, ここで新たなTensorを制作し, <br>$(\\rm{Tensor1} - \\rm{Tensor2})^{2}$の平均を計算して勾配を計算してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = torch.pow(Tensor1-Tensor2, 2):  tensor(9., grad_fn=<MeanBackward0>)\n",
      "Tensor1.grad: \n",
      " tensor([-2., -2., -2.])\n",
      "Tensor2.grad: \n",
      " tensor([2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "b = torch.Tensor([4.,5.,6.]).to(torch.float32)\n",
    "b.requires_grad = True #勾配をTrueに\n",
    "loss = torch.pow(a-b, 2).mean()\n",
    "print(\"loss = torch.pow(Tensor1-Tensor2, 2): \", loss)\n",
    "loss.backward()\n",
    "print(\"Tensor1.grad: \\n\", a.grad)\n",
    "print(\"Tensor2.grad: \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算グラフはtorchvizのmake_dot関数で表示ができます。正しくモデルが制作できるか気になったら確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n -->\n<!-- Pages: 1 -->\n<svg width=\"226pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 226.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-322 222,-322 222,4 -4,4\"/>\n<!-- 140619004909904 -->\n<g id=\"node1\" class=\"node\">\n<title>140619004909904</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"136,-30.5 82,-30.5 82,0 136,0 136,-30.5\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-17\" font-family=\"monospace\" font-size=\"10.00\">Loss</text>\n<text text-anchor=\"middle\" x=\"109\" y=\"-5.75\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140618725366032 -->\n<g id=\"node2\" class=\"node\">\n<title>140618725366032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"156,-85.75 62,-85.75 62,-66.5 156,-66.5 156,-85.75\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-72.25\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140618725366032&#45;&gt;140619004909904 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140618725366032&#45;&gt;140619004909904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109,-66.18C109,-59.65 109,-50.45 109,-41.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-41.78 109,-31.78 105.5,-41.78 112.5,-41.78\"/>\n</g>\n<!-- 140618725366128 -->\n<g id=\"node3\" class=\"node\">\n<title>140618725366128</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-141 65,-141 65,-121.75 153,-121.75 153,-141\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-127.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140618725366128&#45;&gt;140618725366032 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140618725366128&#45;&gt;140618725366032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109,-121.58C109,-114.92 109,-105.49 109,-97.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-97.11 109,-87.11 105.5,-97.11 112.5,-97.11\"/>\n</g>\n<!-- 140618725365888 -->\n<g id=\"node4\" class=\"node\">\n<title>140618725365888</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-196.25 65,-196.25 65,-177 153,-177 153,-196.25\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-182.75\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140618725365888&#45;&gt;140618725366128 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140618725365888&#45;&gt;140618725366128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109,-176.83C109,-170.17 109,-160.74 109,-152.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-152.36 109,-142.36 105.5,-152.36 112.5,-152.36\"/>\n</g>\n<!-- 140618725366176 -->\n<g id=\"node5\" class=\"node\">\n<title>140618725366176</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-251.5 0,-251.5 0,-232.25 100,-232.25 100,-251.5\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140618725366176&#45;&gt;140618725365888 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140618725366176&#45;&gt;140618725365888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M60.01,-231.84C68.54,-224.15 81,-212.9 91.22,-203.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"93.06,-206.82 98.14,-197.52 88.37,-201.63 93.06,-206.82\"/>\n</g>\n<!-- 140618448840000 -->\n<g id=\"node6\" class=\"node\">\n<title>140618448840000</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"79,-318 21,-318 21,-287.5 79,-287.5 79,-318\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-304.5\" font-family=\"monospace\" font-size=\"10.00\">Tensor1</text>\n<text text-anchor=\"middle\" x=\"50\" y=\"-293.25\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 140618448840000&#45;&gt;140618725366176 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140618448840000&#45;&gt;140618725366176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50,-287.2C50,-279.87 50,-270.87 50,-262.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-262.95 50,-252.95 46.5,-262.95 53.5,-262.95\"/>\n</g>\n<!-- 140618725365792 -->\n<g id=\"node7\" class=\"node\">\n<title>140618725365792</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"218,-251.5 118,-251.5 118,-232.25 218,-232.25 218,-251.5\"/>\n<text text-anchor=\"middle\" x=\"168\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140618725365792&#45;&gt;140618725365888 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140618725365792&#45;&gt;140618725365888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.99,-231.84C149.46,-224.15 137,-212.9 126.78,-203.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"129.63,-201.63 119.86,-197.52 124.94,-206.82 129.63,-201.63\"/>\n</g>\n<!-- 140619004909184 -->\n<g id=\"node8\" class=\"node\">\n<title>140619004909184</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"197,-318 139,-318 139,-287.5 197,-287.5 197,-318\"/>\n<text text-anchor=\"middle\" x=\"168\" y=\"-304.5\" font-family=\"monospace\" font-size=\"10.00\">Tensor2</text>\n<text text-anchor=\"middle\" x=\"168\" y=\"-293.25\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 140619004909184&#45;&gt;140618725365792 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140619004909184&#45;&gt;140618725365792</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168,-287.2C168,-279.87 168,-270.87 168,-262.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-262.95 168,-252.95 164.5,-262.95 171.5,-262.95\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fe4592c9850>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "graph = make_dot(loss,params = {\"Tensor1\": a,\"Tensor2\": b, \"Loss\": loss})\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配計算を適用しているTensorの勾配計算を一時的に停止するには.detachメソッドを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1.detach():  tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor1.detach(): \", a.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with torch.no_grad():と書くことで, withブロックが適用される範囲では勾配計算が停止されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradが適用されている場合のTensor1 + Tensor2:  tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
      "gradが適用されていない場合のTensor1 + Tensor2:  tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "add1 = a + b\n",
    "with torch.no_grad():\n",
    "    add2 = a + b\n",
    "print(\"gradが適用されている場合のTensor1 + Tensor2: \", add1)\n",
    "print(\"gradが適用されていない場合のTensor1 + Tensor2: \", add2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では実際にモデルを定義して学習するところまでをやってみましょう。<br>今回はモデル定義編で制作したlinearクラスを使って学習していきましょう。<br>\n",
    "データはmake_moonsを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "data, label = make_moons(100)\n",
    "plt.scatter(data[label == 0][:,0],data[label == 0][:,1], s = 10, color = \"blue\")\n",
    "plt.scatter(data[label == 1][:,0],data[label == 1][:,1], s = 10, color = \"red\", marker = \"x\")\n",
    "plt.legend([\"label = 0\", \"label = 1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データとラベルのTensor化\n",
    "from torch import optim\n",
    "data = torch.Tensor(data)\n",
    "label = torch.Tensor(label).view(-1,1)\n",
    "data = (data - data.mean(axis = 0))/data.std(axis = 0) #平均で引いて標準偏差で割っておく。これで精度改善につながる。\n",
    "#モデル定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = linear(in_dim, hidden_dim)\n",
    "        self.relu = relu\n",
    "        self.l2 = linear(hidden_dim, out_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上位APIを使う場合のコードは以下の通りとなります。\n",
    "#class Net(nn.Module):\n",
    "#    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "#        super().__init__()\n",
    "#        self.l1 = nn.Linear(in_dim, hidden_dim)\n",
    "#        nn.init.uniform_(self.l1.weight, a = -np.sqrt(6/in_dim), b = np.sqrt(6/in_dim))\n",
    "#        self.relu = nn.ReLU()\n",
    "#        self.l2 = nn.Linear(hidden_dim, out_dim)\n",
    "#        nn.init.uniform_(self.l2.weight, a = -np.sqrt(6/hidden_dim), b = np.sqrt(6/hidden_dim))\n",
    "#        #自作したlinearはHe uniformで実装したのでnn.initで初期化の方法を指定してあげなければならない。\n",
    "#    def forward(self, x):\n",
    "#        x = self.l1(x)\n",
    "#        x = self.relu(x)\n",
    "#        x = self.l2(x)\n",
    "#        return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、学習のための最適化アルゴリズムと損失関数を決定します。<br>\n",
    "最適化アルゴリズムと損失関数は上位APIのものを用います。<br>\n",
    "損失関数のスクラッチ実装は簡単なのでここでは説明をしませんが、自作の最適化手法を制作する方法はAppendixに記します。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習で用いられる最適化の手法としては以下の記事などを参考にするのがおすすめです。<br>\n",
    "[【決定版】スーパーわかりやすい最適化アルゴリズム -損失関数からAdamとニュートン法-](https://qiita.com/omiita/items/1735c1d048fe5f611f80)<br>\n",
    "損失関数には今回は二値分類のためBinaryCrossEntropy(BCE)を用います。何故BCEを用いるのかに関しては、<br>\n",
    "「尤度関数の最大化」というワードについて調べてみると良いでしょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(2,30,1)\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  tensor(0.8100)\n",
      "acc:  tensor(0.8700)\n",
      "acc:  tensor(0.8800)\n",
      "acc:  tensor(0.8800)\n",
      "acc:  tensor(0.8800)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9200)\n",
      "acc:  tensor(0.9200)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9400)\n",
      "acc:  tensor(0.9400)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(data)\n",
    "    loss = criterion(y_pred, label) #ここ違うけどまあ\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            y_pred_label = torch.where(y_pred > 0.5, torch.ones_like(y_pred), torch.zeros_like(y_pred))\n",
    "            y_pred_label.to(torch.float32)\n",
    "            print(\"acc: \", (y_pred_label == label).sum() / len(y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初めての学習は喜んで欲しいので正解率が100%近くになるように工夫しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "### - BatchNormalization, Dropout, RNN, LSTMの低レベルAPI実装\n",
    "### - カスタムOptimizerの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendixで使うライブラリのimport\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNormalization, Dropout, RNN, LSTMの低レベルAPI実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNormalizationの実装<br>\n",
    "以下の画像の式に従って計算を行います。<br>\n",
    "![](https://standardfrancis.files.wordpress.com/2015/04/screenshot-from-2015-04-16-133436.png?w=1008)<br>\n",
    "画像元http://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/43442.pdf<br>\n",
    "ただし、上の式において```γとβは学習可能(もしくは学習対象)なパラメーター```であることに注意してパラメーターのモデル構築を行わなければいけません。<br>\n",
    "例えば線形層l1, l2という二つの層があったとき、一つのBN(BatchNormalization)層を(BN,l1,BN,l2)のように用いてはいけません。<br>\n",
    "このBN層ではl1の入力に関してγとβが最適化されてしまっているためです。もし2つの線形層に関してBN層を用いたい場合は<br>BN層をBN1, BN2のように別々に定義を行い、\n",
    "(BN1,l1,BN2,l2)のようにしなければいけません。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*実装上の注意\n",
    "- BatchNormalization2dの入力は(batch_size, Channel, Height, Width)を想定しています。<br>\n",
    "- meanとstdの計算において、torch.mean(Tensor, (0,2,3), keepdim = True)のように書きます<br>\n",
    "  これは、Pytorchの公式ドキュメントによると、二つ目の引数はdimensionを指定する引数であり、<br>\n",
    "  (0, 2, 3)の意味は入力されたバッチの画像全体の平均をチャンネルごとに求めるという意味です。<br>\n",
    "  keepdim=Trueにすることで計算の際にブロードキャスト機能を用いても大丈夫なようになっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mean, torch.stdの使い方にもう少し慣れておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.mean(Tensor, (0,2,3),keepdim=True):\n",
      " tensor([[[[0.5017]],\n",
      "\n",
      "         [[0.4989]],\n",
      "\n",
      "         [[0.4949]]]])\n",
      "torch.std(Tensor, (0,2,3),keepdim=True):\n",
      " tensor([[[[0.2896]],\n",
      "\n",
      "         [[0.2895]],\n",
      "\n",
      "         [[0.2904]]]])\n"
     ]
    }
   ],
   "source": [
    "#入力のサンプル\n",
    "x = torch.rand(32, 3 ,28, 28)\n",
    "print(\"torch.mean(Tensor, (0,2,3),keepdim=True):\\n\", torch.mean(x, (0,2,3),keepdim=True))\n",
    "print(\"torch.std(Tensor, (0,2,3),keepdim=True):\\n\", torch.std(x, (0,2,3),keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNormalizationの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization2d(nn.Module):\n",
    "    def __init__(self, shape, epsilon = 1e-10):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(shape).float())\n",
    "        self.beta = nn.Parameter(torch.zeros(shape).float())\n",
    "        self.epsilon = epsilon\n",
    "    def forward(self,x):\n",
    "        mean_x = torch.mean(x, (0,2,3), keepdim=True)\n",
    "        std_x = torch.std(x, (0,2,3), keepdim=True)\n",
    "        normalized_x = (x - mean_x) / torch.sqrt(std_x**2+self.epsilon)\n",
    "        return self.gamma * normalized_x + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropoutの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 過学習を抑制するためのレイヤーの一つです。\n",
    "- Dropoutは特定のレイヤーの出力を学習時にある確率`dropout_ratio`で0にすることで、データが欠損しても正しく認識ができるようにします。<br>これはモデルのロバスト性の向上に寄与します。<br>\n",
    "- 学習時は確率`dropout_ratio`で0にしたレイヤーを用いて学習を進めますが、推論時には全てのレイヤーの変数を使うため、<br>\n",
    "値の調整のために出力値には1 - dropout_ratioを乗算します。<br>\n",
    "- また、そのためにはレイヤーに訓練モードと推論モードを切り替える機能をつける必要があります。<br>これはnn.Moduleを継承することで実現できます。\n",
    "  nn.Moduleを継承したあとはself.trainingというattributeが追加されており、<br>これにより訓練モードか推論モードかを識別することができます。<br>\n",
    "  切り替える際は、trainメソッドやevalメソッドで切り替えることができます。<br>\n",
    "  詳しくは公式ドキュメントをご覧ください。https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-23_at_6.19.24_PM.png\" alt=\"\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropoutの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, dropout_ratio = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training: #self.trainingは訓練モードと推論モードを識別する変数(bool)\n",
    "            mask = torch.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * mask.to(x.device)\n",
    "        else:\n",
    "            return x * (1 - self.dropout_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout実行例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算元のテンソル: \n",
      " tensor([[[[0.7454, 0.2818, 0.6645, 0.3719, 0.2491],\n",
      "          [0.7464, 0.8656, 0.7901, 0.6560, 0.4790],\n",
      "          [0.4416, 0.3455, 0.8660, 0.2658, 0.0127],\n",
      "          [0.2627, 0.7956, 0.4877, 0.2442, 0.7255],\n",
      "          [0.5951, 0.6323, 0.2995, 0.3074, 0.1805]]]])\n",
      "訓練モードの場合の出力: \n",
      " tensor([[[[0.7454, 0.0000, 0.0000, 0.0000, 0.2491],\n",
      "          [0.0000, 0.0000, 0.7901, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8660, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.2442, 0.7255],\n",
      "          [0.0000, 0.0000, 0.2995, 0.3074, 0.1805]]]])\n",
      "推論モードの場合の出力: \n",
      " tensor([[[[0.3727, 0.1409, 0.3323, 0.1859, 0.1246],\n",
      "          [0.3732, 0.4328, 0.3951, 0.3280, 0.2395],\n",
      "          [0.2208, 0.1727, 0.4330, 0.1329, 0.0064],\n",
      "          [0.1313, 0.3978, 0.2438, 0.1221, 0.3627],\n",
      "          [0.2975, 0.3162, 0.1498, 0.1537, 0.0903]]]])\n"
     ]
    }
   ],
   "source": [
    "dropout = Dropout(dropout_ratio=0.5)\n",
    "x = torch.rand(1, 1, 5, 5)\n",
    "print(\"計算元のテンソル: \\n\", x)\n",
    "print(\"訓練モードの場合の出力: \\n\", dropout(x))\n",
    "dropout.eval() #推論モードに移行\n",
    "print(\"推論モードの場合の出力: \\n\", dropout(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNを実装する前に簡単なRNNの解説を行います。<br>\n",
    "RNNは系列データを扱うモデルである。<br>\n",
    "系列データとはデータの並び方に重要性があるデータである。<br>\n",
    "例えば株価の変化は時間と共に変動していくため、順序を入れ替えて処理をしてはならないし、<br>\n",
    "自然言語は文脈というものがあるので、順序を入れ替えて処理をしてはいけない。といったふうなものが系列データの例になります<br>\n",
    "RNNはこの前の状態からの影響を再帰的に行列演算する形で表現しています。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時刻$t$における入力を$x^{(t)}$、隠れ層を$h^{(t)}$, 出力を$o^{(t)}$とすると、<br>\n",
    "下の例はRNNの隠れ層から隠れ層への再帰を行うRNNになります。<br>\n",
    "他にも出力から隠れ層までの再帰、出力から出力までの再帰を行うRNNのアーキテクチャもあります。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/440px-Recurrent_neural_network_unfold.svg.png\" height = \"100%\" width = \"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の図の隠れ層から隠れ層までの再帰を行うRNNをもう少し数式的に理解を試みます。<br>\n",
    "$σ_{h}, σ_{o}$を隠れ層、出力の活性化関数, $b_{h}, b_{o}$を隠れ層、出力のバイアスベクトルとし、$W, V, U$を上の図の行列とすると、<br>\n",
    "時刻$t$における隠れ層と出力は以下のように計算できます。<br>\n",
    "$$\n",
    "h^{(t)} = σ_{h}(Vh^{(t-1)}+Ux^{(t)}+b_{h}) \\\\\n",
    "o^{(t)} = σ_{o}(Wh^{(t)}+b_{o})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理論的にはこの式で問題ないのですが、実装上は、<br>\n",
    "(batch_size, sequence_length, num_features)といった感じで、2次元目に系列長、3次元目に変数の数が追加されるため、<br>\n",
    "実際は、\n",
    "$$\n",
    "h^{(t)} = σ_{h}(h^{(t-1)}V^{T}+x^{(t)}U^{T}+b_{h}) \\\\\n",
    "o^{(t)} = σ_{o}(h^{(t)}W^{T}+b_{o})\n",
    "$$\n",
    "が計算されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式ドキュメントによると、内部では\n",
    "$$\n",
    "h^{(t)} =  σ_{h}(h^{(t-1)}{W_{hh}}^{T}+x^{(t)}{W_{ih}}^{T}+b_{ih}++b_{hh})\n",
    "$$\n",
    "のように計算されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このことを上位API torch.nn.RNNを用いて確かめます。<br>\n",
    "上位APIのRNNの引数の意味は<br>\n",
    "<br>\n",
    "input_size: 入力$x^{(t)}$の変数数<br>\n",
    "hidden_size: 隠れ層$h^{(t)}$の変数数<br>\n",
    "num_layers: 再帰層の数<br>\n",
    "batch_first: Trueだと入力は(batch, seq, feature)として扱われ、Falseだと(seq, batch, feature)として扱われる。<br>\n",
    "<br>\n",
    "また、デフォルトでの活性化関数はtanhとなっております。<br>\n",
    "nn.RNN.forwardの出力は出力系列yと、最終状態hとなっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 5).float()\n",
    "rnn = nn.RNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "Wih = rnn.weight_ih_l0.data\n",
    "Whh = rnn.weight_hh_l0.data\n",
    "bih = rnn.bias_ih_l0.data\n",
    "bhh = rnn.bias_hh_l0.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.RNNの出力: \n",
      " tensor([[[ 0.0426,  0.5924, -0.5697, -0.6111,  0.5253],\n",
      "         [-0.0548,  0.6242, -0.6449, -0.3825,  0.4418],\n",
      "         [ 0.0405,  0.6801, -0.4493, -0.3697,  0.6332]]],\n",
      "       grad_fn=<TransposeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(\"nn.RNNの出力: \\n\", rnn(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time t = 0\n",
      "隠れ層h: tensor([ 0.0426,  0.5924, -0.5697, -0.6111,  0.5253])\n",
      "time t = 1\n",
      "隠れ層h: tensor([-0.0548,  0.6242, -0.6449, -0.3825,  0.4418])\n",
      "time t = 2\n",
      "隠れ層h: tensor([ 0.0405,  0.6801, -0.4493, -0.3697,  0.6332])\n"
     ]
    }
   ],
   "source": [
    "for t in range(3):\n",
    "    print(f\"time t = {t}\")\n",
    "    x_t = x[0][t]\n",
    "    if t == 0:\n",
    "        h_t = torch.zeros_like(x_t)\n",
    "    h_t = torch.tanh(x_t @ Wih.transpose(0,1) + h_t @ Whh.transpose(0,1) + bih + bhh)\n",
    "    print(\"隠れ層h:\", h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各tにおける隠れ層の値がnn.RNNの0行目, 1行目, 2行目に当たることが確認できたと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの実装<br>\n",
    "今回は簡単のため、input_size, hidden_size, batch_firstをinitの引数とする1層のSimpleRNNを実装します。<br>\n",
    "本来のnn.RNNは他の引数もあります。是非公式ドキュメントをご覧ください。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first = False)->None:\n",
    "        \"\"\"\n",
    "        input_size: 入力x^{t}の変数数\n",
    "        hidden_size: 隠れ層h^{t}の変数数\n",
    "        num_layers: 再帰層の数\n",
    "        batch_first: Trueだと入力は(batch, seq, feature)として扱われ、Falseだと(seq, batch, feature)として扱われる。\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        公式ドキュメントにのっとり、weight, bias共にk = 1/hidden_sizeとした時、Uniform(-sqrt(k), sqrt(k))で初期化する。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        k = 1 / hidden_size\n",
    "        self.weight_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size, input_size))).float())\n",
    "        self.weight_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size, hidden_size))).float())\n",
    "        self.bias_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size))).float())\n",
    "        self.bias_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size))).float())\n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        実装上の注意点\n",
    "        h0がNoneなら系列の始めは隠れ層の値が0であることに注意すること\n",
    "        出力の形状に気をつけること今回はtorch.catで配列を結合し、unsqueezeメソッドなどを用いて次元を調整している。\n",
    "        同じ時間のものは計算に使う行列は共通のため、行列演算を用いて計算を早くしている。2重でforループを回すと遅い\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            #(seq, batch, feature)->(batch, seq, feature)へ\n",
    "            x = x.transpose(0,1)\n",
    "        sequence_length = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "        output_all = torch.empty(size = (batch_size, 0, self.input_size)).to(x.device)\n",
    "        final_hidden_state = torch.empty(size = (0 , self.input_size)).to(x.device)\n",
    "        if h0 == None:\n",
    "            h_t = torch.zeros_like(x[:,0,:]).to(x.device)\n",
    "        else:\n",
    "            h_t = h0.to(x.device)\n",
    "        for t in range(sequence_length):\n",
    "            h_t = torch.tanh(x[:,t,:] @ self.weight_ih_l0.transpose(0,1) + \\\n",
    "                h_t @ self.weight_hh_l0.transpose(0,1) + self.bias_hh_l0 + self.bias_ih_l0)\n",
    "            if t != 0:\n",
    "                output_all = torch.cat([output_all, h_t.reshape(-1,1,self.input_size)],dim = 1)\n",
    "            else:\n",
    "                output_all = h_t.reshape(-1,1,self.input_size)\n",
    "            #final_hidden_state = torch.cat([final_hidden_state, output[-1].unsqueeze(0)])\n",
    "        if not self.batch_first:\n",
    "            return output_all.transpose(0,1), output_all[:,-1,:].unsqueeze(0)\n",
    "        return output_all, output_all[:,-1,:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力があっているか一応確認しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータ\n",
    "x = torch.rand(3, 4, 5).float()\n",
    "simplernn = SimpleRNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "rnn = nn.RNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "#使う重みを等しくする\n",
    "simplernn.weight_ih_l0 = rnn.weight_ih_l0\n",
    "simplernn.weight_hh_l0 = rnn.weight_hh_l0\n",
    "simplernn.bias_ih_l0 = rnn.bias_ih_l0\n",
    "simplernn.bias_hh_l0 = rnn.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNNの自前実装: \n",
      "出力系列y: \n",
      "tensor([[[-0.7266,  0.4751,  0.1298,  0.0316, -0.4668],\n",
      "         [-0.3561,  0.6068, -0.2152, -0.4553, -0.4375],\n",
      "         [-0.5835,  0.6895, -0.0677, -0.1316, -0.4057],\n",
      "         [-0.4182,  0.7803,  0.0520, -0.5631, -0.6057]],\n",
      "\n",
      "        [[-0.5883,  0.7024,  0.2856, -0.1352, -0.5286],\n",
      "         [-0.3052,  0.6848, -0.2004, -0.3035, -0.3408],\n",
      "         [-0.4579,  0.7744,  0.0014, -0.3082, -0.6134],\n",
      "         [-0.5067,  0.7713, -0.0431, -0.2656, -0.3687]],\n",
      "\n",
      "        [[-0.7551,  0.5780,  0.2645, -0.2669, -0.6299],\n",
      "         [-0.2686,  0.6889, -0.0591, -0.1587, -0.2700],\n",
      "         [-0.5917,  0.5444, -0.2266, -0.1309, -0.4093],\n",
      "         [-0.3874,  0.8257,  0.0408, -0.5439, -0.6623]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "最終状態h: \n",
      "tensor([[[-0.4182,  0.7803,  0.0520, -0.5631, -0.6057],\n",
      "         [-0.5067,  0.7713, -0.0431, -0.2656, -0.3687],\n",
      "         [-0.3874,  0.8257,  0.0408, -0.5439, -0.6623]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "SimpleRNNの出力の形状: \n",
      "出力系列y: \n",
      "torch.Size([3, 4, 5])\n",
      "最終状態h: \n",
      "torch.Size([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimpleRNNの自前実装: \\n出力系列y: \\n{simplernn(x)[0]}\\n最終状態h: \\n{simplernn(x)[1]}\")\n",
    "print(f\"SimpleRNNの出力の形状: \\n出力系列y: \\n{simplernn(x)[0].shape}\\n最終状態h: \\n{simplernn(x)[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.RNN: \n",
      "出力系列y: \n",
      "tensor([[[-0.7266,  0.4751,  0.1298,  0.0316, -0.4668],\n",
      "         [-0.3561,  0.6068, -0.2152, -0.4553, -0.4375],\n",
      "         [-0.5835,  0.6895, -0.0677, -0.1316, -0.4057],\n",
      "         [-0.4182,  0.7803,  0.0520, -0.5631, -0.6057]],\n",
      "\n",
      "        [[-0.5883,  0.7024,  0.2856, -0.1352, -0.5286],\n",
      "         [-0.3052,  0.6848, -0.2004, -0.3035, -0.3408],\n",
      "         [-0.4579,  0.7744,  0.0014, -0.3082, -0.6134],\n",
      "         [-0.5067,  0.7713, -0.0431, -0.2656, -0.3687]],\n",
      "\n",
      "        [[-0.7551,  0.5780,  0.2645, -0.2669, -0.6299],\n",
      "         [-0.2686,  0.6889, -0.0591, -0.1587, -0.2700],\n",
      "         [-0.5917,  0.5444, -0.2266, -0.1309, -0.4093],\n",
      "         [-0.3874,  0.8257,  0.0408, -0.5439, -0.6623]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "最終状態h: \n",
      "tensor([[[-0.4182,  0.7803,  0.0520, -0.5631, -0.6057],\n",
      "         [-0.5067,  0.7713, -0.0431, -0.2656, -0.3687],\n",
      "         [-0.3874,  0.8257,  0.0408, -0.5439, -0.6623]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "nn.RNNの出力の形状: \n",
      "出力系列y: \n",
      "torch.Size([3, 4, 5])\n",
      "最終状態h: \n",
      "torch.Size([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.RNN: \\n出力系列y: \\n{rnn(x)[0]}\\n最終状態h: \\n{rnn(x)[1]}\")\n",
    "print(f\"nn.RNNの出力の形状: \\n出力系列y: \\n{rnn(x)[0].shape}\\n最終状態h: \\n{rnn(x)[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力の値と形状は同じになっていることがわかりました。しかし、grad_fnの表示が異なっているため、本当にカスタムなモデルを制作しない限りはnn.RNNを使った方が良さそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの実装の際も、RNNの実装と同じように内部ではどうなっているのかを理解しながら組んでいこうと思います。<br>\n",
    "一度RNNを組めてしまえばRNNに行列演算が少し追加された程度なので大丈夫なはずです。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://production-media.paperswithcode.com/methods/1_PJ5atpFStpNWE_XpB4e8qQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の画像によると、LSTMは入力$x_{t}$, $c_{t-1}$, $h_{t-1}$を受け取って$c_{t}, h_{t}$を出力するものであるとわかる。<br>\n",
    "$c_{t}, h_{t}$はinput $i_{t}$, forget $f_{t}$, cell $g_{t}$ output $o_{t}$を用いて次のように計算される。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "i_{t} = \\text{sigmoid}(W_{ii}x_{t}+b_{ii}+W_{hi}h_{t-1}+b_{hi}) \\\\\n",
    "f_{t} = \\text{sigmoid}(W_{if}x_{t}+b_{if}+W_{hf}h_{t-1}+b_{hf}) \\\\\n",
    "g_{t} = \\tanh(W_{ig}x_{t}+b_{ig}+W_{hg}h_{t-1}+b_{hg}) \\\\\n",
    "o_{t} = \\text{sigmoid}(W_{io}x_{t}+b_{io}+W_{ho}h_{t-1}+b_{ho}) \\\\\n",
    "c_{t} = f_{t} \\odot c_{t-1} + i_{t} \\odot g_{t} \\\\\n",
    "h_{t} = o_{t} \\odot \\tanh(c_{t}) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを1 epoch分計算してみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchでは例によって工夫がなされている。\n",
    "例えば、$x_{t}$が計算に使われるような行列を<br>$W_{ih} \\in M_{4hidden\\_size \\times input\\_size}$としてまとめて、\n",
    "$h_{t}$が計算に使われるような行列を$W_{hh}  \\in M_{4hidden\\_size \\times input\\_size} $としてまとめ、<br>\n",
    "それぞれのバイアスベクトルを$b_{ih}, b_{hh}$としてまとめた上で、まずは以下の量で定義される$z_{t}$を計算する。\n",
    "\n",
    "$$\n",
    "z_{t} = x_{t}W_{ih}^{T} + h_{t}W_{hh}^{T} + b_{ih} + b_{hh}\n",
    "$$\n",
    "$z_{t}$をもとめたあと、各量は以下の通りに計算される\n",
    "$$\n",
    "i_{t} = \\text{sigmoid}(z_t[:,:\\text{hidden\\_size}]) \\\\\n",
    "f_{t} = \\text{sigmoid}(z_t[:,\\text{hidden\\_size:2hidden\\_size}]) \\\\\n",
    "g_{t} = \\tanh(z_t[:,\\text{2hidden\\_size:3hidden\\_size}]) \\\\\n",
    "o_{t} = \\text{sigmoid}(z_t[:,\\text{3hidden\\_size:}]) \\\\\n",
    "c_{t} = f_{t} \\odot c_{t-1} + i_{t} \\odot g_{t} \\\\\n",
    "h_{t} = o_{t} \\odot \\tanh(c_{t}) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z_t$は何度も同じような計算をするところを、まとめて行ってくれているものである。\n",
    "このことを実際に確かめてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "x = torch.rand(2, 3, 5)\n",
    "lstm = nn.LSTM(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "w_ih = lstm.weight_ih_l0\n",
    "w_hh = lstm.weight_hh_l0\n",
    "b_ih = lstm.bias_ih_l0\n",
    "b_hh = lstm.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.LSTMの出力: h_t:\n",
      "tensor([[[ 0.0249,  0.0421,  0.0054,  0.0080, -0.0516],\n",
      "         [ 0.0220,  0.0737,  0.0240, -0.0036, -0.1153],\n",
      "         [-0.0239,  0.0521, -0.0511,  0.0394, -0.1665]],\n",
      "\n",
      "        [[ 0.0049,  0.0006, -0.0841, -0.0117, -0.0805],\n",
      "         [-0.0262,  0.0438, -0.0333, -0.0057, -0.1471],\n",
      "         [-0.0835,  0.0249, -0.0254,  0.0825, -0.1756]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "Last h_t and c_n:\n",
      "(tensor([[[-0.0239,  0.0521, -0.0511,  0.0394, -0.1665],\n",
      "         [-0.0835,  0.0249, -0.0254,  0.0825, -0.1756]]],\n",
      "       grad_fn=<StackBackward0>), tensor([[[-0.0424,  0.0830, -0.0928,  0.0838, -0.3851],\n",
      "         [-0.1523,  0.0411, -0.0561,  0.1630, -0.4261]]],\n",
      "       grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.LSTMの出力: h_t:\\n{lstm(x)[0]}\\nLast h_t and c_n:\\n{lstm(x)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0: \n",
      "h_t:\n",
      "tensor([[ 0.0249,  0.0421,  0.0054,  0.0080, -0.0516],\n",
      "        [ 0.0049,  0.0006, -0.0841, -0.0117, -0.0805]], grad_fn=<MulBackward0>)\n",
      "c_t:\n",
      "tensor([[ 0.0500,  0.0743,  0.0105,  0.0178, -0.1170],\n",
      "        [ 0.0081,  0.0010, -0.1529, -0.0243, -0.2009]], grad_fn=<AddBackward0>)\n",
      "time: 1: \n",
      "h_t:\n",
      "tensor([[ 0.0220,  0.0737,  0.0240, -0.0036, -0.1153],\n",
      "        [-0.0262,  0.0438, -0.0333, -0.0057, -0.1471]], grad_fn=<MulBackward0>)\n",
      "c_t:\n",
      "tensor([[ 0.0448,  0.1414,  0.0444, -0.0078, -0.2352],\n",
      "        [-0.0487,  0.0803, -0.0667, -0.0117, -0.3124]], grad_fn=<AddBackward0>)\n",
      "time: 2: \n",
      "h_t:\n",
      "tensor([[-0.0239,  0.0521, -0.0511,  0.0394, -0.1665],\n",
      "        [-0.0835,  0.0249, -0.0254,  0.0825, -0.1756]], grad_fn=<MulBackward0>)\n",
      "c_t:\n",
      "tensor([[-0.0424,  0.0830, -0.0928,  0.0838, -0.3851],\n",
      "        [-0.1523,  0.0411, -0.0561,  0.1630, -0.4261]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 5\n",
    "for t in range(3):\n",
    "    x_t = x[:,t,:]\n",
    "    if t == 0:\n",
    "        h_t = torch.zeros_like(x_t)\n",
    "        c_t = torch.zeros_like(x_t)\n",
    "    z_t = x_t @ w_ih.transpose(0,1) + h_t @ w_hh.transpose(0,1) + b_ih + b_hh\n",
    "    #W_ii|W_if|W_ig|W_io\n",
    "    i_t = torch.sigmoid(z_t[:,:hidden_size])\n",
    "    f_t = torch.sigmoid(z_t[:,hidden_size:2*hidden_size])\n",
    "    g_t = torch.tanh(z_t[:,2*hidden_size:3*hidden_size])\n",
    "    o_t = torch.sigmoid(z_t[:,3*hidden_size:])\n",
    "    c_t = f_t * c_t + i_t * g_t\n",
    "    h_t = o_t * torch.tanh(c_t)\n",
    "    print(f\"time: {t}: \\nh_t:\\n{h_t}\\nc_t:\\n{c_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に確かめられたら、あとはRNNのように実装するだけである。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの実装<br>\n",
    "今回も簡単のため、input_size, hidden_size, batch_firstをinitの引数とする1層のSimpleLSTMを実装します。<br>\n",
    "本来のnn.LSTMは他の引数もあります。是非公式ドキュメントをご覧ください。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first = False)->None:\n",
    "        \"\"\"\n",
    "        input_size: 入力x^{t}の変数数\n",
    "        hidden_size: 隠れ層h^{t}の変数数\n",
    "        num_layers: 再帰層の数\n",
    "        batch_first: Trueだと入力は(batch, seq, feature)として扱われ、Falseだと(seq, batch, feature)として扱われる。\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        公式ドキュメントにのっとり、weight, bias共にk = 1/hidden_sizeとした時、Uniform(-sqrt(k), sqrt(k))で初期化する。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        k = 1 / hidden_size\n",
    "        self.weight_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size, input_size))).float())\n",
    "        self.weight_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size, hidden_size))).float())\n",
    "        self.bias_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size))).float())\n",
    "        self.bias_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size))).float())\n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor = None, c0: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        実装上の注意点\n",
    "        h0がNoneなら系列の始めは隠れ層の値が0であることに注意すること\n",
    "        出力の形状に気をつけること今回はtorch.catで配列を結合し、unsqueezeメソッドなどを用いて次元を調整している。\n",
    "        同じ時間のものは計算に使う行列は共通のため、行列演算を用いて計算を早くしている。2重でforループを回すと遅い\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            #(seq, batch, feature)->(batch, seq, feature)へ\n",
    "            x = x.transpose(0,1)\n",
    "        sequence_length = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "        output_all = torch.empty(size = (batch_size, 0, self.input_size)).to(x.device)\n",
    "        if h0 == None and c0 == None:\n",
    "            h_t = torch.zeros_like(x[:,0,:]).to(x.device)\n",
    "            c_t = torch.zeros_like(x[:,0,:]).to(x.device)\n",
    "        elif h0 == None:\n",
    "            c_t = c0.to(x.device)\n",
    "        elif c0 == None:\n",
    "            h_t = h0.to(x.device)\n",
    "        else:\n",
    "            h_t = h0.to(x.device)\n",
    "            c_t = c0.to(x.device)\n",
    "        for t in range(sequence_length):\n",
    "            x_t = x[:,t,:]\n",
    "            z_t = x_t @ self.weight_ih_l0.transpose(0,1) + h_t @ self.weight_hh_l0.transpose(0,1) + self.bias_ih_l0 + self.bias_hh_l0\n",
    "            i_t = torch.sigmoid(z_t[:,:self.hidden_size])\n",
    "            f_t = torch.sigmoid(z_t[:,self.hidden_size:2*self.hidden_size])\n",
    "            g_t = torch.tanh(z_t[:,2*self.hidden_size:3*self.hidden_size])\n",
    "            o_t = torch.sigmoid(z_t[:,3*self.hidden_size:])\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            if t != 0:\n",
    "                output_all = torch.cat([output_all, h_t.reshape(-1,1,self.input_size)],dim = 1)\n",
    "            else:\n",
    "                output_all = h_t.reshape(-1,1,self.input_size)\n",
    "            #final_hidden_state = torch.cat([final_hidden_state, output[-1].unsqueeze(0)])\n",
    "        if not self.batch_first:\n",
    "            return output_all.transpose(0,1), (output_all[:,-1,:].unsqueeze(0), c_t.unsqueeze(0))\n",
    "        return output_all, (output_all[:,-1,:].unsqueeze(0), c_t.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく動作するか確かめてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3, 5)\n",
    "lstm = nn.LSTM(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "simplelstm = SimpleLSTM(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "simplelstm.weight_ih_l0 = lstm.weight_ih_l0\n",
    "simplelstm.weight_hh_l0 = lstm.weight_hh_l0\n",
    "simplelstm.bias_ih_l0 = lstm.bias_ih_l0\n",
    "simplelstm.bias_hh_l0 = lstm.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLSTMの自前実装: \n",
      "出力h_t: \n",
      "tensor([[[-0.0611,  0.0963, -0.0180, -0.0811,  0.1167],\n",
      "         [-0.1305,  0.1822, -0.0777, -0.0942,  0.1962],\n",
      "         [-0.1253,  0.0282,  0.0129, -0.2420,  0.1967]],\n",
      "\n",
      "        [[-0.0162,  0.0439,  0.1405, -0.1151,  0.0303],\n",
      "         [-0.0910,  0.1181,  0.1757, -0.1572,  0.0921],\n",
      "         [-0.0493,  0.1701,  0.2609, -0.1594,  0.0428]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "最終状態h_t and c_t: \n",
      "tensor([[[-0.1253,  0.0282,  0.0129, -0.2420,  0.1967],\n",
      "         [-0.0493,  0.1701,  0.2609, -0.1594,  0.0428]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[[-0.1738,  0.0431,  0.0179, -0.5630,  0.5865],\n",
      "         [-0.0785,  0.2818,  0.3721, -0.6279,  0.0902]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "SimpleLSTMの出力の形状: \n",
      "出力h_t: \n",
      "torch.Size([2, 3, 5])\n",
      "最終状態h_t and c_t: \n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimpleLSTMの自前実装: \\n出力h_t: \\n{simplelstm(x)[0]}\\n最終状態h_t and c_t: \\n{simplelstm(x)[1][0]}\\n{simplelstm(x)[1][1]}\")\n",
    "print(f\"SimpleLSTMの出力の形状: \\n出力h_t: \\n{simplelstm(x)[0].shape}\\n最終状態h_t and c_t: \\n{simplelstm(x)[1][0].shape}\\n{simplelstm(x)[1][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.LSTMの出力: \n",
      "出力h_t: \n",
      "tensor([[[-0.0611,  0.0963, -0.0180, -0.0811,  0.1167],\n",
      "         [-0.1305,  0.1822, -0.0777, -0.0942,  0.1962],\n",
      "         [-0.1253,  0.0282,  0.0129, -0.2420,  0.1967]],\n",
      "\n",
      "        [[-0.0162,  0.0439,  0.1405, -0.1151,  0.0303],\n",
      "         [-0.0910,  0.1181,  0.1757, -0.1572,  0.0921],\n",
      "         [-0.0493,  0.1701,  0.2609, -0.1594,  0.0428]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "最終状態h_t and c_t: \n",
      "tensor([[[-0.1253,  0.0282,  0.0129, -0.2420,  0.1967],\n",
      "         [-0.0493,  0.1701,  0.2609, -0.1594,  0.0428]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.1738,  0.0431,  0.0179, -0.5630,  0.5865],\n",
      "         [-0.0785,  0.2818,  0.3721, -0.6279,  0.0902]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "nn.LSTMの出力の形状: \n",
      "出力h_t: \n",
      "torch.Size([2, 3, 5])\n",
      "最終状態h_t and c_t: \n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.LSTMの出力: \\n出力h_t: \\n{lstm(x)[0]}\\n最終状態h_t and c_t: \\n{lstm(x)[1][0]}\\n{lstm(x)[1][1]}\")\n",
    "print(f\"nn.LSTMの出力の形状: \\n出力h_t: \\n{lstm(x)[0].shape}\\n最終状態h_t and c_t: \\n{lstm(x)[1][0].shape}\\n{lstm(x)[1][1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以上までで、LSTMの自前実装が完了しました。双方向LSTMなどの実装が残っていることを除けば、\n",
    "##### Attentionのスクラッチ実装まであともう少しです。\n",
    "##### レイヤーの実装の続きはAttention_from_scratch.ipynbで行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタムOptimizerの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤーに比べてOptimizerの実装の優先度は低いかもしれませんが、<br>\n",
    "それでも勉強していて新しいOptimizerのアイデアが浮かぶことがあるかもしれません。<br>\n",
    "例えば、Github上で「SAM」などと検索するとSAMと呼ばれるOptimizerの実装を見ることができます。<br>\n",
    "自分でOptimizerを設計したくなった時に困らないようにカスタムOptimizerの実装も解説していきます。<br>\n",
    "カスタムOptimizerは日本語記事がほとんどヒットしません。検索する際は公式ドキュメントや英語検索を行うと良いでしょう。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤーの制作の際はnn.Moduleの継承を行いました。Optimizerはtorch.optim.Optimizerの継承を行います。<br>\n",
    "nn.Moduleでは主にinitとforwardのオーバーライドを行いました。optim.optimizerではinitとstepのオーバーライドを行います。<br>\n",
    "- initの引数<br>\n",
    "  ```params```: 最適化するパラメータ-をまとめるもの(iterableでなければならない)、model.parameters()で渡すものだと考えてください。<br>\n",
    "  ```他のパラメーター```: 学習率やOptimizerによっては他のパラメーターがあると思いますが、それにあたります。<br><br>\n",
    "- initの実装上の注意点<br>\n",
    "  initメソッドではパラメータ-が正当なものかを判別する例外処理を書く必要があることもあります。<br>\n",
    "  Optimizerクラスを継承する時にはparamsに加えてlrのなどのパラメーターがまとめられたものを辞書型で渡して継承しなければいけません。<br><br>\n",
    "- stepの引数<br>\n",
    "  ```closure```: Conjugate GradientやLBFGSのような最適化アルゴリズムでは関数を何度も再評価するので必要になるらしいですが、おそらく滅多に使うことはないかと思われます。<br><br>\n",
    "- stepの実装上の注意点<br>\n",
    "  stepを実行した時点でParametersの勾配(grad)は計算されているものとします。<br>計算済みのgradを使って最適化の処理を書くところがstepと考えて良いでしょう。<br>\n",
    "  optimizerが処理するパラメーターはself.param_groupsにOptimizerクラスを継承した際に入れられています。<br>\n",
    "  params_groupsは辞書を要素としたリストであり、モデルのパラメーターを個別の要素に分割する方法を提供します。<br>\n",
    "  例えば、異なる学習率を使用してネットワークの別々のレイヤーをトレーニングする場合などはこれが使われます。<br>\n",
    "  [Pytorchの公式ドキュメント](https://pytorch.org/docs/stable/optim.html)では以下のように使用例があります。<br>\n",
    "  ```\n",
    "  optim.SGD([\n",
    "                {'params': model.base.parameters()},\n",
    "                {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "            ], lr=1e-2, momentum=0.9)\n",
    "  ```\n",
    "  <br>\n",
    "  params_groupの要素となっている辞書は, {\"params\":, \"lr\":, \"momentum\":, }のように、<br>\n",
    "  Optimizerの継承の時に使用したパラメーターなどを保存しています。<br>\n",
    "  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はMomentumSGDの実装を行います。\n",
    "MomentumSGDは以下の式で定義されます。\n",
    "$$\n",
    "\\text{w}^{t+1} = \\text{w}^{t} - η\\dfrac{\\partial E(\\text{w}^t)}{\\partial \\text{w}^t} + \\alpha Δ\\text{w}^t\n",
    "$$\n",
    "$$\n",
    "Δ\\text{w}^{t+1} = - η\\dfrac{\\partial E(\\text{w}^t)}{\\partial \\text{w}^t} + \\alpha Δ\\text{w}^t\n",
    "$$\n",
    "デフォルトで$η=0.001, \\alpha = 0.9$として実装を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum付きSGDの実装\n",
    "<br><br>\n",
    "あとで比較のために普通のSGDも記しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumSGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr = 0.001, momentum = 0.9) -> None:\n",
    "        if lr < 0:\n",
    "            raise ValueError(f\"Invalid learning rate: lr should be >= 0\")\n",
    "        if momentum < 0:\n",
    "            raise ValueError(f\"Invalid momentum rate: momentum should be >= 0\")\n",
    "        defaults = dict(lr = lr, momentum = momentum)\n",
    "        super(MomentumSGD, self).__init__(params, defaults)\n",
    "        self.state = dict()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                #stateの初期化\n",
    "                self.state[p] = dict(momentum=torch.zeros_like(p.data))\n",
    "    def step(self, closure = None) -> None:\n",
    "        \"\"\"\n",
    "        parameterのgradはbackwardメソッドで計算済みと考える。\n",
    "        更新するパラメーターのt時点での値をW^{t}と表すと、\n",
    "        W^{t+1} <- W^{t} - lr * W.grad.data + d_W^{t} * momentum\n",
    "        d_W^{t} <- W^{t+1} - W^{t} =  - lr * W.grad.data + d_W^{t} * momentum\n",
    "        の式を用いて更新する。\n",
    "        \"\"\"\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p not in self.state:\n",
    "                    self.state[p] = dict(momentum=torch.zeros_like(p.data))\n",
    "                mom = self.state[p]['momentum']\n",
    "                d_p = - group['lr'] * p.grad.data + group[\"momentum\"] * mom\n",
    "                p.data += d_p\n",
    "                self.state[p]['momentum'] = d_p\n",
    "\n",
    "class NormalSGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr = 0.001) -> None:\n",
    "        if lr < 0:\n",
    "            raise ValueError(f\"Invalid learning rate: lr should be >= 0\")\n",
    "        defaults = dict(lr = lr)\n",
    "        super(NormalSGD, self).__init__(params, defaults)\n",
    "    def step(self, closure = None) -> None:\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                d_p = - group['lr'] * p.grad.data\n",
    "                p.data += d_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応、上手く動作するかを確認しておきましょう。<br>\n",
    "$y = 5x+1$上にデータが載っている場合の最適化を考えます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#実験のためにデータを定義\n",
    "l1 = nn.Linear(1,1)\n",
    "l2 = nn.Linear(1,1)\n",
    "x = torch.arange(10).view(-1,1).float()\n",
    "y = 5*x+10\n",
    "sgd_mom = MomentumSGD(l1.parameters(), lr = 0.01)\n",
    "sgd = NormalSGD(l2.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum付きとMomentum無しの損失も観察してみましょう。この際、ただしくMomentumが動作しているかも確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20, loss_mom: 230.64793395996094, loss: 8.204264640808105\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[9.8956]], requires_grad=True): {'momentum': tensor([[0.4451]])}, Parameter containing:\n",
      "tensor([-3.7151], requires_grad=True): {'momentum': tensor([-0.1342])}}\n",
      "\n",
      "epoch: 40, loss_mom: 6.582394599914551, loss: 19.606168746948242\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.0933]], requires_grad=True): {'momentum': tensor([[0.1665]])}, Parameter containing:\n",
      "tensor([-4.2631], requires_grad=True): {'momentum': tensor([0.2575])}}\n",
      "\n",
      "epoch: 60, loss_mom: 28.049381256103516, loss: 17.275157928466797\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[6.8353]], requires_grad=True): {'momentum': tensor([[-0.0724]])}, Parameter containing:\n",
      "tensor([1.5763], requires_grad=True): {'momentum': tensor([0.4310])}}\n",
      "\n",
      "epoch: 80, loss_mom: 8.380489349365234, loss: 14.117976188659668\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[4.9406]], requires_grad=True): {'momentum': tensor([[0.3057]])}, Parameter containing:\n",
      "tensor([8.0550], requires_grad=True): {'momentum': tensor([0.1748])}}\n",
      "\n",
      "epoch: 100, loss_mom: 5.191126823425293, loss: 10.861875534057617\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.3314]], requires_grad=True): {'momentum': tensor([[-0.2258]])}, Parameter containing:\n",
      "tensor([8.8218], requires_grad=True): {'momentum': tensor([-0.0385])}}\n",
      "\n",
      "epoch: 120, loss_mom: 6.800321578979492, loss: 6.862704277038574\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[4.8744]], requires_grad=True): {'momentum': tensor([[0.2261]])}, Parameter containing:\n",
      "tensor([8.4182], requires_grad=True): {'momentum': tensor([-0.0022])}}\n",
      "\n",
      "epoch: 140, loss_mom: 3.4762001037597656, loss: 2.878584384918213\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.4667]], requires_grad=True): {'momentum': tensor([[-0.1102]])}, Parameter containing:\n",
      "tensor([8.0529], requires_grad=True): {'momentum': tensor([-0.0276])}}\n",
      "\n",
      "epoch: 160, loss_mom: 0.7750384211540222, loss: 1.4716582298278809\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.0849]], requires_grad=True): {'momentum': tensor([[-0.0706]])}, Parameter containing:\n",
      "tensor([8.5529], requires_grad=True): {'momentum': tensor([0.0519])}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(175):\n",
    "    y_pred_mom = l1(x)\n",
    "    y_pred = l2(x)\n",
    "    loss_mom = ((y_pred_mom-y)**2).std()\n",
    "    loss_mom.backward()\n",
    "    loss = ((y_pred-y)**2).std()\n",
    "    loss.backward()\n",
    "    sgd_mom.step()\n",
    "    sgd_mom.zero_grad()\n",
    "    sgd.step()\n",
    "    sgd.zero_grad()\n",
    "\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(f\"\\nepoch: {i+1}, loss_mom: {loss_mom.item()}, loss: {loss.item()}\")\n",
    "        print(\"\\nこの時のMomentumのパラメーターの状態\\n\", sgd_mom.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x.numpy(),l1(x).detach().numpy(),marker = \"x\")\n",
    "plt.scatter(x.numpy(),l2(x).detach().numpy(),marker = \"v\")\n",
    "plt.plot(x.numpy(),y.numpy())\n",
    "plt.legend([\"Momentum\", \"Non Momentum\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix2\n",
    "Pytorchを普通の最適化に使えないか?\n",
    "例えば$y = \\dfrac{1}{x+10} + 5$という関数を<br>\n",
    "学習可能なパラメーターa, bをもちいて$y = \\dfrac{1}{x+a} + b$を用いてaとbを求めるように計算を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(50, dtype = \"float32\")\n",
    "y = 1/(x + 10) + 5. + np.random.uniform(size = 50, low = -0.01, high = 0.01)\n",
    "y = y.astype(\"float32\")\n",
    "plt.scatter(x,y,color = \"red\", marker = \"x\")\n",
    "plt.legend([\"y = $\\dfrac{1}{x+10}+5+error$\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoaderとパラメーターの定義\n",
    "from torch.utils.data import TensorDataset\n",
    "x_train = torch.from_numpy(x).view(-1,1)\n",
    "y_train = torch.from_numpy(y).view(-1,1)\n",
    "train_dl = TensorDataset(x_train, y_train)\n",
    "a = torch.ones(1, requires_grad=True).to(torch.float32)\n",
    "b = torch.ones(1, requires_grad=True).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(a)\n",
    "        self.b = nn.Parameter(b)\n",
    "    def forward(self,x):\n",
    "        return 1/(x+self.a) + self.b\n",
    "model = Model(a,b)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, loss: 6.456416303990409e-05\n",
      "epoch: 400, loss: 0.00013196228246670216\n",
      "epoch: 600, loss: 0.00013139322982169688\n",
      "epoch: 800, loss: 0.00013140415831003338\n",
      "epoch: 1000, loss: 0.00013138230133336037\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "best_score = 100\n",
    "for epoch in range(epochs):\n",
    "    for x_b, y_b in train_dl:\n",
    "        pred = model(x_b)\n",
    "        loss = criterion(pred, y_b)\n",
    "        loss.backward()\n",
    "        if loss.item() < best_score:\n",
    "            best_params = model.parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"epoch: {epoch+1}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(0,49, num = 200).astype(\"float32\")\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_test.detach().numpy(), y_test.detach().numpy())\n",
    "plt.scatter(x,y,color = \"red\", marker = \"x\")\n",
    "plt.legend([\"Prediction\",\"y = $\\dfrac{1}{x+10}+5+error$\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchが最適計算に使えることもわかった。<br>\n",
    "Pytorchの本質はこのようにモデルと損失関数を定義してさえしまえばあとは勝手に計算を行ってくれることであるとわかる。<br>\n",
    "従って、理論式があるようなデータを扱う時は理論に沿ってモデルを立てた方が変なモデルを作るよりもいい結果を導いてくれることがわかる。<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e2ef60554f914b7f3190499c85ea0c48ae4fc01e8f403cc646d16228abbf679"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
