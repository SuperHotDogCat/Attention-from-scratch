{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch基礎\n",
    "Pytorchを使う上で一番ネックになるのはPytorchの文法、classの仕様などを詳しく知らないことです。\n",
    "<br>\n",
    "それを解説するipynbファイルを制作しました。<br>\n",
    "基本コマンド編は適宜既知の内容を読み飛ばして使用ください<br>\n",
    "目次\n",
    "- 基本コマンド\n",
    "- Dataloader定義\n",
    "- モデル定義\n",
    "- Pytorchの勾配について, 最適化の方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本コマンド編"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#警告の非表示\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの作り方<br>\n",
    "Pythonデフォルトにもあるリストからtorch.tensorで作る方法とnumpyのndarrayを使ってtorch.tensorかfrom_numpyから作る方法の二通りがある<br>\n",
    "引数にdtypeを加えることで型を変更することができる。<br>\n",
    "基本的にPytorchで使う方はfloat32型である。tensor.float()とすることでfloat32型の変換を行うこともできる。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonのリストから制作 tensor([1, 2, 3])\n",
      "Pythonのnumpyからtorch.tensorで制作 tensor([1, 2, 3])\n",
      "Pythonのnumpyからtorch.from_numpyで制作 tensor([1, 2, 3])\n",
      "dtypeを引数にすることで型をfloatへ tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = [1,2,3]\n",
    "b = np.array([1,2,3])\n",
    "print(\"Pythonのリストから制作\",torch.tensor(a))\n",
    "print(\"Pythonのnumpyからtorch.tensorで制作\",torch.tensor(b))\n",
    "print(\"Pythonのnumpyからtorch.from_numpyで制作\",torch.from_numpy(b))\n",
    "print(\"dtypeを引数にすることで型をfloatへ\", torch.tensor(a, dtype = torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全成分が0と1のTensorの制作<br>\n",
    "torch.zeros, torch.onesはtorch.zeros(d1,d2,...dn)のようにn次元目の要素数を指定して制作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.zerosで制作(3,3)Tensor\n",
      " torch.Size([3, 3]) \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.onesで制作(3,3)Tensor\n",
      " torch.Size([3, 3]) \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,3)\n",
    "b = torch.ones(3,3)\n",
    "print(\"torch.zerosで制作(3,3)Tensor\\n\", a.shape, \"\\n\", a)\n",
    "print(\"torch.onesで制作(3,3)Tensor\\n\", b.shape, \"\\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乱数Tensorの作成<br>\n",
    "0から1までの一様分布ならば<br>\n",
    "torch.randはtorch.rand(d1,d2,...dn)のようにn次元目の要素数を指定して制作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.randで制作(3,3)Tensor\n",
      " torch.Size([3, 3]) \n",
      " tensor([[0.1493, 0.4873, 0.4839],\n",
      "        [0.0998, 0.0131, 0.1331],\n",
      "        [0.0270, 0.1556, 0.7052]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "print(\"torch.randで制作(3,3)Tensor\\n\", a.shape, \"\\n\", a)\n",
    "#他にも, torch.randnで正規分布の乱数の生成, torch.bernoulliでベルヌーイ分布の乱数の生成, torch.multinominalで多項分布の乱数の生成が行われる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値を指定して行列を作るのはtorch.full関数を用いる<br>\n",
    "torch.fullはtorch.full(size = (tuple or list), fill_value = (int, float))のように指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.fullで制作\n",
      " tensor([[100, 100, 100],\n",
      "        [100, 100, 100],\n",
      "        [100, 100, 100]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.full(size = (3,3), fill_value = 100)\n",
    "print(\"torch.fullで制作\\n\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単位行列はtorch.eyeで制作する引数には次元数を指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.eyeで制作, 3d対角行列\n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.eye(3)\n",
    "print(\"torch.eyeで制作, 3d対角行列\\n\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等差数列のTensorを作成<br>\n",
    "torch.arrange(start = Number, end = Number, step = Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始: 0, 終了: 100, step: 2\n",
      " tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
      "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70,\n",
      "        72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98])\n"
     ]
    }
   ],
   "source": [
    "print(\"開始: 0, 終了: 100, step: 2\\n\",torch.arange(start = 0, end = 100, step = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorのデータ型と形状を操作する<br>\n",
    "データ型を変更するのは制作したTensorにtoメソッドを使用します。<br>\n",
    "形状指定は転置にはtransposeメソッド, 形状変更はreshapeかviewメソッド, <br>サイズが1の次元を追加するのはunsqueezeメソッドサイズが1の次元を削除はsqueezeメソッドを使う<br>\n",
    "指定された順に次元を入れ替えるにはtorch.permuteメソッドを用いる<br>\n",
    "各関数, メソッドの引数は<br>\n",
    "tensor.transpose(転置する次元1つ目,転置する次元2つ目)<br>\n",
    "tensor.reshape(d1,d2,d3,...dn)<br>\n",
    "tensor.unsqueeze(追加するサイズ1の次元)<br>\n",
    "tensor.squeeze(削除するサイズ1の次元)<br>\n",
    "tensor.permute(d1, d2, ..., dn)<br>\n",
    "のように用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor\n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "転置\n",
      " tensor([[[1],\n",
      "         [4]],\n",
      "\n",
      "        [[2],\n",
      "         [5]],\n",
      "\n",
      "        [[3],\n",
      "         [6]]]) torch.Size([3, 2, 1])\n",
      "形状変更 reshape\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]]) torch.Size([6, 1])\n",
      "形状変更 view\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]]) torch.Size([6, 1])\n",
      "サイズが1の次元を追加\n",
      " tensor([[[[1]],\n",
      "\n",
      "         [[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]],\n",
      "\n",
      "         [[6]]]]) torch.Size([2, 3, 1, 1])\n",
      "サイズが1の次元を削除\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n",
      "次元の入れ替え\n",
      " tensor([[[1, 4],\n",
      "         [2, 5],\n",
      "         [3, 6]]]) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1],[2],[3]],[[4],[5],[6]]])\n",
    "print(\"元のTensor\\n\", a, a.shape)\n",
    "print(\"転置\\n\", a.transpose(0,1),a.transpose(0,1).shape)\n",
    "print(\"形状変更 reshape\\n\", a.reshape(-1,1),a.reshape(-1,1).shape) \n",
    "#numpyを使い慣れている人ならわかるように、引数に-1を指定すると, 0以上で指定した次元のサイズをいい感じに整えてくれます、\n",
    "print(\"形状変更 view\\n\", a.reshape(-1,1),a.view(-1,1).shape)\n",
    "# a.viewでエラーが出ることがある場合は.contiguous()を呼んでからview()する(https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930)\n",
    "print(\"サイズが1の次元を追加\\n\", a.unsqueeze(2), a.unsqueeze(2).shape)\n",
    "print(\"サイズが1の次元を削除\\n\", a.squeeze(2), a.squeeze(2).shape)\n",
    "print(\"次元の入れ替え\\n\", a.permute(2,1,0), a.permute(2,1,0).shape) \n",
    "#指定するのは次元, 今回は元の行列の3次元目(2)を1次元目(0),2次元目(1)を2次元目(1), 1次元目(0)を3次元目(2)にしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squeezeとunsqueezeはよく使うため詳しく解説しておく。<br>\n",
    "tensor.squeeze(num): num次元目のサイズが1ならばその次元を消す。サイズが1でなければ消さない<br>\n",
    "tensor.unsqueeze(num): num次元目に次元を増やしてサイズを1とする。<br>\n",
    "増やし方は、<br>\n",
    "$(d_0, d_1, d_{num}, d_{num+1}, d_n) -> (d_0, d_1, d_{num},1, d_{num+1}, d_n)$<br>\n",
    "と言った感じである。$num \\gt n$のときはエラーとなる。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.squeeze(0): \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.squeeze(1): \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.squeeze(2): \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1],[2],[3]],[[4],[5],[6]]])\n",
    "print(\"元のTensor: \\n\", a, a.shape)\n",
    "print(\"tensor.squeeze(0): \\n\", a.squeeze(0), a.squeeze(0).shape)\n",
    "print(\"tensor.squeeze(1): \\n\", a.squeeze(1), a.squeeze(1).shape)\n",
    "print(\"tensor.squeeze(2): \\n\", a.squeeze(2), a.squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]]) torch.Size([2, 3, 1])\n",
      "tensor.unsqueeze(0):\n",
      " tensor([[[[1],\n",
      "          [2],\n",
      "          [3]],\n",
      "\n",
      "         [[4],\n",
      "          [5],\n",
      "          [6]]]]) torch.Size([1, 2, 3, 1])\n",
      "tensor.unsqueeze(1):\n",
      " tensor([[[[1],\n",
      "          [2],\n",
      "          [3]]],\n",
      "\n",
      "\n",
      "        [[[4],\n",
      "          [5],\n",
      "          [6]]]]) torch.Size([2, 1, 3, 1])\n",
      "tensor.unsqueeze(2):\n",
      " tensor([[[[1]],\n",
      "\n",
      "         [[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]],\n",
      "\n",
      "         [[6]]]]) torch.Size([2, 3, 1, 1])\n",
      "tensor.unsqueeze(3):\n",
      " tensor([[[[1]],\n",
      "\n",
      "         [[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]],\n",
      "\n",
      "         [[6]]]]) torch.Size([2, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"元のTensor: \\n\", a, a.shape)\n",
    "print(\"tensor.unsqueeze(0):\\n\", a.unsqueeze(0), a.unsqueeze(0).shape)\n",
    "print(\"tensor.unsqueeze(1):\\n\", a.unsqueeze(1), a.unsqueeze(1).shape)\n",
    "print(\"tensor.unsqueeze(2):\\n\", a.unsqueeze(2), a.unsqueeze(2).shape)\n",
    "print(\"tensor.unsqueeze(3):\\n\", a.unsqueeze(3), a.unsqueeze(3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorでの算術演算<br>\n",
    "基本的にはnumpyと同じなので使い慣れている人には大丈夫なはずです。<br>\n",
    "Broadcastなどの仕様を知らない場合は理解しておきましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明に使うTensorの定義\n",
    "a = torch.tensor([[1.,2.,3.],[4.,5.,6.]]) #size (2,3)のTensor\n",
    "b = torch.tensor([[1.,2.],[3.,4.],[5.,6.]]) #size (3,2)のTensor\n",
    "c = 10. #スカラー\n",
    "d = torch.tensor([1.,2.,3.]) #size (3)のTensor\n",
    "e = torch.tensor([[7.,8.,9.],[1.,2.,3.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列の要素積(アダマール積)<br>\n",
    "行列の要素ごとの計算はtorch.multiply関数か、<br>Pythonの演算記号*を用いるものの2通りがあります。<br>どちらも同じ計算結果となります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.multiplyの計算結果\n",
      " tensor([[ 7., 16., 27.],\n",
      "        [ 4., 10., 18.]])\n",
      "*での計算結果\n",
      " tensor([[ 7., 16., 27.],\n",
      "        [ 4., 10., 18.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.multiplyの計算結果\\n\", torch.multiply(a,e))\n",
    "print(\"*での計算結果\\n\", a*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列積<br>\n",
    "線形代数でよく使われる行列の積です。<br>\n",
    "torch.matmulもしくは@記号で計算ができます。<br>\n",
    "torch.dotでの計算も可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.multiplyの計算結果\n",
      " tensor([[22., 28.],\n",
      "        [49., 64.]])\n",
      "@での計算結果\n",
      " tensor([[22., 28.],\n",
      "        [49., 64.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.multiplyの計算結果\\n\", torch.matmul(a,b))\n",
    "print(\"@での計算結果\\n\", a@b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三階以上のTensorの掛け算には<br>\n",
    "torch.bmm(Tensor1, Tensor2)(batch matrix matrix product)や、torch.einsumを用いる方が良いです。<br>\n",
    "torch.bmmは3階のテンソルで、それぞれが(b, n, m)と(b, m, p)のsizeを有する場合に(b, n, p)のテンソルを出力します。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### einsum, bmm共にattentionの実装において\n",
    "##### pythonに組み込まれているfor文を使わずに効率よくバッチごとの計算を行うために必要な関数です。\n",
    "##### 今はわからなくてもattention_from_scratch.ipynbでのattentionの実装では必ずマスターしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算対象のTensor:  torch.Size([2, 3, 4]) torch.Size([2, 4, 5])\n",
      "torch.bmm: \n",
      " tensor([[[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]],\n",
      "\n",
      "        [[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]]]) torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, 4)\n",
    "b = torch.ones(2, 4, 5)\n",
    "print(\"計算対象のTensor: \", a.shape, b.shape)\n",
    "print(\"torch.bmm: \\n\", torch.bmm(a,b), torch.bmm(a,b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.einsumはアインシュタインの縮約記法による計算です。<br>\n",
    "einsumは、最初の引数に、計算を行う前と後のサイズを添字とした文字列で与え、第二、第三の引数にTensorを与えて計算します。<br>\n",
    "詳しくは公式ドキュメント(https://pytorch.org/docs/stable/torch.html#torch.einsum)を参照してください。<br>\n",
    "上のtorch.bmmでの計算は下のように実装できます<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算対象のTensor:  torch.Size([2, 3, 4]) torch.Size([2, 4, 5])\n",
      "torch.einsum(\"bnm, bmp->bnp\", Tensor1, Tensor2): \n",
      " tensor([[[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]],\n",
      "\n",
      "        [[4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4.]]]) torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, 4)\n",
    "b = torch.ones(2, 4, 5)\n",
    "print(\"計算対象のTensor: \", a.shape, b.shape)\n",
    "print('torch.einsum(\"bnm, bmp->bnp\", Tensor1, Tensor2): \\n', torch.einsum(\"bnm, bmp->bnp\",a,b), torch.einsum(\"bnm, bmp->bnp\",a,b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの足し算引き算\n",
    "Tensorの足し算引き算が可能になる条件は何通りかあります。\n",
    "- サイズが完全に揃っている場合\n",
    "- ブロードキャストが使える状態の場合\n",
    "- 計算対象の一方がスカラーの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "サイズが完全に揃っている場合\n",
      " torch.Size([2, 3]) torch.Size([2, 3]) \n",
      " tensor([[ 8., 10., 12.],\n",
      "        [ 5.,  7.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "#サイズが完全に揃っている場合\n",
    "#説明に使うTensorの定義\n",
    "a = torch.tensor([[1.,2.,3.],[4.,5.,6.]]) #size (2,3)のTensor\n",
    "e = torch.tensor([[7.,8.,9.],[1.,2.,3.]])\n",
    "print(\"サイズが完全に揃っている場合\\n\", a.shape, e.shape, \"\\n\" ,a + e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブロードキャストが使える時の場合<br>\n",
    "ブロードキャストに関してはNumpyの記事を参照して欲しいです。<br>少し細かい話にはなりますが、\n",
    "計算対象のテンソルのサイズが合っていなくても、<br>一部のサイズが合っていれば計算ができるといった感じです。例えば<br>\n",
    "Tensor1: size (3,3), Tensor2: size (1,3)という2つのテンソルでTensor1 + Tensor2を計算する時に<br>\n",
    "Tensor2のサイズはTensor1に合わせて(3,3)というサイズにまで拡張されて計算されます。<br>\n",
    "このときはTensor2 = [1,2,3]ならば、Tensor2は[1,2,3]という要素が3つになった(3,3)というサイズになって計算が行われます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1: torch.Size([2, 3])\n",
      "Tensor2: torch.Size([3])\n",
      "Tensor1 + Tensor2 =\n",
      " tensor([[2., 4., 6.],\n",
      "        [5., 7., 9.]])\n",
      "Tensor1 * Tensor2 =\n",
      " tensor([[ 1.,  4.,  9.],\n",
      "        [ 4., 10., 18.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor1:\",  a.shape)\n",
    "print(\"Tensor2:\",  d.shape)\n",
    "print(\"Tensor1 + Tensor2 =\\n\", a + d)\n",
    "#実は、ブロードキャストは他の演算でも有効\n",
    "print(\"Tensor1 * Tensor2 =\\n\", a * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スカラー演算<br>\n",
    "スカラーでの演算は全ての要素が足し引き、掛け算割り算されます。<br>\n",
    "スカラー演算はブロードキャストの一種と見なすこともできます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Scalar 10.0\n",
      "Scaler + Tensor1 = \n",
      " tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor1:\\n\",  a)\n",
    "print(\"Scalar\",  c)\n",
    "print(\"Scaler + Tensor1 = \\n\", a + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ブロードキャスト機能をうまく活用すると効率的にコードを書くことができます。<br>他人のコードはブロードキャスト機能を用いたものが多いため、注意を払って読みましょう。<br>また、この他にもnumpyにあったsum, mean, var, std, max, minなども実装されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_p$ノルムを求めることができます。$L_p$ノルムとは以下の式で定義される量です。<br>\n",
    "ベクトルではなく2階以上のテンソルの場合は2階以上のテンソルの場合の$L_p$ノルムを計算します。<br>\n",
    "$$\n",
    "    ||x||_p = \\left(x^p_1 + x^p_2 + \\ldots + x^p_N\\right)^{1/p}\n",
    "$$\n",
    "$L_p$ノルムを求める関数にはtorch.linalg.norm関数とtorch.norm関数があります。<br>\n",
    "それぞれ仕様に違いがあるので注意<br>\n",
    "\n",
    "torch.linalg.norm関数: ordという引数で計算するノルムの種類を指定<br>\n",
    "torch.norm関数: pという引数で計算するノルムの種類を指定<br>\n",
    "- 引数にpとdimがあるpは$L_p$ノルムのpの値を決める。dimは計算する次元を決定する。<br>\n",
    "- 計算する次元を決定する引数名はnumpyではaxisだったが、PyTorchではdimであることに注意する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算対象行列\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "行列L_2ノルム(torch.norm) tensor(9.5394)\n",
      "行列L_2ノルム(torch.norm), dim = 1 tensor([3.7417, 8.7750])\n"
     ]
    }
   ],
   "source": [
    "print(\"計算対象行列\\n\", a)\n",
    "print(\"行列L_2ノルム(torch.norm)\", a.norm(p = 2))\n",
    "print(\"行列L_2ノルム(torch.norm), dim = 1\", a.norm(p = 2,dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの分割、連結<br>\n",
    "Tensorの分割はtorch.chunk, torch.splitなどの関数が用意されており、<br>\n",
    "Tensorの結合はtorch.stack, torch.catなどの関数が用意されている。<br>\n",
    "torch.chunkはchunks引数とdim引数を持ち、chunksで分割する数を指定し、dimで分割する次元を指定する。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "torch.chunk(Tensor, chunks = 2):  (tensor([[0, 1, 2, 3, 4]]), tensor([[5, 6, 7, 8, 9]]))\n",
      "torch.chunk(Tensor, chunks = 2, dim = 1): \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [5, 6, 7]])\n",
      "tensor([[3, 4],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10).reshape(2, 5)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"torch.chunk(Tensor, chunks = 2): \", a.chunk(2))\n",
    "print(\"torch.chunk(Tensor, chunks = 2, dim = 1): \\n\")\n",
    "for t in a.chunk(chunks = 2, dim = 1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.splitはsplit_size_or_sections引数とdim引数を持ち<br>\n",
    "dimはtorch.chunkと同様の働きをする。<br>\n",
    "split_size_or_sectionsにint型を渡すと、渡した数を要素に持つようにデータを分割する<br>\n",
    "split_size_or_sectionsにlist型を渡すとlistの要素に従ってデータを分割する。例えば[1,3,1]とすると、<br>\n",
    "要素数が[1,3,1]となるように分割する<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "torch.split(Tensor, split_size_or_sections=2,dim = 1): \n",
      "\n",
      "tensor([[0, 1],\n",
      "        [5, 6]])\n",
      "tensor([[2, 3],\n",
      "        [7, 8]])\n",
      "tensor([[4],\n",
      "        [9]])\n",
      "torch.split(Tensor, split_size_or_sections=[1,3,1],dim = 1): \n",
      "\n",
      "tensor([[0],\n",
      "        [5]])\n",
      "tensor([[1, 2, 3],\n",
      "        [6, 7, 8]])\n",
      "tensor([[4],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10).reshape(2, 5)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"torch.split(Tensor, split_size_or_sections=2,dim = 1): \\n\")\n",
    "for t in torch.split(a,split_size_or_sections=2,dim = 1):\n",
    "    print(t)\n",
    "print(\"torch.split(Tensor, split_size_or_sections=[1,3,1],dim = 1): \\n\")\n",
    "for t in torch.split(a,split_size_or_sections=[1,3,1],dim = 1):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorの連結に使う関数にはtorch.catとtorch.stackがあります。<br>\n",
    "torch.catは結合する2つのTensorの既存の次元数に従ってTensorを結合する関数であり,<br>\n",
    "torch.stackは結合する2つのTensorに次元を追加してTensorを結合する関数である。<br>\n",
    "torch.catはtorch.cat([結合するTensorのリスト], dim = (結合する次元を指定))という感じで使い、<br>\n",
    "torch.stackはtorch.stack([結合するTensorのリスト], dim = (増やして結合する次元を指定))という感じで使う。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結合するTensorのサイズ torch.Size([2, 3]) torch.Size([2, 4])\n",
      "結合するTensor\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      " tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "torch.cat([Tensor1, Tensor2], dim = 1): \n",
      " tensor([[0, 1, 2, 0, 1, 2, 3],\n",
      "        [3, 4, 5, 4, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(8).reshape(2, 4)\n",
    "print(\"結合するTensorのサイズ\", a.shape, b.shape)\n",
    "print(\"結合するTensor\\n\", a,\"\\n\", b)\n",
    "print(\"torch.cat([Tensor1, Tensor2], dim = 1): \\n\", torch.cat([a,b], dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結合するTensorのサイズ torch.Size([2, 3]) torch.Size([2, 3])\n",
      "結合するTensor\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.stack([Tensor1, Tensor2], dim = 2): \n",
      " tensor([[[0, 0],\n",
      "         [1, 1],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[3, 3],\n",
      "         [4, 4],\n",
      "         [5, 5]]]) torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(6).reshape(2, 3)\n",
    "print(\"結合するTensorのサイズ\", a.shape, b.shape)\n",
    "print(\"結合するTensor\\n\", a,\"\\n\", b)\n",
    "print(\"torch.stack([Tensor1, Tensor2], dim = 2): \\n\", torch.stack([a,b], dim = 2),torch.stack([a,b], dim = 2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einopsというライブラリを用いるとアインシュタインの縮約記法を用いて配列を次元毎に操作することが簡単となります。<br>\n",
    "einsumとeinopsを使用してコードを簡潔に書いてしまうのがどうやら流行っているようなので覚えて損はないはずです。[einsum-attention](https://theaisummer.com/einsum-attention/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einopsはPytorchとの互換性があるため、普通に用いても勾配の計算方法を示してくれます。<br>Pytorchの勾配に関してはPytorchの勾配について, 最適化の方法で解説します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einops.rearangeはTensorの分割を行います。()で囲んだところは一つの次元とみなします。例えば下の実行例では<br>\n",
    "(i j (h k))という3つの次元のうち、3つめをh×kとみなし、h = 5, k = 3として分割をしています。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor:\n",
      " tensor([[[ 0.3190,  0.3849,  0.0924, -0.0886,  0.3225,  0.1488,  0.6149,\n",
      "          -0.6632, -0.2944,  0.3243, -0.3702, -0.1325, -0.8012, -0.5966,\n",
      "          -0.4884],\n",
      "         [-0.9475,  0.0532, -0.7294,  0.5840,  0.9410,  0.5510, -0.4713,\n",
      "          -0.1896,  0.2714, -0.7667,  0.7492, -0.8148,  0.2695, -0.7870,\n",
      "          -0.5291],\n",
      "         [ 0.4864, -0.9792,  0.2007, -0.4630,  0.7768, -0.6595,  0.2567,\n",
      "           0.5525, -0.0207, -0.8245,  0.6366,  0.2192,  0.3277, -0.8060,\n",
      "          -0.9147]],\n",
      "\n",
      "        [[-0.5084,  0.3811,  0.6384, -0.5537, -0.1752,  0.8650, -0.2048,\n",
      "          -0.9870, -0.0086,  0.3217, -0.0982, -0.2040, -0.2163, -0.7580,\n",
      "           0.3338],\n",
      "         [-0.0377, -0.8841, -0.9739,  0.1904,  0.1510, -0.6864, -0.0790,\n",
      "          -0.5698,  0.3305,  0.1943,  0.3973,  0.5618, -0.9110, -0.8872,\n",
      "          -0.7736],\n",
      "         [ 0.0921,  0.2255,  0.4380,  0.8268, -0.6630,  0.0804,  0.4171,\n",
      "          -0.2415, -0.9891, -0.0653,  0.7564, -0.2714, -0.8692,  0.0771,\n",
      "           0.0442]]], grad_fn=<ToCopyBackward0>) torch.Size([2, 3, 15])\n",
      "rearrange(i j (h k)->h i j k):\n",
      " tensor([[[[ 0.3190,  0.3849,  0.0924],\n",
      "          [-0.9475,  0.0532, -0.7294],\n",
      "          [ 0.4864, -0.9792,  0.2007]],\n",
      "\n",
      "         [[-0.5084,  0.3811,  0.6384],\n",
      "          [-0.0377, -0.8841, -0.9739],\n",
      "          [ 0.0921,  0.2255,  0.4380]]],\n",
      "\n",
      "\n",
      "        [[[-0.0886,  0.3225,  0.1488],\n",
      "          [ 0.5840,  0.9410,  0.5510],\n",
      "          [-0.4630,  0.7768, -0.6595]],\n",
      "\n",
      "         [[-0.5537, -0.1752,  0.8650],\n",
      "          [ 0.1904,  0.1510, -0.6864],\n",
      "          [ 0.8268, -0.6630,  0.0804]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6149, -0.6632, -0.2944],\n",
      "          [-0.4713, -0.1896,  0.2714],\n",
      "          [ 0.2567,  0.5525, -0.0207]],\n",
      "\n",
      "         [[-0.2048, -0.9870, -0.0086],\n",
      "          [-0.0790, -0.5698,  0.3305],\n",
      "          [ 0.4171, -0.2415, -0.9891]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3243, -0.3702, -0.1325],\n",
      "          [-0.7667,  0.7492, -0.8148],\n",
      "          [-0.8245,  0.6366,  0.2192]],\n",
      "\n",
      "         [[ 0.3217, -0.0982, -0.2040],\n",
      "          [ 0.1943,  0.3973,  0.5618],\n",
      "          [-0.0653,  0.7564, -0.2714]]],\n",
      "\n",
      "\n",
      "        [[[-0.8012, -0.5966, -0.4884],\n",
      "          [ 0.2695, -0.7870, -0.5291],\n",
      "          [ 0.3277, -0.8060, -0.9147]],\n",
      "\n",
      "         [[-0.2163, -0.7580,  0.3338],\n",
      "          [-0.9110, -0.8872, -0.7736],\n",
      "          [-0.8692,  0.0771,  0.0442]]]], grad_fn=<ReshapeAliasBackward0>) torch.Size([5, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce\n",
    "x = torch.tensor(np.random.uniform(low = -1, high = 1, size = (2,3,15)), requires_grad=True).float()\n",
    "print(\"元のTensor:\\n\",x,x.shape)\n",
    "print(\"rearrange(i j (h k)->h i j k):\\n\",rearrange(x,\"i j (h k) -> h i j k\",h=5,k=3),rearrange(x,\"i j (h k) -> h i j k\",h=5,k=3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einops.reduceは次元を減らします。第一引数に次元を減らす対象となるテンソル, 第二引数に減らす前の次元と減らした後の次元を指定、第三引数に次元の減らし方を指定します。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor:\n",
      " tensor([[[ 0.3190,  0.3849,  0.0924, -0.0886,  0.3225,  0.1488,  0.6149,\n",
      "          -0.6632, -0.2944,  0.3243, -0.3702, -0.1325, -0.8012, -0.5966,\n",
      "          -0.4884],\n",
      "         [-0.9475,  0.0532, -0.7294,  0.5840,  0.9410,  0.5510, -0.4713,\n",
      "          -0.1896,  0.2714, -0.7667,  0.7492, -0.8148,  0.2695, -0.7870,\n",
      "          -0.5291],\n",
      "         [ 0.4864, -0.9792,  0.2007, -0.4630,  0.7768, -0.6595,  0.2567,\n",
      "           0.5525, -0.0207, -0.8245,  0.6366,  0.2192,  0.3277, -0.8060,\n",
      "          -0.9147]],\n",
      "\n",
      "        [[-0.5084,  0.3811,  0.6384, -0.5537, -0.1752,  0.8650, -0.2048,\n",
      "          -0.9870, -0.0086,  0.3217, -0.0982, -0.2040, -0.2163, -0.7580,\n",
      "           0.3338],\n",
      "         [-0.0377, -0.8841, -0.9739,  0.1904,  0.1510, -0.6864, -0.0790,\n",
      "          -0.5698,  0.3305,  0.1943,  0.3973,  0.5618, -0.9110, -0.8872,\n",
      "          -0.7736],\n",
      "         [ 0.0921,  0.2255,  0.4380,  0.8268, -0.6630,  0.0804,  0.4171,\n",
      "          -0.2415, -0.9891, -0.0653,  0.7564, -0.2714, -0.8692,  0.0771,\n",
      "           0.0442]]], grad_fn=<ToCopyBackward0>) torch.Size([2, 3, 15])\n",
      "reduce(i j k->i j) method max:\n",
      " tensor([[0.6149, 0.9410, 0.7768],\n",
      "        [0.8650, 0.5618, 0.8268]], grad_fn=<ReshapeAliasBackward0>) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"元のTensor:\\n\",x,x.shape)\n",
    "print(\"reduce(i j k->i j) method max:\\n\",reduce(x, \"i j k->i j\",\"max\"),reduce(x, \"i j k->i j\",\"max\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件演算子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.where条件を満たす要素に処理を行う関数です。\n",
    "torch.where(条件式, Trueの場合, Falseの場合)のように書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([0.3092, 0.6917, 0.9336, 0.4014, 0.4436, 0.4361, 0.6281, 0.3551, 0.6891,\n",
      "        0.1616])\n",
      "Tensor1 > 0.5なら1, Tensor1 <= 0.5なら0としてtorch.where関数を適用させたもの: \n",
      " tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10)\n",
    "a = 1/(1+torch.exp(a))\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"Tensor1 > 0.5なら1, Tensor1 <= 0.5なら0としてtorch.where関数を適用させたもの: \\n\", torch.where(a > 0.5, torch.ones_like(a), torch.zeros_like(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.clamp<br>\n",
    "torch.clampは値を一定の範囲でクリッピングします。logやゼロ割に対処するために使用します。<br>\n",
    "torch.clamp(処理前のTensor, min, max)のように指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([-0.2070,  0.4184, -0.6245, -0.3027, -1.8518,  0.1531, -0.7373,  0.7766,\n",
      "         0.1881,  0.7315])\n",
      "torch.clampを適用しない場合: \n",
      " tensor([    nan, -0.8713,     nan,     nan,     nan, -1.8768,     nan, -0.2528,\n",
      "        -1.6710, -0.3127])\n",
      "torch.clampを適用する場合: \n",
      " tensor([-73.6827,  -0.8713, -73.6827, -73.6827, -73.6827,  -1.8768, -73.6827,\n",
      "         -0.2528,  -1.6710,  -0.3127])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10)\n",
    "a_clamp = torch.clamp(a, 1e-32, 1e+32) #値が\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"torch.clampを適用しない場合: \\n\", torch.log(a))\n",
    "print(\"torch.clampを適用する場合: \\n\", torch.log(a_clamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.ge, torch.gt, torch.le, torch.lt, torch.eq<br>\n",
    "torch.geはgreater than or equal toを意味し,torch.ge(tensor, num)となった場合、tensor>=numとなった要素をTrueとして返します。<br>\n",
    "torch.gt, torch.le, torch.lt, torch.eqも関数の呼び出し方は一緒です。<br>\n",
    "gtはgreater than, leはless than or equal, ltはless than, eqはequalを意味します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Tensor >= 4 tensor([False, False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "Tensor > 4 tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "Tensor <= 4 tensor([ True,  True,  True,  True,  True, False, False, False, False, False])\n",
      "Tensor < 4 tensor([ True,  True,  True,  True, False, False, False, False, False, False])\n",
      "Tensor == 4 tensor([False, False, False, False,  True, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"Tensor >= 4\", torch.ge(a, 4))\n",
    "print(\"Tensor > 4\", torch.gt(a, 4))\n",
    "print(\"Tensor <= 4\", torch.le(a, 4))\n",
    "print(\"Tensor < 4\", torch.lt(a, 4))\n",
    "print(\"Tensor == 4\", torch.eq(a, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyと同じく、算術演算子を使うこともできます。実用上はこちらの方が使う場面が多いかもしれません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor: \n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Tensor >= 4 tensor([False, False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "Tensor > 4 tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "Tensor <= 4 tensor([ True,  True,  True,  True,  True, False, False, False, False, False])\n",
      "Tensor < 4 tensor([ True,  True,  True,  True, False, False, False, False, False, False])\n",
      "Tensor == 4 tensor([False, False, False, False,  True, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "print(\"元のTensor: \\n\", a)\n",
    "print(\"Tensor >= 4\", a>=4)\n",
    "print(\"Tensor > 4\", a>4)\n",
    "print(\"Tensor <= 4\", a<=4)\n",
    "print(\"Tensor < 4\", a<4)\n",
    "print(\"Tensor == 4\", a==4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他にPytorchで知っておくメソッドは, <br>リストやnumpyのndarrayに変換するtolist, numpyメソッド, 値の取得を行うitemメソッド, 計算するデバイスの指定などがあります。<br>\n",
    "紹介する時になったら紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader定義編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有名なデータセットは前もってPytorch上で扱いやすいように提供されています。<br>しかし実際には自分でデータを集めて制作した自作データセットを使いたいという場面もあります。<br>\n",
    "そこでこの章では自作Dataloaderセットの定義の方法を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データがTensorオブジェクト, Pythonリスト, またはNumpy配列として既に存在している場合には<br>torch.utils.data.DataLoaderクラスを用いればデータセットローダーを簡単に制作することができる。<br>\n",
    "DataLoaderクラスの定義の際にBatch_sizeを指定すると, 指定したサイズのバッチが反復の際に出力される。<br>\n",
    "また、シャッフルが必要なときはshuffle = Trueと引数を変更することでデータがシャッフルされた状態で取り出される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "t = torch.ones(size = (10,3), dtype = torch.float32)\n",
    "data_loader = DataLoader(t, batch_size = 2)\n",
    "for t_item in data_loader:\n",
    "    print(t_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に2つのテンソルを1つのデータセットに結合する。<br>\n",
    "この時に自作データセットの定義が必要となる。<br>\n",
    "Pythonのクラスに関しての説明は詳しくは行わないので, Pythonの基本的な参考書で補填して欲しい。<br>\n",
    "Datasetクラスの継承を行ったあと, init, getitem, lenメソッドの挙動の定義を行うことで簡単にDatasetクラスを制作することができる。<br>\n",
    "getitemメソッドが見慣れないと思うので少し簡単な解説を行う。<br>\n",
    "getitemメソッドはPythonの特殊メソッドであり鉤括弧[]でオブジェクトにアクセスした時の挙動を定義するものである。<br>\n",
    "例えばリストL = [0,1,2,3,4,5]の4番目の要素にアクセスする時、L[3] = 3となるのはこのgetitemメソッドによるものである。<br>\n",
    "今回はfor文を回した時に, データとラベルを出力できるように制作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: \n",
      " tensor([[0.7725, 0.1325, 0.1150, 0.8772, 0.6803],\n",
      "        [0.6020, 0.6206, 0.1650, 0.4728, 0.9869],\n",
      "        [0.8132, 0.7102, 0.5097, 0.7580, 0.7245],\n",
      "        [0.1720, 0.1463, 0.7559, 0.3371, 0.5650]]) \n",
      "label: \n",
      " tensor([0., 1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "#簡単なデータを制作する\n",
    "data = torch.rand(size = (4,5), dtype = torch.float32)\n",
    "y = torch.arange(4, dtype = torch.float32)\n",
    "print(\"Data: \\n\", data, \"\\nlabel: \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7725, 0.1325, 0.1150, 0.8772, 0.6803]) tensor(0.)\n",
      "tensor([0.6020, 0.6206, 0.1650, 0.4728, 0.9869]) tensor(1.)\n",
      "tensor([0.8132, 0.7102, 0.5097, 0.7580, 0.7245]) tensor(2.)\n",
      "tensor([0.1720, 0.1463, 0.7559, 0.3371, 0.5650]) tensor(3.)\n",
      "Length:  4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class normal_dataset(Dataset):\n",
    "    def __init__(self, data, y):\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.y[idx]\n",
    "d_set = normal_dataset(data, y)\n",
    "for batch_x, batch_y in d_set:\n",
    "    print(batch_x, batch_y)\n",
    "print(\"Length: \", len(d_set))\n",
    "#実際にDataLoaderと同じように使えることがわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットがテンソル形式のラベルデータセットならば, 単純にtorch.utils.data.TensorDatasetを用いることでも実装ができる。<br>\n",
    "TensorDatasetで制作したオブジェクトをDataLoaderに渡すことでbatch_sizeを指定してデータを取り出すこともできる。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7725, 0.1325, 0.1150, 0.8772, 0.6803],\n",
      "        [0.6020, 0.6206, 0.1650, 0.4728, 0.9869]]) tensor([0., 1.])\n",
      "tensor([[0.8132, 0.7102, 0.5097, 0.7580, 0.7245],\n",
      "        [0.1720, 0.1463, 0.7559, 0.3371, 0.5650]]) tensor([2., 3.])\n",
      "Length:  2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "d_set = TensorDataset(data, y)\n",
    "d_set = DataLoader(d_set, batch_size = 2)\n",
    "for batch_x, batch_y in d_set:\n",
    "    print(batch_x, batch_y)\n",
    "print(\"Length: \", len(d_set))\n",
    "#実際にDataLoaderと同じように使えることがわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データのサブセット作成<br>\n",
    "torch.utils.data.Subset(data, idx)でデータセットのサブセットの制作が行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7725, 0.1325, 0.1150, 0.8772, 0.6803]]) tensor([0.])\n",
      "Length:  1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "d_set = TensorDataset(data, y)\n",
    "d_set_sub = Subset(d_set, torch.arange(1))\n",
    "d_set_sub = DataLoader(d_set_sub)\n",
    "for batch_x, batch_y in d_set_sub:\n",
    "    print(batch_x, batch_y)\n",
    "print(\"Length: \", len(d_set_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでの説明はDataloaderの一部にすぎませんが, <br>Datasetクラスを定義し, init, len, getitemメソッドの挙動を定義することを覚えておけば, 応用が効くようになると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル定義編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この章では主にモデルを構築する方法を学びます。<br>Pytorchの高レベルAPIを用いれば簡単なモデルの構築は3秒で終わりますが, <br>\n",
    "今回は全結合層, 2次元畳み込み層の低レベルAPIを用いた実装を通してより深くPytorchを学んだ上でモデルの定義を行おうと思います。<br>\n",
    "<br>\n",
    "低レベルAPIで高レベルAPIにある機能を実装することは、Pytorch内部の仕様の理解を助け、よりカスタムされた機能を追加することに役立つため、<br>\n",
    "必ず自分でドキュメントを読み、一度は手を動かして行ってください。<br>\n",
    "写経でも全く問題はありません、しかし組んでいる最中でコードに疑問を持ったところは必ず理解して次に進みましょう。<br>\n",
    "モデル定義編で扱わなかったレイヤーの低レベルAPI実装はAppendixに記しておきます。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU\n",
    "ReLUは<br>$$\\text{ReLU}(x) = \\text{max}(0, x)$$<br>で定義される関数であり、$x=0$付近で非線形の特性を示す関数です。活性化関数としておそらく最も頻繁に使われています。<br>\n",
    "Pytorchの練習としてtorch.where関数で組んでみましょう。\n",
    "また、今後は関数を組む際に事故を防ぐためにPythonの型を明示的にコードを書いていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元のTensor:  tensor([-0.4885, -2.1808, -1.4371,  1.5590,  1.3819, -0.9579,  0.3448,  0.1898])\n",
      "ReLU(Tensor):  tensor([0.0000, 0.0000, 0.0000, 1.5590, 1.3819, 0.0000, 0.3448, 0.1898])\n"
     ]
    }
   ],
   "source": [
    "def relu(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.where(x > 0, x, torch.zeros_like(x))\n",
    "a = torch.randn(8)\n",
    "print(\"元のTensor: \", a)\n",
    "print(\"ReLU(Tensor): \", relu(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層のスクラッチ実装<br>\n",
    "全結合層\n",
    "$$\n",
    "Z = XW^{T}+b\n",
    "$$\n",
    "の実装を行います。ここで、$W \\in{M_{out\\_dim×in\\_dim}}, X \\in{M_{num\\_data×in\\_dim}}$であることに注意してください。<br>\n",
    "初めはこの定義に対して疑問を思うかもしれませんが、一度誤差逆伝播法の証明をすればわかるようになるかと思います。<br>\n",
    "<br>実際に使う時はtorch.nn.Linearクラスを用いれば問題はありませんが, 今回はPytorchの理解のためにスクラッチ実装を行います。\n",
    "手順<br>\n",
    "- nn.Moduleの継承\n",
    "- init引数をin_dim, out_dimとする。\n",
    "- nn.Parameterでパラメーター行列, バイアスベクトルを制作\n",
    "- クラス内でforward関数の挙動を定義, $Z = XW^{T}+b$を出力するようにする。これにはtorch.matmulとtorch.nn.functional.linearを使う方法の2通りがある\n",
    "\n",
    "torch.nn.functional.linearはtorch.nn.functional.linear(A,B,b)として実行すると$AB^{T}+b$を出力する関数である。torch.matmulとの違いに気をつけよう。<br>\n",
    "torch.matmulを使った方が直感的にはわかりやすい。\n",
    "<br>\n",
    "<br>\n",
    "次に, nn.Parameterを使う理由としては、公式ドキュメントによると, nn.Parameterで定義されたパラメーターは<br>nn.Moduleのparameters()イテレーターとして追加されるからである。\n",
    "<br>\n",
    "<br>\n",
    "nn.Moduleを継承したクラスでforwardを定義すると、丸括弧で囲んだときの挙動を指定する。例えば、Linear(x)などである。<br>\n",
    "Pythonではこれは__call__メソッドの定義にあたるものだが、__call__メソッドとして forward が機能するようにモジュール側で実装されています。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "rng = np.random.RandomState(1)\n",
    "class linear(nn.Module):\n",
    "    def __init__(self, in_dim: int or float, out_dim: int or float) -> None:\n",
    "        super().__init__()\n",
    "        #He uniformで初期化\n",
    "        weight = torch.tensor(rng.uniform(low=-np.sqrt(6/in_dim),high=np.sqrt(6/in_dim),size=(out_dim, in_dim)).astype('float32'))\n",
    "        #Biasは全て0で初期化\n",
    "        bias = torch.tensor(np.zeros([out_dim]).astype('float32'))\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #以下の関数はreturn torch.matmul(x, self.weight.T) + self.biasを実行していることと同じである。\n",
    "        return F.linear(x, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に使ってみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size = (3,3))\n",
    "L = linear(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に,forwardが機能していることと, Linearのパラメーターがparametersメソッドを使った時にイテレーターになっているかを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward: \n",
      " tensor([[ 0.9241,  0.6332,  0.5992],\n",
      "        [-0.1345,  0.8631,  0.4104],\n",
      "        [ 0.1910, -0.2729, -0.1300]], grad_fn=<AddmmBackward0>)\n",
      "Linear parameters: \n",
      "Parameter containing:\n",
      "tensor([[-0.2347,  0.6232, -1.4139],\n",
      "        [-0.5591, -0.9991, -1.1530],\n",
      "        [-0.8874, -0.4368, -0.2920]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"forward: \\n\", L(x))\n",
    "print(\"Linear parameters: \")\n",
    "for p in L.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に2次元畳み込み層の実装を示します。<br>\n",
    "畳み込みをするモチベーションに関しては市販の技術書やウェブサイトを参考にしてほしい<br>\n",
    "<br>\n",
    "公式ドキュメントにのっとり、__init__にはin_channels, out_channels, kernel_size, stride, padding,dilation,groupを引数として実装します。<br>\n",
    "バッチサイズを$N$, 入力チャンネルを$C_{in}$, 出力チャンネルを$C_{out}$, 入力2次元画像の高さを幅を$H, W$とすると<br>\n",
    "conv2dは$(N, C_{in}, H, W) \\to (N, C_{out}, H_{out}, W_{out})$とする層である。<br>\n",
    "$H_{out}, W_{out}$の大きさはpaddingなどで決まる。<br>\n",
    "式は以下の通りである。<br>\n",
    "$$\n",
    "H_{out} = \\lfloor \\dfrac{H_{in}+2\\rm{padding}[0]-\\rm{dilation}[0](\\rm{kernel\\_size}[0]-1)-1}{\\rm{stride}[0]}+1 \\rfloor\n",
    "$$\n",
    "$$\n",
    "W_{out} = \\lfloor \\dfrac{W_{in}+2\\rm{padding}[1]-\\rm{dilation}[1](\\rm{kernel\\_size}[1]-1)-1}{\\rm{stride}[1]}+1 \\rfloor\n",
    "$$\n",
    "モデルを構築するときは畳み込み層を通した後の形に注意しながら実装する必要がある。<br>\n",
    "二次元畳み込みは全結合層のようにtorch.matmulなどの単純な関数による実装はできないため、torch.nn.functional.conv2d関数を用いる<br>\n",
    "もし本当にゼロからの実装に興味がある人は, 効率よく二次元畳み込み演算を計算する方法として<br>Winograd's Minimal Filteringアルゴリズムなどが知られているため、調べてもらいたい。<br>\n",
    "単純に二次元畳み込みの定義式\n",
    "$$\n",
    "Y[i,j] = \\sum\\limits_{k_1=-\\infty}^{+\\infty}\\sum\\limits_{k_2=-\\infty}^{+\\infty}X[i-k_1, j-k_2]W[k_1,k_2]\n",
    "$$\n",
    "を実装するだけでは非常に効率が悪いため効率が良いアルゴリズムを用いてPytorchでは実装を行っている。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "rng = np.random.RandomState(1)\n",
    "class conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = (1,1), padding = (0,0), dilation = (1,1), group = 1):\n",
    "        super().__init__()\n",
    "        filter_shape = (out_channels, in_channels // group, kernel_size[0], kernel_size[1])\n",
    "        k = in_channels * kernel_size[0] * kernel_size[1]\n",
    "        weight = torch.tensor(rng.uniform(low=-np.sqrt(k),high=np.sqrt(k),size=filter_shape).astype('float32'))\n",
    "        bias = torch.tensor(rng.uniform(low = -np.sqrt(k), high = np.sqrt(k), size = [out_channels]).astype('float32'))\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "        self.stride = stride  \n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.group = group\n",
    "    def forward(self, x):\n",
    "        return F.conv2d(x, weight = self.weight, bias = self.bias, stride = self.stride, padding = self.padding, dilation = self.dilation, groups = self.group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(rng.uniform(size = (3,3,3,3)).astype(\"float32\"))\n",
    "conv = conv2d(3,32,(3,3),padding=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv(x), conv(x)のサイズ: \n",
      " tensor([[[[-4.2212e+00,  1.2553e+01,  1.8412e+00],\n",
      "          [ 1.9680e+00,  9.3378e+00,  1.0218e+01],\n",
      "          [ 3.4083e+00,  9.3369e+00,  3.0335e+00]],\n",
      "\n",
      "         [[-4.0024e+00, -1.6263e+00, -1.5996e+01],\n",
      "          [-1.9691e+00, -6.2055e+00,  1.4242e+00],\n",
      "          [-5.3402e-01, -6.7465e+00, -1.1870e+00]],\n",
      "\n",
      "         [[-5.1369e+00,  5.8946e+00, -4.3092e+00],\n",
      "          [-7.9002e+00, -7.5852e+00, -9.3150e+00],\n",
      "          [-3.0901e+00, -1.0952e+01, -9.2359e+00]],\n",
      "\n",
      "         [[-5.2849e+00, -1.3041e+01, -1.1580e+01],\n",
      "          [-9.4775e+00, -6.8972e+00, -1.2919e+01],\n",
      "          [-5.3173e+00, -6.5992e+00, -7.8031e+00]],\n",
      "\n",
      "         [[ 1.4641e+00, -1.6522e+00,  2.8938e+00],\n",
      "          [ 3.0718e+00,  3.8519e+00,  8.9192e+00],\n",
      "          [ 1.4945e+01,  1.8072e+01,  7.8460e+00]],\n",
      "\n",
      "         [[ 2.3566e+00,  2.1134e+00,  1.6296e+00],\n",
      "          [ 9.4615e+00,  9.0693e+00,  1.0424e+00],\n",
      "          [ 7.3955e+00, -1.5721e+00,  4.7677e+00]],\n",
      "\n",
      "         [[ 3.8665e+00,  3.6910e+00, -3.2254e+00],\n",
      "          [ 8.2848e+00,  1.1335e+01,  5.6206e+00],\n",
      "          [ 9.4431e+00,  1.5931e+01,  6.6220e+00]],\n",
      "\n",
      "         [[-5.8059e+00, -6.8000e+00, -5.6801e+00],\n",
      "          [-4.7471e+00, -4.5583e-01,  2.5118e+00],\n",
      "          [ 1.2426e+00,  4.9865e+00,  3.6071e+00]],\n",
      "\n",
      "         [[-4.8402e+00, -3.1580e+00, -8.0357e-01],\n",
      "          [-6.8964e+00, -1.0076e+01, -1.0149e+01],\n",
      "          [ 7.5310e+00, -2.1680e+00, -1.3987e+00]],\n",
      "\n",
      "         [[ 1.8814e+00,  6.4850e+00, -2.4349e+00],\n",
      "          [ 4.6980e-01, -4.2739e-01,  5.9480e+00],\n",
      "          [ 4.8854e-01,  5.5092e+00,  2.4561e+00]],\n",
      "\n",
      "         [[ 6.4304e+00, -1.7882e+00,  8.7652e+00],\n",
      "          [ 2.6893e+00, -1.4163e+00, -3.9525e+00],\n",
      "          [-2.6933e+00, -1.2160e+01, -8.2072e+00]],\n",
      "\n",
      "         [[ 8.5322e+00,  2.1324e+00,  2.0537e+00],\n",
      "          [ 7.3839e+00,  1.7225e+00, -4.5678e+00],\n",
      "          [ 1.0294e+01,  9.3125e-01,  6.0450e+00]],\n",
      "\n",
      "         [[-6.4079e+00, -4.1864e+00, -3.4164e+00],\n",
      "          [-5.5811e+00, -8.6498e+00,  1.5957e-01],\n",
      "          [ 1.5107e+00, -1.1364e+01, -4.3111e+00]],\n",
      "\n",
      "         [[-5.9112e+00,  1.0174e+01,  9.3950e+00],\n",
      "          [-1.1121e+00,  8.4347e+00,  6.9819e+00],\n",
      "          [ 3.9289e+00,  1.0275e+01,  3.8587e+00]],\n",
      "\n",
      "         [[ 4.3815e+00, -3.3545e+00,  3.8626e+00],\n",
      "          [ 3.4558e+00,  3.1050e-01, -3.9126e+00],\n",
      "          [ 2.6509e+00,  7.9246e-01, -6.6392e+00]],\n",
      "\n",
      "         [[-2.5555e+00, -5.5719e+00,  9.0077e-01],\n",
      "          [-3.5690e+00, -3.6162e+00,  8.9537e+00],\n",
      "          [ 5.2036e+00,  1.1415e+01,  5.0173e+00]],\n",
      "\n",
      "         [[-1.1978e+00, -6.0554e+00, -2.5344e+00],\n",
      "          [ 5.5720e-01,  1.0559e+01,  8.4872e+00],\n",
      "          [ 9.0260e+00,  3.6497e+00,  7.4694e+00]],\n",
      "\n",
      "         [[-2.0615e+00, -2.9419e+00,  5.6444e+00],\n",
      "          [ 6.9038e-02, -1.1934e+00,  2.4905e+00],\n",
      "          [-8.6935e+00, -2.9418e+00, -2.3955e+00]],\n",
      "\n",
      "         [[ 1.3307e+01,  4.6928e+00,  1.2866e+01],\n",
      "          [ 4.1512e+00,  1.4819e+01,  1.2864e+01],\n",
      "          [ 1.2055e+01,  5.8130e+00,  5.4783e+00]],\n",
      "\n",
      "         [[-9.4914e+00, -1.4016e+01, -3.5725e+00],\n",
      "          [-2.1224e+01, -7.6232e+00, -7.3130e+00],\n",
      "          [-1.3175e+01, -1.2351e+01, -4.5656e+00]],\n",
      "\n",
      "         [[-1.0647e+01, -1.6798e+01, -7.1448e-01],\n",
      "          [-1.3792e+01, -3.7417e+00, -9.1354e+00],\n",
      "          [-3.5064e+00, -5.6484e+00, -1.0031e+01]],\n",
      "\n",
      "         [[ 2.6667e+00, -4.4700e-01,  2.9994e+00],\n",
      "          [ 2.7490e+00, -2.6855e+00, -3.0351e+00],\n",
      "          [-2.4086e+00,  1.4948e+00, -9.0130e+00]],\n",
      "\n",
      "         [[ 3.6116e+00,  2.8318e+00, -3.2734e+00],\n",
      "          [ 2.0908e+00, -4.7741e+00,  1.9412e+00],\n",
      "          [ 6.8920e-01,  1.9249e+00, -4.2260e+00]],\n",
      "\n",
      "         [[-6.4911e-01,  1.4366e+01,  3.5775e+00],\n",
      "          [ 2.8121e+00,  5.1930e+00,  1.5458e+01],\n",
      "          [ 1.0417e+01,  1.1579e+01,  1.1893e+01]],\n",
      "\n",
      "         [[ 8.2714e+00,  1.1812e+01, -6.3672e+00],\n",
      "          [ 6.6282e+00,  1.3404e+01, -1.8837e+00],\n",
      "          [ 3.0128e+00, -5.5767e+00, -1.5928e+00]],\n",
      "\n",
      "         [[ 5.3380e+00, -2.9487e-01,  4.6412e+00],\n",
      "          [ 3.8932e+00, -4.3542e+00, -2.8166e+00],\n",
      "          [-2.7744e+00,  9.8807e-01, -8.7967e+00]],\n",
      "\n",
      "         [[ 6.7980e+00,  1.0394e+01,  1.2109e+01],\n",
      "          [ 1.0949e+01,  1.3516e+01,  1.8680e+01],\n",
      "          [ 4.7029e+00,  1.1905e+01,  4.8649e+00]],\n",
      "\n",
      "         [[-7.2184e+00, -6.6266e+00, -4.3200e+00],\n",
      "          [-4.8187e+00, -7.5617e+00, -3.1376e+00],\n",
      "          [-8.6600e+00,  1.5430e-01,  3.3446e+00]],\n",
      "\n",
      "         [[ 3.9177e+00,  1.7335e+00,  4.8065e+00],\n",
      "          [ 3.5283e+00,  3.6849e+00,  4.2832e+00],\n",
      "          [ 1.1976e+01,  5.2033e+00,  5.7067e+00]],\n",
      "\n",
      "         [[-9.8239e+00, -1.3295e+01, -3.3296e+00],\n",
      "          [-9.6862e+00, -1.1987e+01, -4.9146e+00],\n",
      "          [-1.1561e+01,  2.0281e+00, -9.5186e+00]],\n",
      "\n",
      "         [[ 3.5834e+00,  4.7398e+00,  1.4064e+01],\n",
      "          [ 3.4230e+00,  3.2606e+00,  8.3300e+00],\n",
      "          [ 2.0626e+00,  3.7634e+00, -6.9722e-01]],\n",
      "\n",
      "         [[ 1.1332e+00, -1.7280e+01, -7.7852e+00],\n",
      "          [-1.2591e+01, -3.3959e+00, -9.6998e+00],\n",
      "          [-1.2414e+01, -1.4146e+01, -3.5798e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.6290e+00,  6.3791e+00,  1.8310e+01],\n",
      "          [-2.9181e+00,  7.8631e+00,  1.2331e+01],\n",
      "          [ 4.0288e+00,  7.9162e+00,  6.1245e+00]],\n",
      "\n",
      "         [[-7.4999e-01, -1.3590e+00, -4.1292e+00],\n",
      "          [-1.0735e+01, -3.6308e+00, -3.4051e+00],\n",
      "          [-4.6021e+00, -4.0944e+00,  3.8529e+00]],\n",
      "\n",
      "         [[-2.7841e-01, -2.5033e+00, -7.1352e+00],\n",
      "          [-1.5301e+01, -1.5327e+01, -8.9060e+00],\n",
      "          [-9.8518e+00, -9.9865e+00, -4.4466e+00]],\n",
      "\n",
      "         [[-5.2352e+00, -1.6359e+01, -1.9155e+01],\n",
      "          [-4.3034e+00, -1.0251e+01, -3.4973e+00],\n",
      "          [-8.7216e+00, -9.3384e+00, -1.2694e+00]],\n",
      "\n",
      "         [[ 1.2675e+00,  4.0405e+00, -1.9288e+00],\n",
      "          [ 1.2483e+01,  1.0918e+01,  6.6721e+00],\n",
      "          [ 1.6136e+01,  1.1558e+01,  7.8340e+00]],\n",
      "\n",
      "         [[ 4.5169e+00,  4.3676e+00,  2.7941e+00],\n",
      "          [ 3.8343e+00,  1.0692e+01,  7.2530e+00],\n",
      "          [ 2.8866e+00,  1.0801e+01,  5.0331e+00]],\n",
      "\n",
      "         [[ 8.7198e+00,  1.0358e+01,  1.1474e+00],\n",
      "          [ 1.3553e+01,  1.6971e+01,  7.8502e+00],\n",
      "          [ 9.4789e+00,  1.1788e+01,  5.7109e+00]],\n",
      "\n",
      "         [[-6.6392e+00,  1.0325e+00,  5.3916e+00],\n",
      "          [-2.0417e+00,  2.5129e+00,  1.4224e+00],\n",
      "          [ 5.3363e+00,  9.6504e+00,  2.3759e+00]],\n",
      "\n",
      "         [[-3.7746e+00, -6.9748e+00, -1.0981e+01],\n",
      "          [-5.7494e+00, -5.7516e+00,  1.9877e+00],\n",
      "          [ 4.8878e+00, -1.0483e+00, -1.5323e+00]],\n",
      "\n",
      "         [[ 8.3991e+00,  7.3758e+00,  6.9483e-01],\n",
      "          [-5.0370e-01,  1.0043e+01, -1.5661e-01],\n",
      "          [-1.7905e+00, -1.5898e+00, -1.3787e+00]],\n",
      "\n",
      "         [[ 2.1383e+00,  1.2943e+01,  7.0721e-01],\n",
      "          [ 6.0177e+00, -2.0380e+00, -3.3859e+00],\n",
      "          [-5.7345e-01, -9.1295e+00, -9.5165e+00]],\n",
      "\n",
      "         [[ 1.2327e+01,  5.7455e+00, -2.6516e+00],\n",
      "          [ 5.7381e+00, -7.8672e+00, -3.8227e+00],\n",
      "          [ 2.1029e+00,  1.5264e+00, -3.1760e+00]],\n",
      "\n",
      "         [[-5.4040e+00, -9.4334e+00, -9.6561e+00],\n",
      "          [-3.3732e+00, -8.3494e+00, -7.0541e+00],\n",
      "          [-2.9421e-01, -6.9657e+00, -4.7243e+00]],\n",
      "\n",
      "         [[-6.6083e-01,  4.1577e+00,  1.0439e+01],\n",
      "          [-1.7464e+00,  6.5143e+00,  7.5378e+00],\n",
      "          [ 7.0832e-02,  3.4198e+00, -9.2248e-01]],\n",
      "\n",
      "         [[ 1.0044e+00,  4.6049e+00,  1.1955e+00],\n",
      "          [ 4.5212e+00, -1.7203e-01, -3.2786e+00],\n",
      "          [ 6.5324e+00, -2.1900e-03, -9.1479e+00]],\n",
      "\n",
      "         [[-7.8223e+00, -5.3046e-03, -8.2315e-01],\n",
      "          [ 1.9117e+00,  6.6971e+00,  1.9747e+00],\n",
      "          [ 1.1842e+01,  1.0832e+01,  9.0077e+00]],\n",
      "\n",
      "         [[ 2.0060e+00,  4.0044e+00,  3.6087e+00],\n",
      "          [ 7.1372e+00,  6.5923e+00, -9.6082e-01],\n",
      "          [ 4.7834e+00,  8.0507e+00,  7.4611e+00]],\n",
      "\n",
      "         [[-1.3594e+00,  4.9089e+00, -2.6031e-01],\n",
      "          [-6.3054e+00, -9.4204e+00,  2.3876e+00],\n",
      "          [-8.1818e+00, -5.6090e+00,  1.9469e+00]],\n",
      "\n",
      "         [[ 6.4556e+00,  1.5133e+01,  8.1501e+00],\n",
      "          [ 1.1768e+01,  8.8059e+00,  1.3763e+01],\n",
      "          [ 9.6549e+00,  4.6258e+00,  6.0580e+00]],\n",
      "\n",
      "         [[-9.8106e+00, -7.0389e+00,  2.5540e+00],\n",
      "          [-1.2352e+01, -1.6962e+01, -6.1246e+00],\n",
      "          [-1.5137e+01, -1.4014e+01, -1.4324e+01]],\n",
      "\n",
      "         [[-1.0515e+01, -3.5720e+00, -5.4189e+00],\n",
      "          [-2.3842e+00, -1.1493e+01, -9.2629e+00],\n",
      "          [-1.9724e+00, -5.7938e-01, -6.8444e+00]],\n",
      "\n",
      "         [[ 1.5699e+00, -5.4154e-01, -4.3305e+00],\n",
      "          [ 9.8684e-01, -8.5585e+00,  5.6663e-01],\n",
      "          [-3.3054e+00, -7.5892e+00, -6.2689e+00]],\n",
      "\n",
      "         [[ 8.4743e+00,  8.7301e+00,  1.5311e+00],\n",
      "          [ 5.2001e+00, -3.9543e+00, -6.1627e+00],\n",
      "          [ 6.9629e+00,  4.5263e-01,  4.4819e+00]],\n",
      "\n",
      "         [[ 1.8458e+00,  4.7003e+00,  1.5452e+01],\n",
      "          [ 3.1319e+00,  1.3936e+01,  9.1319e+00],\n",
      "          [ 8.9022e+00,  7.3387e+00,  5.8197e+00]],\n",
      "\n",
      "         [[ 1.2771e+01,  1.4898e+00, -4.1418e+00],\n",
      "          [ 1.3131e+01,  2.2502e+00, -5.4882e+00],\n",
      "          [ 1.0136e+00, -2.8761e+00, -1.5011e+00]],\n",
      "\n",
      "         [[ 1.2431e+00,  1.6483e+00, -3.9307e+00],\n",
      "          [ 1.6282e+00, -4.4497e-01, -2.0258e+00],\n",
      "          [ 4.1253e+00, -3.6479e+00, -8.2212e-01]],\n",
      "\n",
      "         [[ 8.7654e+00,  1.1373e+01,  1.2680e+01],\n",
      "          [ 9.8735e+00,  8.2289e+00,  9.3030e+00],\n",
      "          [ 4.7899e+00,  3.3438e+00,  1.3274e+01]],\n",
      "\n",
      "         [[-1.2854e+01, -1.2594e+01, -2.8448e+00],\n",
      "          [-6.5775e+00,  1.9210e-01,  1.1152e+00],\n",
      "          [-4.3130e+00,  2.8903e+00,  7.1117e-01]],\n",
      "\n",
      "         [[ 5.4331e+00,  6.4694e-01,  2.2074e-01],\n",
      "          [ 8.2765e+00,  8.5867e+00,  1.1131e+01],\n",
      "          [ 3.7019e+00, -3.1859e-01, -2.4731e+00]],\n",
      "\n",
      "         [[-1.3178e+01, -9.9554e+00, -1.1767e+01],\n",
      "          [-1.0278e+01, -9.5932e+00, -1.2342e+01],\n",
      "          [-5.0609e+00, -9.5404e+00, -1.8665e+00]],\n",
      "\n",
      "         [[ 6.7730e-01,  1.0042e+01,  9.6175e+00],\n",
      "          [-1.9441e+00,  4.5315e+00,  1.9249e+00],\n",
      "          [ 2.8057e-01,  1.3284e+00,  4.5271e+00]],\n",
      "\n",
      "         [[-4.8964e+00, -1.9346e+00, -1.0283e+01],\n",
      "          [-3.0094e+00, -1.3003e+01, -1.4780e+01],\n",
      "          [-1.3760e+01, -1.3550e+01, -8.5229e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6047e+00, -7.3884e-01,  1.3551e+01],\n",
      "          [ 3.6223e+00,  5.3254e+00,  1.4668e+01],\n",
      "          [ 4.0871e+00,  7.1577e+00,  1.2292e+01]],\n",
      "\n",
      "         [[ 8.6263e+00, -5.3601e+00, -3.9610e+00],\n",
      "          [ 1.4187e+00, -2.4955e+00, -9.8172e+00],\n",
      "          [-8.8111e+00, -7.5229e-01,  4.1888e+00]],\n",
      "\n",
      "         [[ 2.5077e+00, -7.9161e+00, -3.7695e+00],\n",
      "          [ 9.2876e-01, -1.1008e+01, -1.1948e+01],\n",
      "          [-4.9378e+00, -6.6643e+00, -8.5078e+00]],\n",
      "\n",
      "         [[-8.0954e+00, -1.2947e+01, -1.7904e+01],\n",
      "          [-4.6707e-01, -1.5804e+01, -1.3748e+01],\n",
      "          [-1.7783e+00, -6.3552e+00, -8.1114e+00]],\n",
      "\n",
      "         [[-2.1184e+00, -1.8313e+00, -2.4582e+00],\n",
      "          [ 4.4134e+00,  9.3000e+00,  2.1008e+00],\n",
      "          [ 1.3264e+01,  1.6818e+01,  1.4438e+01]],\n",
      "\n",
      "         [[ 3.0839e+00,  1.1935e+00,  2.3193e+00],\n",
      "          [ 4.8929e+00,  7.0598e+00,  7.0652e+00],\n",
      "          [ 2.3729e+00,  1.5318e+01,  2.0044e+00]],\n",
      "\n",
      "         [[ 5.9446e+00,  3.2566e+00,  1.5805e+00],\n",
      "          [ 1.3635e+01,  7.7481e+00,  6.7409e+00],\n",
      "          [ 1.1206e+01,  1.6691e+01,  1.2002e+01]],\n",
      "\n",
      "         [[-4.4276e+00, -4.8204e+00, -3.5936e+00],\n",
      "          [-6.3297e+00, -4.3057e-01, -8.7262e-01],\n",
      "          [-8.0288e-01,  9.6970e+00,  7.4679e+00]],\n",
      "\n",
      "         [[-9.1240e+00, -9.5453e+00, -6.6369e+00],\n",
      "          [-8.8295e+00, -7.1727e+00, -1.6203e+00],\n",
      "          [ 1.0565e+00,  2.4760e+00, -1.1719e+00]],\n",
      "\n",
      "         [[ 3.7123e+00,  2.9068e+00,  4.0652e+00],\n",
      "          [ 3.5694e+00,  5.0169e+00,  5.7890e+00],\n",
      "          [-2.3937e+00, -8.8178e-02,  4.9725e+00]],\n",
      "\n",
      "         [[ 2.6424e-01,  1.2250e+01,  8.1262e-01],\n",
      "          [-2.1852e+00,  1.0388e+01, -5.2863e-02],\n",
      "          [-7.3361e+00, -8.5632e+00, -1.2737e+01]],\n",
      "\n",
      "         [[ 1.1987e+01,  5.1389e+00, -3.3562e-01],\n",
      "          [ 8.1262e+00,  4.4373e+00, -3.8335e+00],\n",
      "          [ 3.3151e+00,  6.5910e+00,  1.7931e+00]],\n",
      "\n",
      "         [[-5.0276e+00, -1.0104e+01, -3.6271e+00],\n",
      "          [-1.3205e+01, -2.8657e+00, -1.0646e+01],\n",
      "          [-3.2976e+00, -5.3939e+00, -8.4897e+00]],\n",
      "\n",
      "         [[-2.6032e+00, -2.2180e+00,  9.2605e+00],\n",
      "          [-1.4976e+00,  6.4846e+00,  1.4091e+01],\n",
      "          [ 8.7707e+00,  7.0327e+00,  5.9579e+00]],\n",
      "\n",
      "         [[-1.3064e+00,  6.9880e+00,  3.4155e-01],\n",
      "          [-5.8306e-01,  3.2536e+00, -4.0354e-02],\n",
      "          [ 6.3339e+00,  8.9876e-01, -6.3275e+00]],\n",
      "\n",
      "         [[-6.5485e+00, -5.3973e+00, -3.3772e+00],\n",
      "          [-5.9393e+00, -9.0221e-01, -4.2650e+00],\n",
      "          [ 8.5019e+00,  1.0532e+01,  9.9411e+00]],\n",
      "\n",
      "         [[ 1.9782e+00,  3.2371e+00,  4.1912e+00],\n",
      "          [ 5.2203e+00, -2.5384e+00, -3.0426e-02],\n",
      "          [ 6.0901e+00,  1.2295e+01,  4.4337e+00]],\n",
      "\n",
      "         [[-5.5379e-01,  3.5056e+00,  2.9124e+00],\n",
      "          [-7.3302e+00, -6.1298e+00,  3.6303e+00],\n",
      "          [-1.1477e+01, -1.0580e+01,  4.4198e+00]],\n",
      "\n",
      "         [[ 5.0140e+00,  1.2207e+01,  1.1656e+01],\n",
      "          [ 8.0010e+00,  1.1849e+01,  1.7671e+01],\n",
      "          [ 3.7417e+00,  8.9745e+00,  9.6801e+00]],\n",
      "\n",
      "         [[-1.4136e+01, -8.6866e+00, -1.2813e+00],\n",
      "          [-1.9277e+01, -2.2596e+01, -1.4766e+00],\n",
      "          [-1.9439e+01, -1.5232e+01, -1.2537e+01]],\n",
      "\n",
      "         [[-1.1376e+01, -8.7493e+00, -8.7837e+00],\n",
      "          [-9.9992e+00, -1.5397e+01, -8.4326e+00],\n",
      "          [ 9.7542e-01, -3.2239e+00, -9.5764e+00]],\n",
      "\n",
      "         [[ 4.7668e+00,  1.8818e-01, -1.8402e+00],\n",
      "          [ 5.4049e+00, -5.5863e+00,  5.5788e-01],\n",
      "          [ 1.7888e+00, -9.4179e+00,  8.4233e-02]],\n",
      "\n",
      "         [[ 4.3913e+00,  7.5108e+00, -1.4728e+00],\n",
      "          [ 1.2413e+00,  1.0709e+00, -8.1921e+00],\n",
      "          [ 8.4713e-01, -2.4171e+00,  5.2994e+00]],\n",
      "\n",
      "         [[ 3.7249e+00,  2.4051e-02,  1.2007e+01],\n",
      "          [-7.6802e-01,  1.5362e+01,  8.8144e+00],\n",
      "          [ 7.5416e+00,  1.2706e+01,  1.0454e+01]],\n",
      "\n",
      "         [[ 1.0289e+01,  9.4594e+00,  3.5331e+00],\n",
      "          [ 1.4638e+01,  1.2071e+01, -6.8785e+00],\n",
      "          [ 3.8484e+00, -2.6836e-01, -9.7891e+00]],\n",
      "\n",
      "         [[-5.3179e+00,  3.9929e+00, -3.9179e+00],\n",
      "          [ 2.8482e+00, -9.0824e-01,  4.1371e-01],\n",
      "          [ 1.4239e+00, -5.6828e+00, -1.7142e+00]],\n",
      "\n",
      "         [[ 3.7275e+00,  1.4129e+01,  1.1769e+01],\n",
      "          [ 9.5122e+00,  1.2548e+01,  1.1275e+01],\n",
      "          [ 7.5099e+00,  3.9628e+00,  1.4818e+01]],\n",
      "\n",
      "         [[-8.9187e+00, -1.1220e+01, -4.6761e+00],\n",
      "          [-1.0532e+01, -7.3066e+00,  3.5394e-01],\n",
      "          [-5.2563e+00, -3.3762e+00,  1.6459e+00]],\n",
      "\n",
      "         [[ 3.4666e+00,  1.9505e+00,  3.1032e+00],\n",
      "          [ 4.0992e+00,  7.5455e+00,  7.3310e+00],\n",
      "          [ 7.7600e+00,  6.5864e+00,  1.2399e+00]],\n",
      "\n",
      "         [[-1.6519e+01, -7.2758e+00, -1.1837e+01],\n",
      "          [-1.0312e+01, -1.1195e+01, -7.9870e+00],\n",
      "          [-3.1562e+00, -1.3690e+01, -1.4919e+00]],\n",
      "\n",
      "         [[ 9.0969e-01,  1.4270e+01,  2.4964e+00],\n",
      "          [ 2.6022e+00,  5.8724e+00,  1.1947e+01],\n",
      "          [ 1.5210e+00,  4.3964e+00,  5.6000e+00]],\n",
      "\n",
      "         [[-5.7555e+00, -2.9475e+00, -5.3105e+00],\n",
      "          [-2.9881e+00, -1.6868e+01, -1.0241e+01],\n",
      "          [-1.5727e+01, -1.4173e+01, -1.3952e+01]]]],\n",
      "       grad_fn=<ConvolutionBackward0>) torch.Size([3, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"conv(x), conv(x)のサイズ: \\n\", conv(x), conv(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorchの勾配について, 最適化の方法編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PytorchのTensorには.data, .grad, .grad_fnという属性があります。<br>\n",
    "dataはテンソルそのものです。<br>gradは損失関数により計算される最適化のためにパラメーターを動かす方向を表します。backwardメソッドにより加算されます。<br>\n",
    "grad_fnはどのTensorを使ってどう作られたかを表すものです。自動微分の計算グラフ構築などに用いられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor.data:  tensor([1., 2., 3.])\n",
      "Tensor.grad:  None\n",
      "Tensor.grad_fn:  None\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1.,2.,3.]).to(torch.float32)\n",
    "a.requires_grad = True #勾配をTrueに\n",
    "print(\"Tensor.data: \", a.data)\n",
    "print(\"Tensor.grad: \",a.grad)\n",
    "print(\"Tensor.grad_fn: \",a.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まだ計算がなされていないので、Tensorのgradには勾配が計算されていない, ここで新たなTensorを制作し, <br>$(\\rm{Tensor1} - \\rm{Tensor2})^{2}$の平均を計算して勾配を計算してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = torch.pow(Tensor1-Tensor2, 2):  tensor(9., grad_fn=<MeanBackward0>)\n",
      "Tensor1.grad: \n",
      " tensor([-2., -2., -2.])\n",
      "Tensor2.grad: \n",
      " tensor([2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "b = torch.Tensor([4.,5.,6.]).to(torch.float32)\n",
    "b.requires_grad = True #勾配をTrueに\n",
    "loss = torch.pow(a-b, 2).mean()\n",
    "print(\"loss = torch.pow(Tensor1-Tensor2, 2): \", loss)\n",
    "loss.backward()\n",
    "print(\"Tensor1.grad: \\n\", a.grad)\n",
    "print(\"Tensor2.grad: \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算グラフはtorchvizのmake_dot関数で表示ができます。正しくモデルが制作できるか気になったら確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n -->\n<!-- Pages: 1 -->\n<svg width=\"226pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 226.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-322 222,-322 222,4 -4,4\"/>\n<!-- 140640054518864 -->\n<g id=\"node1\" class=\"node\">\n<title>140640054518864</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"136,-30.5 82,-30.5 82,0 136,0 136,-30.5\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-17\" font-family=\"monospace\" font-size=\"10.00\">Loss</text>\n<text text-anchor=\"middle\" x=\"109\" y=\"-5.75\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140640869181808 -->\n<g id=\"node2\" class=\"node\">\n<title>140640869181808</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"156,-85.75 62,-85.75 62,-66.5 156,-66.5 156,-85.75\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-72.25\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140640869181808&#45;&gt;140640054518864 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140640869181808&#45;&gt;140640054518864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109,-66.18C109,-59.65 109,-50.45 109,-41.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-41.78 109,-31.78 105.5,-41.78 112.5,-41.78\"/>\n</g>\n<!-- 140640869181904 -->\n<g id=\"node3\" class=\"node\">\n<title>140640869181904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-141 65,-141 65,-121.75 153,-121.75 153,-141\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-127.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140640869181904&#45;&gt;140640869181808 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140640869181904&#45;&gt;140640869181808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109,-121.58C109,-114.92 109,-105.49 109,-97.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-97.11 109,-87.11 105.5,-97.11 112.5,-97.11\"/>\n</g>\n<!-- 140640869181664 -->\n<g id=\"node4\" class=\"node\">\n<title>140640869181664</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-196.25 65,-196.25 65,-177 153,-177 153,-196.25\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-182.75\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140640869181664&#45;&gt;140640869181904 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140640869181664&#45;&gt;140640869181904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109,-176.83C109,-170.17 109,-160.74 109,-152.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-152.36 109,-142.36 105.5,-152.36 112.5,-152.36\"/>\n</g>\n<!-- 140640869181952 -->\n<g id=\"node5\" class=\"node\">\n<title>140640869181952</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-251.5 0,-251.5 0,-232.25 100,-232.25 100,-251.5\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140640869181952&#45;&gt;140640869181664 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140640869181952&#45;&gt;140640869181664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M60.01,-231.84C68.54,-224.15 81,-212.9 91.22,-203.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"93.06,-206.82 98.14,-197.52 88.37,-201.63 93.06,-206.82\"/>\n</g>\n<!-- 140640482625952 -->\n<g id=\"node6\" class=\"node\">\n<title>140640482625952</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"79,-318 21,-318 21,-287.5 79,-287.5 79,-318\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-304.5\" font-family=\"monospace\" font-size=\"10.00\">Tensor1</text>\n<text text-anchor=\"middle\" x=\"50\" y=\"-293.25\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 140640482625952&#45;&gt;140640869181952 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140640482625952&#45;&gt;140640869181952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50,-287.2C50,-279.87 50,-270.87 50,-262.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-262.95 50,-252.95 46.5,-262.95 53.5,-262.95\"/>\n</g>\n<!-- 140640869181568 -->\n<g id=\"node7\" class=\"node\">\n<title>140640869181568</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"218,-251.5 118,-251.5 118,-232.25 218,-232.25 218,-251.5\"/>\n<text text-anchor=\"middle\" x=\"168\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140640869181568&#45;&gt;140640869181664 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140640869181568&#45;&gt;140640869181664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.99,-231.84C149.46,-224.15 137,-212.9 126.78,-203.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"129.63,-201.63 119.86,-197.52 124.94,-206.82 129.63,-201.63\"/>\n</g>\n<!-- 140640495480080 -->\n<g id=\"node8\" class=\"node\">\n<title>140640495480080</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"197,-318 139,-318 139,-287.5 197,-287.5 197,-318\"/>\n<text text-anchor=\"middle\" x=\"168\" y=\"-304.5\" font-family=\"monospace\" font-size=\"10.00\">Tensor2</text>\n<text text-anchor=\"middle\" x=\"168\" y=\"-293.25\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 140640495480080&#45;&gt;140640869181568 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140640495480080&#45;&gt;140640869181568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168,-287.2C168,-279.87 168,-270.87 168,-262.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-262.95 168,-252.95 164.5,-262.95 171.5,-262.95\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fe9810c68b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "graph = make_dot(loss,params = {\"Tensor1\": a,\"Tensor2\": b, \"Loss\": loss})\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配計算を適用しているTensorの勾配計算を一時的に停止するには.detachメソッドを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1.detach():  tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor1.detach(): \", a.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with torch.no_grad():と書くことで, withブロックが適用される範囲では勾配計算が停止されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradが適用されている場合のTensor1 + Tensor2:  tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
      "gradが適用されていない場合のTensor1 + Tensor2:  tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "add1 = a + b\n",
    "with torch.no_grad():\n",
    "    add2 = a + b\n",
    "print(\"gradが適用されている場合のTensor1 + Tensor2: \", add1)\n",
    "print(\"gradが適用されていない場合のTensor1 + Tensor2: \", add2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では実際にモデルを定義して学習するところまでをやってみましょう。<br>今回はモデル定義編で制作したlinearクラスを使って学習していきましょう。<br>\n",
    "データはmake_moonsを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "data, label = make_moons(100)\n",
    "plt.scatter(data[label == 0][:,0],data[label == 0][:,1], s = 10, color = \"blue\")\n",
    "plt.scatter(data[label == 1][:,0],data[label == 1][:,1], s = 10, color = \"red\", marker = \"x\")\n",
    "plt.legend([\"label = 0\", \"label = 1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データとラベルのTensor化\n",
    "from torch import optim\n",
    "data = torch.Tensor(data)\n",
    "label = torch.Tensor(label).view(-1,1)\n",
    "data = (data - data.mean(axis = 0))/data.std(axis = 0) #平均で引いて標準偏差で割っておく。これで精度改善につながる。\n",
    "#モデル定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = linear(in_dim, hidden_dim)\n",
    "        self.relu = relu\n",
    "        self.l2 = linear(hidden_dim, out_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上位APIを使う場合のコードは以下の通りとなります。\n",
    "#class Net(nn.Module):\n",
    "#    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "#        super().__init__()\n",
    "#        self.l1 = nn.Linear(in_dim, hidden_dim)\n",
    "#        nn.init.uniform_(self.l1.weight, a = -np.sqrt(6/in_dim), b = np.sqrt(6/in_dim))\n",
    "#        self.relu = nn.ReLU()\n",
    "#        self.l2 = nn.Linear(hidden_dim, out_dim)\n",
    "#        nn.init.uniform_(self.l2.weight, a = -np.sqrt(6/hidden_dim), b = np.sqrt(6/hidden_dim))\n",
    "#        #自作したlinearはHe uniformで実装したのでnn.initで初期化の方法を指定してあげなければならない。\n",
    "#    def forward(self, x):\n",
    "#        x = self.l1(x)\n",
    "#        x = self.relu(x)\n",
    "#        x = self.l2(x)\n",
    "#        return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、学習のための最適化アルゴリズムと損失関数を決定します。<br>\n",
    "最適化アルゴリズムと損失関数は上位APIのものを用います。<br>\n",
    "損失関数のスクラッチ実装は簡単なのでここでは説明をしませんが、自作の最適化手法を制作する方法はAppendixに記します。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習で用いられる最適化の手法としては以下の記事などを参考にするのがおすすめです。<br>\n",
    "[【決定版】スーパーわかりやすい最適化アルゴリズム -損失関数からAdamとニュートン法-](https://qiita.com/omiita/items/1735c1d048fe5f611f80)<br>\n",
    "損失関数には今回は二値分類のためBinaryCrossEntropy(BCE)を用います。何故BCEを用いるのかに関しては、<br>\n",
    "「尤度関数の最大化」というワードについて調べてみると良いでしょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(2,30,1)\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  tensor(0.8100)\n",
      "acc:  tensor(0.8700)\n",
      "acc:  tensor(0.8800)\n",
      "acc:  tensor(0.8800)\n",
      "acc:  tensor(0.8800)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.8900)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9000)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9100)\n",
      "acc:  tensor(0.9200)\n",
      "acc:  tensor(0.9200)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9300)\n",
      "acc:  tensor(0.9400)\n",
      "acc:  tensor(0.9400)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9500)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9600)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9700)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9800)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(0.9900)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n",
      "acc:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(data)\n",
    "    loss = criterion(y_pred, label) #ここ違うけどまあ\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            y_pred_label = torch.where(y_pred > 0.5, torch.ones_like(y_pred), torch.zeros_like(y_pred))\n",
    "            y_pred_label.to(torch.float32)\n",
    "            print(\"acc: \", (y_pred_label == label).sum() / len(y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初めての学習は喜んで欲しいので正解率が100%近くになるように工夫しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "### - BatchNormalization, Dropout, RNN, LSTMの低レベルAPI実装\n",
    "### - カスタムOptimizerの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendixで使うライブラリのimport\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNormalization, Dropout, RNN, LSTMの低レベルAPI実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNormalizationの実装<br>\n",
    "以下の画像の式に従って計算を行います。<br>\n",
    "![](https://standardfrancis.files.wordpress.com/2015/04/screenshot-from-2015-04-16-133436.png?w=1008)<br>\n",
    "画像元http://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/43442.pdf<br>\n",
    "ただし、上の式において```γとβは学習可能(もしくは学習対象)なパラメーター```であることに注意してパラメーターのモデル構築を行わなければいけません。<br>\n",
    "例えば線形層l1, l2という二つの層があったとき、一つのBN(BatchNormalization)層を(BN,l1,BN,l2)のように用いてはいけません。<br>\n",
    "このBN層ではl1の入力に関してγとβが最適化されてしまっているためです。もし2つの線形層に関してBN層を用いたい場合は<br>BN層をBN1, BN2のように別々に定義を行い、\n",
    "(BN1,l1,BN2,l2)のようにしなければいけません。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*実装上の注意\n",
    "- BatchNormalization2dの入力は(batch_size, Channel, Height, Width)を想定しています。<br>\n",
    "- meanとstdの計算において、torch.mean(Tensor, (0,2,3), keepdim = True)のように書きます<br>\n",
    "  これは、Pytorchの公式ドキュメントによると、二つ目の引数はdimensionを指定する引数であり、<br>\n",
    "  (0, 2, 3)の意味は入力されたバッチの画像全体の平均をチャンネルごとに求めるという意味です。<br>\n",
    "  keepdim=Trueにすることで計算の際にブロードキャスト機能を用いても大丈夫なようになっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mean, torch.stdの使い方にもう少し慣れておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.mean(Tensor, (0,2,3),keepdim=True):\n",
      " tensor([[[[0.5019]],\n",
      "\n",
      "         [[0.4995]],\n",
      "\n",
      "         [[0.5032]]]])\n",
      "torch.std(Tensor, (0,2,3),keepdim=True):\n",
      " tensor([[[[0.2894]],\n",
      "\n",
      "         [[0.2891]],\n",
      "\n",
      "         [[0.2877]]]])\n"
     ]
    }
   ],
   "source": [
    "#入力のサンプル\n",
    "x = torch.rand(32, 3 ,28, 28)\n",
    "print(\"torch.mean(Tensor, (0,2,3),keepdim=True):\\n\", torch.mean(x, (0,2,3),keepdim=True))\n",
    "print(\"torch.std(Tensor, (0,2,3),keepdim=True):\\n\", torch.std(x, (0,2,3),keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNormalizationの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization2d(nn.Module):\n",
    "    def __init__(self, shape, epsilon = 1e-10):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(shape).float())\n",
    "        self.beta = nn.Parameter(torch.zeros(shape).float())\n",
    "        self.epsilon = epsilon\n",
    "    def forward(self,x):\n",
    "        mean_x = torch.mean(x, (0,2,3), keepdim=True)\n",
    "        std_x = torch.std(x, (0,2,3), keepdim=True)\n",
    "        normalized_x = (x - mean_x) / torch.sqrt(std_x**2+self.epsilon)\n",
    "        return self.gamma * normalized_x + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropoutの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 過学習を抑制するためのレイヤーの一つです。\n",
    "- Dropoutは特定のレイヤーの出力を学習時にある確率`dropout_ratio`で0にすることで、データが欠損しても正しく認識ができるようにします。<br>これはモデルのロバスト性の向上に寄与します。<br>\n",
    "- 学習時は確率`dropout_ratio`で0にしたレイヤーを用いて学習を進めますが、推論時には全てのレイヤーの変数を使うため、<br>\n",
    "値の調整のために出力値には1 - dropout_ratioを乗算します。<br>\n",
    "- また、そのためにはレイヤーに訓練モードと推論モードを切り替える機能をつける必要があります。<br>これはnn.Moduleを継承することで実現できます。\n",
    "  nn.Moduleを継承したあとはself.trainingというattributeが追加されており、<br>これにより訓練モードか推論モードかを識別することができます。<br>\n",
    "  切り替える際は、trainメソッドやevalメソッドで切り替えることができます。<br>\n",
    "  詳しくは公式ドキュメントをご覧ください。https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-23_at_6.19.24_PM.png\" alt=\"\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropoutの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, dropout_ratio = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training: #self.trainingは訓練モードと推論モードを識別する変数(bool)\n",
    "            mask = torch.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * mask.to(x.device)\n",
    "        else:\n",
    "            return x * (1 - self.dropout_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout実行例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算元のテンソル: \n",
      " tensor([[[[0.9262, 0.9456, 0.8017, 0.1791, 0.1094],\n",
      "          [0.5887, 0.9673, 0.2296, 0.9485, 0.0955],\n",
      "          [0.2466, 0.0342, 0.7073, 0.6685, 0.1365],\n",
      "          [0.3560, 0.0707, 0.9101, 0.3922, 0.6371],\n",
      "          [0.0169, 0.4367, 0.4341, 0.9345, 0.6618]]]])\n",
      "訓練モードの場合の出力: \n",
      " tensor([[[[0.9262, 0.9456, 0.8017, 0.1791, 0.0000],\n",
      "          [0.5887, 0.9673, 0.0000, 0.0000, 0.0955],\n",
      "          [0.0000, 0.0000, 0.7073, 0.0000, 0.0000],\n",
      "          [0.3560, 0.0000, 0.0000, 0.3922, 0.0000],\n",
      "          [0.0169, 0.0000, 0.4341, 0.0000, 0.0000]]]])\n",
      "推論モードの場合の出力: \n",
      " tensor([[[[0.4631, 0.4728, 0.4008, 0.0895, 0.0547],\n",
      "          [0.2943, 0.4837, 0.1148, 0.4742, 0.0477],\n",
      "          [0.1233, 0.0171, 0.3537, 0.3343, 0.0683],\n",
      "          [0.1780, 0.0353, 0.4551, 0.1961, 0.3185],\n",
      "          [0.0085, 0.2183, 0.2171, 0.4673, 0.3309]]]])\n"
     ]
    }
   ],
   "source": [
    "dropout = Dropout(dropout_ratio=0.5)\n",
    "x = torch.rand(1, 1, 5, 5)\n",
    "print(\"計算元のテンソル: \\n\", x)\n",
    "print(\"訓練モードの場合の出力: \\n\", dropout(x))\n",
    "dropout.eval() #推論モードに移行\n",
    "print(\"推論モードの場合の出力: \\n\", dropout(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNを実装する前に簡単なRNNの解説を行います。<br>\n",
    "RNNは系列データを扱うモデルである。<br>\n",
    "系列データとはデータの並び方に重要性があるデータである。<br>\n",
    "例えば株価の変化は時間と共に変動していくため、順序を入れ替えて処理をしてはならないし、<br>\n",
    "自然言語は文脈というものがあるので、順序を入れ替えて処理をしてはいけない。といったふうなものが系列データの例になります<br>\n",
    "RNNはこの前の状態からの影響を再帰的に行列演算する形で表現しています。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時刻$t$における入力を$x^{(t)}$、隠れ層を$h^{(t)}$, 出力を$o^{(t)}$とすると、<br>\n",
    "下の例はRNNの隠れ層から隠れ層への再帰を行うRNNになります。<br>\n",
    "他にも出力から隠れ層までの再帰、出力から出力までの再帰を行うRNNのアーキテクチャもあります。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/440px-Recurrent_neural_network_unfold.svg.png\" height = \"100%\" width = \"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の図の隠れ層から隠れ層までの再帰を行うRNNをもう少し数式的に理解を試みます。<br>\n",
    "$σ_{h}, σ_{o}$を隠れ層、出力の活性化関数, $b_{h}, b_{o}$を隠れ層、出力のバイアスベクトルとし、$W, V, U$を上の図の行列とすると、<br>\n",
    "時刻$t$における隠れ層と出力は以下のように計算できます。<br>\n",
    "$$\n",
    "h^{(t)} = σ_{h}(Vh^{(t-1)}+Ux^{(t)}+b_{h}) \\\\\n",
    "o^{(t)} = σ_{o}(Wh^{(t)}+b_{o})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理論的にはこの式で問題ないのですが、実装上は、<br>\n",
    "(batch_size, sequence_length, num_features)といった感じで、2次元目に系列長、3次元目に変数の数が追加されるため、<br>\n",
    "実際は、\n",
    "$$\n",
    "h^{(t)} = σ_{h}(h^{(t-1)}V^{T}+x^{(t)}U^{T}+b_{h}) \\\\\n",
    "o^{(t)} = σ_{o}(h^{(t)}W^{T}+b_{o})\n",
    "$$\n",
    "が計算されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式ドキュメントによると、内部では\n",
    "$$\n",
    "h^{(t)} =  σ_{h}(h^{(t-1)}{W_{hh}}^{T}+x^{(t)}{W_{ih}}^{T}+b_{ih}++b_{hh})\n",
    "$$\n",
    "のように計算されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このことを上位API torch.nn.RNNを用いて確かめます。<br>\n",
    "上位APIのRNNの引数の意味は<br>\n",
    "<br>\n",
    "input_size: 入力$x^{(t)}$の変数数<br>\n",
    "hidden_size: 隠れ層$h^{(t)}$の変数数<br>\n",
    "num_layers: 再帰層の数<br>\n",
    "batch_first: Trueだと入力は(batch, seq, feature)として扱われ、Falseだと(seq, batch, feature)として扱われる。<br>\n",
    "<br>\n",
    "また、デフォルトでの活性化関数はtanhとなっております。<br>\n",
    "nn.RNN.forwardの出力は出力系列yと、最終状態hとなっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 5).float()\n",
    "rnn = nn.RNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "Wih = rnn.weight_ih_l0.data\n",
    "Whh = rnn.weight_hh_l0.data\n",
    "bih = rnn.bias_ih_l0.data\n",
    "bhh = rnn.bias_hh_l0.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.RNNの出力: \n",
      " tensor([[[ 0.5247, -0.4095, -0.0820, -0.4619,  0.2461],\n",
      "         [ 0.3221, -0.7121, -0.4102, -0.3323, -0.1252],\n",
      "         [-0.0465, -0.6660, -0.1830, -0.3196, -0.1323]]],\n",
      "       grad_fn=<TransposeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(\"nn.RNNの出力: \\n\", rnn(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time t = 0\n",
      "隠れ層h: tensor([ 0.5247, -0.4095, -0.0820, -0.4619,  0.2461])\n",
      "time t = 1\n",
      "隠れ層h: tensor([ 0.3221, -0.7121, -0.4102, -0.3323, -0.1252])\n",
      "time t = 2\n",
      "隠れ層h: tensor([-0.0465, -0.6660, -0.1830, -0.3196, -0.1323])\n"
     ]
    }
   ],
   "source": [
    "for t in range(3):\n",
    "    print(f\"time t = {t}\")\n",
    "    x_t = x[0][t]\n",
    "    if t == 0:\n",
    "        h_t = torch.zeros_like(x_t)\n",
    "    h_t = torch.tanh(x_t @ Wih.transpose(0,1) + h_t @ Whh.transpose(0,1) + bih + bhh)\n",
    "    print(\"隠れ層h:\", h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各tにおける隠れ層の値がnn.RNNの0行目, 1行目, 2行目に当たることが確認できたと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNの実装<br>\n",
    "今回は簡単のため、input_size, hidden_size, batch_firstをinitの引数とする1層のSimpleRNNを実装します。<br>\n",
    "本来のnn.RNNは他の引数もあります。是非公式ドキュメントをご覧ください。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first = False)->None:\n",
    "        \"\"\"\n",
    "        input_size: 入力x^{t}の変数数\n",
    "        hidden_size: 隠れ層h^{t}の変数数\n",
    "        num_layers: 再帰層の数\n",
    "        batch_first: Trueだと入力は(batch, seq, feature)として扱われ、Falseだと(seq, batch, feature)として扱われる。\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        公式ドキュメントにのっとり、weight, bias共にk = 1/hidden_sizeとした時、Uniform(-sqrt(k), sqrt(k))で初期化する。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        k = 1 / hidden_size\n",
    "        self.weight_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size, input_size))).float())\n",
    "        self.weight_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size, hidden_size))).float())\n",
    "        self.bias_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size))).float())\n",
    "        self.bias_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (hidden_size))).float())\n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        実装上の注意点\n",
    "        h0がNoneなら系列の始めは隠れ層の値が0であることに注意すること\n",
    "        出力の形状に気をつけること今回はtorch.catで配列を結合し、unsqueezeメソッドなどを用いて次元を調整している。\n",
    "        同じ時間のものは計算に使う行列は共通のため、行列演算を用いて計算を早くしている。2重でforループを回すと遅い\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            #(seq, batch, feature)->(batch, seq, feature)へ\n",
    "            x = x.transpose(0,1)\n",
    "        sequence_length = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "        output_all = torch.empty(size = (batch_size, 0, self.input_size)).to(x.device)\n",
    "        final_hidden_state = torch.empty(size = (0 , self.input_size)).to(x.device)\n",
    "        if h0 == None:\n",
    "            h_t = torch.zeros_like(x[:,0,:]).to(x.device)\n",
    "        else:\n",
    "            h_t = h0.to(x.device)\n",
    "        for t in range(sequence_length):\n",
    "            h_t = torch.tanh(x[:,t,:] @ self.weight_ih_l0.transpose(0,1) + \\\n",
    "                h_t @ self.weight_hh_l0.transpose(0,1) + self.bias_hh_l0 + self.bias_ih_l0)\n",
    "            if t != 0:\n",
    "                output_all = torch.cat([output_all, h_t.reshape(-1,1,self.input_size)],dim = 1)\n",
    "            else:\n",
    "                output_all = h_t.reshape(-1,1,self.input_size)\n",
    "            #final_hidden_state = torch.cat([final_hidden_state, output[-1].unsqueeze(0)])\n",
    "        if not self.batch_first:\n",
    "            return output_all.transpose(0,1), output_all[:,-1,:].unsqueeze(0)\n",
    "        return output_all, output_all[:,-1,:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力があっているか一応確認しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータ\n",
    "x = torch.rand(3, 4, 5).float()\n",
    "simplernn = SimpleRNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "rnn = nn.RNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "#使う重みを等しくする\n",
    "simplernn.weight_ih_l0 = rnn.weight_ih_l0\n",
    "simplernn.weight_hh_l0 = rnn.weight_hh_l0\n",
    "simplernn.bias_ih_l0 = rnn.bias_ih_l0\n",
    "simplernn.bias_hh_l0 = rnn.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNNの自前実装: \n",
      "出力系列y: \n",
      "tensor([[[-0.5359,  0.1395,  0.1925, -0.0780, -0.1734],\n",
      "         [-0.5639, -0.2767,  0.1205,  0.1259,  0.3919],\n",
      "         [-0.6944,  0.2234,  0.5389,  0.0120, -0.2438],\n",
      "         [-0.6712, -0.2667, -0.1013,  0.2526, -0.0389]],\n",
      "\n",
      "        [[-0.4195, -0.0752,  0.0493, -0.0680,  0.1195],\n",
      "         [-0.4027, -0.0755, -0.1106, -0.2566, -0.1473],\n",
      "         [-0.3427, -0.0581, -0.0503, -0.1410, -0.0747],\n",
      "         [-0.4043,  0.0552, -0.1264,  0.1327, -0.1024]],\n",
      "\n",
      "        [[-0.3435, -0.0501, -0.0369, -0.2350,  0.0898],\n",
      "         [-0.5118,  0.1574,  0.0233, -0.0241,  0.0725],\n",
      "         [-0.6236, -0.0572,  0.2670, -0.0617, -0.0087],\n",
      "         [-0.4173, -0.2909,  0.0147,  0.1253, -0.1422]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "最終状態h: \n",
      "tensor([[[-0.6712, -0.2667, -0.1013,  0.2526, -0.0389],\n",
      "         [-0.4043,  0.0552, -0.1264,  0.1327, -0.1024],\n",
      "         [-0.4173, -0.2909,  0.0147,  0.1253, -0.1422]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "SimpleRNNの出力の形状: \n",
      "出力系列y: \n",
      "torch.Size([3, 4, 5])\n",
      "最終状態h: \n",
      "torch.Size([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimpleRNNの自前実装: \\n出力系列y: \\n{simplernn(x)[0]}\\n最終状態h: \\n{simplernn(x)[1]}\")\n",
    "print(f\"SimpleRNNの出力の形状: \\n出力系列y: \\n{simplernn(x)[0].shape}\\n最終状態h: \\n{simplernn(x)[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.RNN: \n",
      "出力系列y: \n",
      "tensor([[[-0.5359,  0.1395,  0.1925, -0.0780, -0.1734],\n",
      "         [-0.5639, -0.2767,  0.1205,  0.1259,  0.3919],\n",
      "         [-0.6944,  0.2234,  0.5389,  0.0120, -0.2438],\n",
      "         [-0.6712, -0.2667, -0.1013,  0.2526, -0.0389]],\n",
      "\n",
      "        [[-0.4195, -0.0752,  0.0493, -0.0680,  0.1195],\n",
      "         [-0.4027, -0.0755, -0.1106, -0.2566, -0.1473],\n",
      "         [-0.3427, -0.0581, -0.0503, -0.1410, -0.0747],\n",
      "         [-0.4043,  0.0552, -0.1264,  0.1327, -0.1024]],\n",
      "\n",
      "        [[-0.3435, -0.0501, -0.0369, -0.2350,  0.0898],\n",
      "         [-0.5118,  0.1574,  0.0233, -0.0241,  0.0725],\n",
      "         [-0.6236, -0.0572,  0.2670, -0.0617, -0.0087],\n",
      "         [-0.4173, -0.2909,  0.0147,  0.1253, -0.1422]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "最終状態h: \n",
      "tensor([[[-0.6712, -0.2667, -0.1013,  0.2526, -0.0389],\n",
      "         [-0.4043,  0.0552, -0.1264,  0.1327, -0.1024],\n",
      "         [-0.4173, -0.2909,  0.0147,  0.1253, -0.1422]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "nn.RNNの出力の形状: \n",
      "出力系列y: \n",
      "torch.Size([3, 4, 5])\n",
      "最終状態h: \n",
      "torch.Size([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.RNN: \\n出力系列y: \\n{rnn(x)[0]}\\n最終状態h: \\n{rnn(x)[1]}\")\n",
    "print(f\"nn.RNNの出力の形状: \\n出力系列y: \\n{rnn(x)[0].shape}\\n最終状態h: \\n{rnn(x)[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力の値と形状は同じになっていることがわかりました。しかし、grad_fnの表示が異なっているため、本当にカスタムなモデルを制作しない限りはnn.RNNを使った方が良さそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの実装の際も、RNNの実装と同じように内部ではどうなっているのかを理解しながら組んでいこうと思います。<br>\n",
    "一度RNNを組めてしまえばRNNに行列演算が少し追加された程度なので大丈夫なはずです。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://production-media.paperswithcode.com/methods/1_PJ5atpFStpNWE_XpB4e8qQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の画像によると、LSTMは入力$x_{t}$, $c_{t-1}$, $h_{t-1}$を受け取って$c_{t}, h_{t}$を出力するものであるとわかる。<br>\n",
    "$c_{t}, h_{t}$はinput $i_{t}$, forget $f_{t}$, cell $g_{t}$ output $o_{t}$を用いて次のように計算される。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "i_{t} = \\text{sigmoid}(W_{ii}x_{t}+b_{ii}+W_{hi}h_{t-1}+b_{hi}) \\\\\n",
    "f_{t} = \\text{sigmoid}(W_{if}x_{t}+b_{if}+W_{hf}h_{t-1}+b_{hf}) \\\\\n",
    "g_{t} = \\tanh(W_{ig}x_{t}+b_{ig}+W_{hg}h_{t-1}+b_{hg}) \\\\\n",
    "o_{t} = \\text{sigmoid}(W_{io}x_{t}+b_{io}+W_{ho}h_{t-1}+b_{ho}) \\\\\n",
    "c_{t} = f_{t} \\odot c_{t-1} + i_{t} \\odot g_{t} \\\\\n",
    "h_{t} = o_{t} \\odot \\tanh(c_{t}) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを1 epoch分計算してみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchでは例によって工夫がなされている。\n",
    "例えば、$x_{t}$が計算に使われるような行列を<br>$W_{ih} \\in M_{4hidden\\_size \\times input\\_size}$としてまとめて、\n",
    "$h_{t}$が計算に使われるような行列を$W_{hh}  \\in M_{4hidden\\_size \\times input\\_size} $としてまとめ、<br>\n",
    "それぞれのバイアスベクトルを$b_{ih}, b_{hh}$としてまとめた上で、まずは以下の量で定義される$z_{t}$を計算する。\n",
    "\n",
    "$$\n",
    "z_{t} = x_{t}W_{ih}^{T} + h_{t}W_{hh}^{T} + b_{ih} + b_{hh}\n",
    "$$\n",
    "$z_{t}$をもとめたあと、各量は以下の通りに計算される\n",
    "$$\n",
    "i_{t} = \\text{sigmoid}(z_t[:,:\\text{hidden\\_size}]) \\\\\n",
    "f_{t} = \\text{sigmoid}(z_t[:,\\text{hidden\\_size:2hidden\\_size}]) \\\\\n",
    "g_{t} = \\tanh(z_t[:,\\text{2hidden\\_size:3hidden\\_size}]) \\\\\n",
    "o_{t} = \\text{sigmoid}(z_t[:,\\text{3hidden\\_size:}]) \\\\\n",
    "c_{t} = f_{t} \\odot c_{t-1} + i_{t} \\odot g_{t} \\\\\n",
    "h_{t} = o_{t} \\odot \\tanh(c_{t}) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z_t$は何度も同じような計算をするところを、まとめて行ってくれているものである。\n",
    "このことを実際に確かめてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "x = torch.rand(2, 3, 5)\n",
    "lstm = nn.LSTM(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "w_ih = lstm.weight_ih_l0\n",
    "w_hh = lstm.weight_hh_l0\n",
    "b_ih = lstm.bias_ih_l0\n",
    "b_hh = lstm.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.LSTMの出力: h_t:\n",
      "tensor([[[ 0.1013, -0.0203, -0.0525, -0.1826,  0.0234],\n",
      "         [ 0.1901, -0.0321, -0.1151, -0.3402,  0.0035],\n",
      "         [ 0.1672,  0.0201, -0.0789, -0.3275,  0.0392]],\n",
      "\n",
      "        [[ 0.1491, -0.0142, -0.0573, -0.2293,  0.0136],\n",
      "         [ 0.2079, -0.0294, -0.1400, -0.4399,  0.0174],\n",
      "         [ 0.2198, -0.0008, -0.1502, -0.4850,  0.0105]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "Last h_t and c_n:\n",
      "(tensor([[[ 0.1672,  0.0201, -0.0789, -0.3275,  0.0392],\n",
      "         [ 0.2198, -0.0008, -0.1502, -0.4850,  0.0105]]],\n",
      "       grad_fn=<StackBackward0>), tensor([[[ 0.4408,  0.0427, -0.1741, -0.5500,  0.0953],\n",
      "         [ 0.4996, -0.0016, -0.3665, -0.9227,  0.0260]]],\n",
      "       grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.LSTMの出力: h_t:\\n{lstm(x)[0]}\\nLast h_t and c_n:\\n{lstm(x)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0: \n",
      "h_t:\n",
      "tensor([[ 0.1013, -0.0203, -0.0525, -0.1826,  0.0234],\n",
      "        [ 0.1491, -0.0142, -0.0573, -0.2293,  0.0136]], grad_fn=<MulBackward0>)\n",
      "c_t:\n",
      "tensor([[ 0.2525, -0.0467, -0.1169, -0.2803,  0.0499],\n",
      "        [ 0.3685, -0.0286, -0.1292, -0.3608,  0.0313]], grad_fn=<AddBackward0>)\n",
      "time: 1: \n",
      "h_t:\n",
      "tensor([[ 0.1901, -0.0321, -0.1151, -0.3402,  0.0035],\n",
      "        [ 0.2079, -0.0294, -0.1400, -0.4399,  0.0174]], grad_fn=<MulBackward0>)\n",
      "c_t:\n",
      "tensor([[ 0.4288, -0.0628, -0.2823, -0.5099,  0.0082],\n",
      "        [ 0.4662, -0.0631, -0.3319, -0.7277,  0.0393]], grad_fn=<AddBackward0>)\n",
      "time: 2: \n",
      "h_t:\n",
      "tensor([[ 0.1672,  0.0201, -0.0789, -0.3275,  0.0392],\n",
      "        [ 0.2198, -0.0008, -0.1502, -0.4850,  0.0105]], grad_fn=<MulBackward0>)\n",
      "c_t:\n",
      "tensor([[ 0.4408,  0.0427, -0.1741, -0.5500,  0.0953],\n",
      "        [ 0.4996, -0.0016, -0.3665, -0.9227,  0.0260]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 5\n",
    "for t in range(3):\n",
    "    x_t = x[:,t,:]\n",
    "    if t == 0:\n",
    "        h_t = torch.zeros_like(x_t)\n",
    "        c_t = torch.zeros_like(x_t)\n",
    "    z_t = x_t @ w_ih.transpose(0,1) + h_t @ w_hh.transpose(0,1) + b_ih + b_hh\n",
    "    #W_ii|W_if|W_ig|W_io\n",
    "    i_t = torch.sigmoid(z_t[:,:hidden_size])\n",
    "    f_t = torch.sigmoid(z_t[:,hidden_size:2*hidden_size])\n",
    "    g_t = torch.tanh(z_t[:,2*hidden_size:3*hidden_size])\n",
    "    o_t = torch.sigmoid(z_t[:,3*hidden_size:])\n",
    "    c_t = f_t * c_t + i_t * g_t\n",
    "    h_t = o_t * torch.tanh(c_t)\n",
    "    print(f\"time: {t}: \\nh_t:\\n{h_t}\\nc_t:\\n{c_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に確かめられたら、あとはRNNのように実装するだけである。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの実装<br>\n",
    "今回も簡単のため、input_size, hidden_size, batch_firstをinitの引数とする1層のSimpleLSTMを実装します。<br>\n",
    "本来のnn.LSTMは他の引数もあります。是非公式ドキュメントをご覧ください。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first = False)->None:\n",
    "        \"\"\"\n",
    "        input_size: 入力x^{t}の変数数\n",
    "        hidden_size: 隠れ層h^{t}の変数数\n",
    "        num_layers: 再帰層の数\n",
    "        batch_first: Trueだと入力は(batch, seq, feature)として扱われ、Falseだと(seq, batch, feature)として扱われる。\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        公式ドキュメントにのっとり、weight, bias共にk = 1/hidden_sizeとした時、Uniform(-sqrt(k), sqrt(k))で初期化する。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        k = 1 / hidden_size\n",
    "        self.weight_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size, input_size))).float())\n",
    "        self.weight_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size, hidden_size))).float())\n",
    "        self.bias_ih_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size))).float())\n",
    "        self.bias_hh_l0 = nn.Parameter(torch.Tensor(np.random.uniform(low = -np.sqrt(k), high = np.sqrt(k)\\\n",
    "            , size = (4*hidden_size))).float())\n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor = None, c0: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        実装上の注意点\n",
    "        h0がNoneなら系列の始めは隠れ層の値が0であることに注意すること\n",
    "        出力の形状に気をつけること今回はtorch.catで配列を結合し、unsqueezeメソッドなどを用いて次元を調整している。\n",
    "        同じ時間のものは計算に使う行列は共通のため、行列演算を用いて計算を早くしている。2重でforループを回すと遅い\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            #(seq, batch, feature)->(batch, seq, feature)へ\n",
    "            x = x.transpose(0,1)\n",
    "        sequence_length = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "        output_all = torch.empty(size = (batch_size, 0, self.input_size)).to(x.device)\n",
    "        if h0 == None and c0 == None:\n",
    "            h_t = torch.zeros_like(x[:,0,:]).to(x.device)\n",
    "            c_t = torch.zeros_like(x[:,0,:]).to(x.device)\n",
    "        elif h0 == None:\n",
    "            c_t = c0.to(x.device)\n",
    "        elif c0 == None:\n",
    "            h_t = h0.to(x.device)\n",
    "        else:\n",
    "            h_t = h0.to(x.device)\n",
    "            c_t = c0.to(x.device)\n",
    "        for t in range(sequence_length):\n",
    "            x_t = x[:,t,:]\n",
    "            z_t = x_t @ self.weight_ih_l0.transpose(0,1) + h_t @ self.weight_hh_l0.transpose(0,1) + self.bias_ih_l0 + self.bias_hh_l0\n",
    "            i_t = torch.sigmoid(z_t[:,:self.hidden_size])\n",
    "            f_t = torch.sigmoid(z_t[:,self.hidden_size:2*self.hidden_size])\n",
    "            g_t = torch.tanh(z_t[:,2*self.hidden_size:3*self.hidden_size])\n",
    "            o_t = torch.sigmoid(z_t[:,3*self.hidden_size:])\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            if t != 0:\n",
    "                output_all = torch.cat([output_all, h_t.reshape(-1,1,self.input_size)],dim = 1)\n",
    "            else:\n",
    "                output_all = h_t.reshape(-1,1,self.input_size)\n",
    "            #final_hidden_state = torch.cat([final_hidden_state, output[-1].unsqueeze(0)])\n",
    "        if not self.batch_first:\n",
    "            return output_all.transpose(0,1), (output_all[:,-1,:].unsqueeze(0), c_t.unsqueeze(0))\n",
    "        return output_all, (output_all[:,-1,:].unsqueeze(0), c_t.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく動作するか確かめてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3, 5)\n",
    "lstm = nn.LSTM(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "simplelstm = SimpleLSTM(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "simplelstm.weight_ih_l0 = lstm.weight_ih_l0\n",
    "simplelstm.weight_hh_l0 = lstm.weight_hh_l0\n",
    "simplelstm.bias_ih_l0 = lstm.bias_ih_l0\n",
    "simplelstm.bias_hh_l0 = lstm.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLSTMの自前実装: \n",
      "出力h_t: \n",
      "tensor([[[ 0.1229, -0.0468,  0.2288, -0.1165, -0.1437],\n",
      "         [ 0.0349,  0.0082,  0.2007, -0.0689, -0.1410],\n",
      "         [-0.0237, -0.0277,  0.1989, -0.1140, -0.1539]],\n",
      "\n",
      "        [[ 0.0553, -0.0228,  0.1809, -0.0706, -0.0899],\n",
      "         [ 0.0356,  0.0204,  0.2365, -0.0291, -0.1428],\n",
      "         [ 0.0963,  0.0178,  0.3161, -0.0694, -0.1907]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "最終状態h_t and c_t: \n",
      "tensor([[[-0.0237, -0.0277,  0.1989, -0.1140, -0.1539],\n",
      "         [ 0.0963,  0.0178,  0.3161, -0.0694, -0.1907]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[[-0.0735, -0.0763,  0.4845, -0.1839, -0.2721],\n",
      "         [ 0.2188,  0.0457,  0.5969, -0.1075, -0.2897]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "SimpleLSTMの出力の形状: \n",
      "出力h_t: \n",
      "torch.Size([2, 3, 5])\n",
      "最終状態h_t and c_t: \n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"SimpleLSTMの自前実装: \\n出力h_t: \\n{simplelstm(x)[0]}\\n最終状態h_t and c_t: \\n{simplelstm(x)[1][0]}\\n{simplelstm(x)[1][1]}\")\n",
    "print(f\"SimpleLSTMの出力の形状: \\n出力h_t: \\n{simplelstm(x)[0].shape}\\n最終状態h_t and c_t: \\n{simplelstm(x)[1][0].shape}\\n{simplelstm(x)[1][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.LSTMの出力: \n",
      "出力h_t: \n",
      "tensor([[[ 0.1229, -0.0468,  0.2288, -0.1165, -0.1437],\n",
      "         [ 0.0349,  0.0082,  0.2007, -0.0689, -0.1410],\n",
      "         [-0.0237, -0.0277,  0.1989, -0.1140, -0.1539]],\n",
      "\n",
      "        [[ 0.0553, -0.0228,  0.1809, -0.0706, -0.0899],\n",
      "         [ 0.0356,  0.0204,  0.2365, -0.0291, -0.1428],\n",
      "         [ 0.0963,  0.0178,  0.3161, -0.0694, -0.1907]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "最終状態h_t and c_t: \n",
      "tensor([[[-0.0237, -0.0277,  0.1989, -0.1140, -0.1539],\n",
      "         [ 0.0963,  0.0178,  0.3161, -0.0694, -0.1907]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.0735, -0.0763,  0.4845, -0.1839, -0.2721],\n",
      "         [ 0.2188,  0.0457,  0.5969, -0.1075, -0.2897]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "nn.LSTMの出力の形状: \n",
      "出力h_t: \n",
      "torch.Size([2, 3, 5])\n",
      "最終状態h_t and c_t: \n",
      "torch.Size([1, 2, 5])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.LSTMの出力: \\n出力h_t: \\n{lstm(x)[0]}\\n最終状態h_t and c_t: \\n{lstm(x)[1][0]}\\n{lstm(x)[1][1]}\")\n",
    "print(f\"nn.LSTMの出力の形状: \\n出力h_t: \\n{lstm(x)[0].shape}\\n最終状態h_t and c_t: \\n{lstm(x)[1][0].shape}\\n{lstm(x)[1][1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以上までで、LSTMの自前実装が完了しました。双方向LSTMなどの実装が残っていることを除けば、\n",
    "##### Attentionのスクラッチ実装まであともう少しです。\n",
    "##### レイヤーの実装の続きはAttention_from_scratch.ipynbで行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタムOptimizerの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤーに比べてOptimizerの実装の優先度は低いかもしれませんが、<br>\n",
    "それでも勉強していて新しいOptimizerのアイデアが浮かぶことがあるかもしれません。<br>\n",
    "例えば、Github上で「SAM」などと検索するとSAMと呼ばれるOptimizerの実装を見ることができます。<br>\n",
    "自分でOptimizerを設計したくなった時に困らないようにカスタムOptimizerの実装も解説していきます。<br>\n",
    "カスタムOptimizerは日本語記事がほとんどヒットしません。検索する際は公式ドキュメントや英語検索を行うと良いでしょう。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤーの制作の際はnn.Moduleの継承を行いました。Optimizerはtorch.optim.Optimizerの継承を行います。<br>\n",
    "nn.Moduleでは主にinitとforwardのオーバーライドを行いました。optim.optimizerではinitとstepのオーバーライドを行います。<br>\n",
    "- initの引数<br>\n",
    "  ```params```: 最適化するパラメータ-をまとめるもの(iterableでなければならない)、model.parameters()で渡すものだと考えてください。<br>\n",
    "  ```他のパラメーター```: 学習率やOptimizerによっては他のパラメーターがあると思いますが、それにあたります。<br><br>\n",
    "- initの実装上の注意点<br>\n",
    "  initメソッドではパラメータ-が正当なものかを判別する例外処理を書く必要があることもあります。<br>\n",
    "  Optimizerクラスを継承する時にはparamsに加えてlrのなどのパラメーターがまとめられたものを辞書型で渡して継承しなければいけません。<br><br>\n",
    "- stepの引数<br>\n",
    "  ```closure```: Conjugate GradientやLBFGSのような最適化アルゴリズムでは関数を何度も再評価するので必要になるらしいですが、おそらく滅多に使うことはないかと思われます。<br><br>\n",
    "- stepの実装上の注意点<br>\n",
    "  stepを実行した時点でParametersの勾配(grad)は計算されているものとします。<br>計算済みのgradを使って最適化の処理を書くところがstepと考えて良いでしょう。<br>\n",
    "  optimizerが処理するパラメーターはself.param_groupsにOptimizerクラスを継承した際に入れられています。<br>\n",
    "  params_groupsは辞書を要素としたリストであり、モデルのパラメーターを個別の要素に分割する方法を提供します。<br>\n",
    "  例えば、異なる学習率を使用してネットワークの別々のレイヤーをトレーニングする場合などはこれが使われます。<br>\n",
    "  [Pytorchの公式ドキュメント](https://pytorch.org/docs/stable/optim.html)では以下のように使用例があります。<br>\n",
    "  ```\n",
    "  optim.SGD([\n",
    "                {'params': model.base.parameters()},\n",
    "                {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "            ], lr=1e-2, momentum=0.9)\n",
    "  ```\n",
    "  <br>\n",
    "  params_groupの要素となっている辞書は, {\"params\":, \"lr\":, \"momentum\":, }のように、<br>\n",
    "  Optimizerの継承の時に使用したパラメーターなどを保存しています。<br>\n",
    "  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はMomentumSGDの実装を行います。\n",
    "MomentumSGDは以下の式で定義されます。\n",
    "$$\n",
    "\\text{w}^{t+1} = \\text{w}^{t} - η\\dfrac{\\partial E(\\text{w}^t)}{\\partial \\text{w}^t} + \\alpha Δ\\text{w}^t\n",
    "$$\n",
    "$$\n",
    "Δ\\text{w}^{t+1} = - η\\dfrac{\\partial E(\\text{w}^t)}{\\partial \\text{w}^t} + \\alpha Δ\\text{w}^t\n",
    "$$\n",
    "デフォルトで$η=0.001, \\alpha = 0.9$として実装を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum付きSGDの実装\n",
    "<br><br>\n",
    "あとで比較のために普通のSGDも記しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumSGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr = 0.001, momentum = 0.9) -> None:\n",
    "        if lr < 0:\n",
    "            raise ValueError(f\"Invalid learning rate: lr should be >= 0\")\n",
    "        if momentum < 0:\n",
    "            raise ValueError(f\"Invalid momentum rate: momentum should be >= 0\")\n",
    "        defaults = dict(lr = lr, momentum = momentum)\n",
    "        super(MomentumSGD, self).__init__(params, defaults)\n",
    "        self.state = dict()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                #stateの初期化\n",
    "                self.state[p] = dict(momentum=torch.zeros_like(p.data))\n",
    "    def step(self, closure = None) -> None:\n",
    "        \"\"\"\n",
    "        parameterのgradはbackwardメソッドで計算済みと考える。\n",
    "        更新するパラメーターのt時点での値をW^{t}と表すと、\n",
    "        W^{t+1} <- W^{t} - lr * W.grad.data + d_W^{t} * momentum\n",
    "        d_W^{t} <- W^{t+1} - W^{t} =  - lr * W.grad.data + d_W^{t} * momentum\n",
    "        の式を用いて更新する。\n",
    "        \"\"\"\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p not in self.state:\n",
    "                    self.state[p] = dict(momentum=torch.zeros_like(p.data))\n",
    "                mom = self.state[p]['momentum']\n",
    "                d_p = - group['lr'] * p.grad.data + group[\"momentum\"] * mom\n",
    "                p.data += d_p\n",
    "                self.state[p]['momentum'] = d_p\n",
    "\n",
    "class NormalSGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr = 0.001) -> None:\n",
    "        if lr < 0:\n",
    "            raise ValueError(f\"Invalid learning rate: lr should be >= 0\")\n",
    "        defaults = dict(lr = lr)\n",
    "        super(NormalSGD, self).__init__(params, defaults)\n",
    "    def step(self, closure = None) -> None:\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                d_p = - group['lr'] * p.grad.data\n",
    "                p.data += d_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応、上手く動作するかを確認しておきましょう。<br>\n",
    "$y = 5x+1$上にデータが載っている場合の最適化を考えます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#実験のためにデータを定義\n",
    "l1 = nn.Linear(1,1)\n",
    "l2 = nn.Linear(1,1)\n",
    "x = torch.arange(10).view(-1,1).float()\n",
    "y = 5*x+10\n",
    "sgd_mom = MomentumSGD(l1.parameters(), lr = 0.01)\n",
    "sgd = NormalSGD(l2.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum付きとMomentum無しの損失も観察してみましょう。この際、ただしくMomentumが動作しているかも確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20, loss_mom: 248.1944580078125, loss: 28.044031143188477\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[10.0104]], requires_grad=True): {'momentum': tensor([[0.4427]])}, Parameter containing:\n",
      "tensor([-3.8284], requires_grad=True): {'momentum': tensor([-0.1398])}}\n",
      "\n",
      "epoch: 40, loss_mom: 73.67290496826172, loss: 17.450098037719727\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[6.3567]], requires_grad=True): {'momentum': tensor([[-0.1748]])}, Parameter containing:\n",
      "tensor([-4.1730], requires_grad=True): {'momentum': tensor([0.4233])}}\n",
      "\n",
      "epoch: 60, loss_mom: 13.311273574829102, loss: 13.902971267700195\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[6.4066]], requires_grad=True): {'momentum': tensor([[0.2352]])}, Parameter containing:\n",
      "tensor([3.9490], requires_grad=True): {'momentum': tensor([0.3720])}}\n",
      "\n",
      "epoch: 80, loss_mom: 0.6129915714263916, loss: 10.225205421447754\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.1107]], requires_grad=True): {'momentum': tensor([[0.0403]])}, Parameter containing:\n",
      "tensor([8.3735], requires_grad=True): {'momentum': tensor([0.1250])}}\n",
      "\n",
      "epoch: 100, loss_mom: 0.06486053764820099, loss: 5.978250503540039\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[4.9979]], requires_grad=True): {'momentum': tensor([[-0.0911]])}, Parameter containing:\n",
      "tensor([9.6548], requires_grad=True): {'momentum': tensor([0.0119])}}\n",
      "\n",
      "epoch: 120, loss_mom: 0.07584024220705032, loss: 1.361779808998108\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.0474]], requires_grad=True): {'momentum': tensor([[0.0779]])}, Parameter containing:\n",
      "tensor([9.7342], requires_grad=True): {'momentum': tensor([0.0044])}}\n",
      "\n",
      "epoch: 140, loss_mom: 0.08132696896791458, loss: 4.297753810882568\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.0227]], requires_grad=True): {'momentum': tensor([[-0.0698]])}, Parameter containing:\n",
      "tensor([9.6583], requires_grad=True): {'momentum': tensor([-0.0119])}}\n",
      "\n",
      "epoch: 160, loss_mom: 0.1783050149679184, loss: 11.352810859680176\n",
      "\n",
      "この時のMomentumのパラメーターの状態\n",
      " {Parameter containing:\n",
      "tensor([[5.0044]], requires_grad=True): {'momentum': tensor([[0.0514]])}, Parameter containing:\n",
      "tensor([9.5896], requires_grad=True): {'momentum': tensor([0.0030])}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(175):\n",
    "    y_pred_mom = l1(x)\n",
    "    y_pred = l2(x)\n",
    "    loss_mom = ((y_pred_mom-y)**2).std()\n",
    "    loss_mom.backward()\n",
    "    loss = ((y_pred-y)**2).std()\n",
    "    loss.backward()\n",
    "    sgd_mom.step()\n",
    "    sgd_mom.zero_grad()\n",
    "    sgd.step()\n",
    "    sgd.zero_grad()\n",
    "\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(f\"\\nepoch: {i+1}, loss_mom: {loss_mom.item()}, loss: {loss.item()}\")\n",
    "        print(\"\\nこの時のMomentumのパラメーターの状態\\n\", sgd_mom.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x.numpy(),l1(x).detach().numpy(),marker = \"x\")\n",
    "plt.scatter(x.numpy(),l2(x).detach().numpy(),marker = \"v\")\n",
    "plt.plot(x.numpy(),y.numpy())\n",
    "plt.legend([\"Momentum\", \"Non Momentum\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix2\n",
    "Pytorchを普通の最適化に使えないか?\n",
    "例えば$y = \\dfrac{1}{x+10} + 5$という関数を<br>\n",
    "学習可能なパラメーターa, bをもちいて$y = \\dfrac{1}{x+a} + b$を用いてaとbを求めるように計算を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(50, dtype = \"float32\")\n",
    "y = 1/(x + 10) + 5. + np.random.uniform(size = 50, low = -0.01, high = 0.01)\n",
    "y = y.astype(\"float32\")\n",
    "plt.scatter(x,y,color = \"red\", marker = \"x\")\n",
    "plt.legend([\"y = $\\dfrac{1}{x+10}+5+error$\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoaderとパラメーターの定義\n",
    "from torch.utils.data import TensorDataset\n",
    "x_train = torch.from_numpy(x).view(-1,1)\n",
    "y_train = torch.from_numpy(y).view(-1,1)\n",
    "train_dl = TensorDataset(x_train, y_train)\n",
    "a = torch.ones(1, requires_grad=True).to(torch.float32)\n",
    "b = torch.ones(1, requires_grad=True).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(a)\n",
    "        self.b = nn.Parameter(b)\n",
    "    def forward(self,x):\n",
    "        return 1/(x+self.a) + self.b\n",
    "model = Model(a,b)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, loss: 0.00018702448869589716\n",
      "epoch: 400, loss: 0.00014653074322268367\n",
      "epoch: 600, loss: 0.00013629171007778496\n",
      "epoch: 800, loss: 0.00013620265235658735\n",
      "epoch: 1000, loss: 0.00013620265235658735\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "best_score = 100\n",
    "for epoch in range(epochs):\n",
    "    for x_b, y_b in train_dl:\n",
    "        pred = model(x_b)\n",
    "        loss = criterion(pred, y_b)\n",
    "        loss.backward()\n",
    "        if loss.item() < best_score:\n",
    "            best_params = model.parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"epoch: {epoch+1}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(0,49, num = 200).astype(\"float32\")\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_test.detach().numpy(), y_test.detach().numpy())\n",
    "plt.scatter(x,y,color = \"red\", marker = \"x\")\n",
    "plt.legend([\"Prediction\",\"y = $\\dfrac{1}{x+10}+5+error$\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchが最適計算に使えることもわかった。<br>\n",
    "Pytorchの本質はこのようにモデルと損失関数を定義してさえしまえばあとは勝手に計算を行ってくれることであるとわかる。<br>\n",
    "従って、理論式があるようなデータを扱う時は理論に沿ってモデルを立てた方が変なモデルを作るよりもいい結果を導いてくれることがわかる。<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e2ef60554f914b7f3190499c85ea0c48ae4fc01e8f403cc646d16228abbf679"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
